{"meta":{"title":"Keep Coding","subtitle":"from a coder","description":null,"author":"Yuechuan Xiao","url":"https://yuechuanx.top"},"pages":[{"title":"","date":"2020-04-23T03:36:06.725Z","updated":"2020-04-23T03:36:06.725Z","comments":true,"path":"google25db0db12bacc6bc.html","permalink":"https://yuechuanx.top/google25db0db12bacc6bc.html","excerpt":"","text":"google-site-verification: google25db0db12bacc6bc.html"},{"title":"404 Not Found：该页无法显示","date":"2020-04-23T03:36:06.701Z","updated":"2020-04-23T03:36:06.701Z","comments":false,"path":"/404.html","permalink":"https://yuechuanx.top//404.html","excerpt":"","text":""},{"title":"关于","date":"2020-04-23T03:36:06.724Z","updated":"2020-04-23T03:36:06.724Z","comments":false,"path":"about/index.html","permalink":"https://yuechuanx.top/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"分类","date":"2020-04-23T03:36:06.724Z","updated":"2020-04-23T03:36:06.724Z","comments":false,"path":"categories/index.html","permalink":"https://yuechuanx.top/categories/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2020-04-23T03:36:06.725Z","updated":"2020-04-23T03:36:06.725Z","comments":false,"path":"repository/index.html","permalink":"https://yuechuanx.top/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-04-23T03:36:06.726Z","updated":"2020-04-23T03:36:06.726Z","comments":false,"path":"tags/index.html","permalink":"https://yuechuanx.top/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"<流畅的 Python> 笔记：一等函数","slug":"Python/fluent-python-notes-chap-05","date":"2020-04-22T08:38:39.000Z","updated":"2020-04-23T03:36:06.719Z","comments":true,"path":"Python/fluent-python-notes-chap-05/","link":"","permalink":"https://yuechuanx.top/Python/fluent-python-notes-chap-05/","excerpt":"","text":"不管别人怎么说或怎么想，我从未觉得 Python 受到来自函数式语言的太多影响。我非常熟悉命令式语言，如 C 和 Algol 68，虽然我把函数定为一等对象，但是我并不把 Python 当作函数式编程语言。 —— Guido van Rossum: Python 仁慈的独裁者 在 Python 中，函数是一等对象。 编程语言理论家把“一等对象”定义为满足下述条件的程序实体： 在运行时创建 能赋值给变量或数据结构中的元素 能作为参数传给函数 能作为函数的返回结果 函数即为对象 1234567def factorial(n): \"\"\"returns n!\"\"\" return 1 if n &lt; 2 else n * factorial(n-1)factorial(42)factorial.__doc__type(factorial) 通过 type(factorial) 可以看到 function 是一种类型，或者说，函数也是对象，可以通过__doc__ 去访问它的属性。 那么作为对象的函数，也能作为参数被传递。函数式风格编程也基于此 12345fact = factorialfactfact(5)map(factorial, range(11))list(map(fact, range(11))) 高阶函数 输入或者输出是函数的即为高阶函数(higher order function)。例如：map， sorted。 123fruits = ['strawberry', 'fig', 'apple', 'cherry', 'raspberry', 'banana']# function len() as keysorted(fruits, key=len) map、filter 和 reduce 的替代品 函数式语言通常提供 map、filter 和 reduce 三个高阶函数。 在 Python 中引入了列表推导和生成式表达式，可以替代它们且更容易阅读。 1234list(map(fact, range(6)))[fact(n) for n in range(6)]list(map(factorial, filter(lambda n : n % 2, range(6))))[factorial(n) for n in range(6) if n % 2] map 和 filter 返回生成器，可用生成器表达式替代 reduce 常用求和，目前最好使用 sum 替代 12345from functools import reducefrom operator import addreduce(add, range(100))sum(range(100)) sum 和 reduce 把操作连续应用在序列元素上，得到返回值 all(iterable), any(iterable) 也是规约函数 all(iterable): 每个元素为真，返回真 any(iterable): 存在一个元素为真，返回真 匿名函数 Python 支持 lambda 表达式。 它是函数对象，在句法上被限制只能用存表达式。 参数列表中最适合使用匿名函数。 1234# 根据单词末尾字符排序fruits = ['strawberry', 'fig', 'apple', 'cherry', 'raspberry', 'banana']sorted(fruits, key=lambda word: word[::-1]) Python 的可调用对象 用户定义的函数：使用 def 或 lambda 创建 内置函数：如 len 或 time.strfttime 内置方法：如 dict.get 类：先调用 __new__ 创建实例，再对实例运行 __init__ 方法 类的实例：如果类上定义了 __call__ 方法，则实例可以作为函数调用 生成器函数：使用 yield 关键字的函数或方法，调用生成器函数会返回生成器对象 判断对象是否能调用，使用内置的 callable() 函数 12abs, str, 13[callable(obj) for obj in (abs, str, 13)] 用户定义的可调用类型 任何 Python 对象都可以表现得像函数，只需实现实例方法 __call__ 1234567891011121314151617181920import random class BingoCage: def __init__(self, items): self._items = list(items) random.shuffle(self._items) def pick(self): try: return self._items.pop() except IndexError: raise LookupError('pick from empty BingoCage') def __call__(self): return self.pick() bingo = BingoCage(range(3))bingo.pick()bingo()callable(bingo) 实现 __call__ 方法的类是创建函数类对象的简便方式。 函数类对象有自己的状态，即为实例变量。装饰器函数也可以有. 函数内省 内省（introspection）可以查看函数内部的细节，函数有许多属性。使用 dir 函数可以查看，或使用 code 属性 12dir(factorial)# factorial.__code__.co_varnames 1234567# eg:5-9# 列出常规对象没有而函数有的属性class C: passobj = C()def func(): passsorted(set(dir(func)) - set(dir(obj))) 函数属性说明 // 插入表格 从定位参数到仅限关键字参数 本节讨论 python 参数处理机制。py3 提供了仅限关键字参数（keyword-only argument） 调用函数使用 * 和 ** 展开可迭代对象。 positional argument 位置参数 keyword-only argument 仅限关键字参数 123456789101112131415161718192021222324252627def tag(name, *content, cls=None, **attrs): \"\"\"生成一个或多个 HTML 标签\"\"\" if cls is not None: attrs['class'] = cls if attrs: attr_str = ''.join(' %s=\"%s\"' % (attr, value) for attr, value in sorted(attrs.items())) else: attr_str = '' if content: return '\\n'.join('&lt;%s%s&gt;%s&lt;/%s&gt;' % (name, attr_str, c, name) for c in content) else: return '&lt;%s%s /&gt;' % (name, attr_str) tag('br')tag('p', 'hello')tag('p', 'hello', 'world') # 'hello', 'world' -&gt; *contenttag('p', 'hello', id=33) # id=33 -&gt; **attrstag('p', 'hello', 'world', cls='sidebar')tag(content='testing', name=\"img\")my_tag = &#123; 'name': 'img', 'title': 'Sunset Boulevard', 'src': 'sunset.jpg', 'cls': 'framed'&#125;tag(**my_tag) cls 参数只能通过关键字指定，而不能通过位置参数指定。 定义函数时若只想定仅限关键字参数，要把它放在带有 * 参数后面，如果不想支持数量不定的位置参数，但支持 keyowrd-only, 在函数签名中放一个 * 12345def f(a, *, b): return a, b# f(1, 2)f(1, b=2) 获取关于参数的信息 上面提到，函数内省可以查看函数内部信息，通过 HTTP 微框架 Bobo 作为例子来看下 12345678910111213141516171819202122232425262728293031# eg: 5-12# hello.pyimport bobo@bobo.query('/')def hello(person): return 'Hello %s!' % person# 在环境中执行 bobo -f hello.py, 若运行端口为 http://localhost:8080/# 没有传入参数# curl -i http://localhost:8080/# HTTP/1.0 403 Forbidden# Date: Wed, 22 Apr 2020 06:23:33 GMT# Server: WSGIServer/0.2 CPython/3.7.4# Content-Type: text/html; charset=UTF-8# Content-Length: 103# &lt;html&gt;# &lt;head&gt;&lt;title&gt;Missing parameter&lt;/title&gt;&lt;/head&gt;# &lt;body&gt;Missing form variable person&lt;/body&gt;# &lt;/html&gt;# 传入参数# curl -i http://localhost:8080/?person=Jim# HTTP/1.0 200 OK# Date: Wed, 22 Apr 2020 06:24:47 GMT# Server: WSGIServer/0.2 CPython/3.7.4# Content-Type: text/html; charset=UTF-8# Content-Length: 10# Hello Jim!% Bobo 如何知道函数需要哪个参数呢？ 函数对象有 __defaults__ 属性，其值为一个元祖，保存着位置参数和关键字参数的默认值。 keyword-only 参数默认值保存在 __kwdefaults__ 属性中。 参数的名称在 __code__ 属性中，其值为 code 对象的引用。 123456789101112131415161718192021def clip(text, max_len=80): \"\"\"在 max_len 前后的第一个空格处截断文本\"\"\" end = None if (len(text)) &gt; max_len: space_before = text.rfind(' ', 0, max_len) if space_before &gt;= 0: end = space_before else: space_after = text.rfind(' ', max_len) if space_after &gt;= 0: end = space_after if end is None: end = len(text) return text[:end].rstrip()clip.__defaults__# clip.__code__# clip.__code__.co_varnames# clip.__code__.co_argcount 函数签名信息，参数和默认值是分开的。可以使用 inspect 模块提取这些信息 1234567from inspect import signaturesig = signature(clip)sigstr(sig)for name, param in sig.parameters.items(): print(param.kind, ':', name, '=', param.default) kind 属性值在 _Parameterkind 类中，列举如下： POSTIONAL_OR_KEYWORD VAR_POSITIONAL VAR_KEYWORD KEYWORD-ONLY POSITIONAL_ONLY inspect.Signature 有 bind 方法，可以把任意个参数绑定在签名中的形参上。 框架可以使用此方法在调用函数前验证参数 12345678910111213import inspectsig = inspect.signature(tag)my_tag = &#123; 'name': 'img', 'title': 'Sunset Boulevard', 'src': 'sunset.jpg', 'cls': 'framed'&#125;bound_args = sig.bind(**my_tag)bound_argsdel my_tag['name']# missing argument errorbound_args = sig.bind(**my_tag) 框架和 IDE 工具可以使用这些信息验证代码 函数注解（annotation） 各个参数可以在 : 后添加注解表达式。 参数有默认值，注解放在参数名和 = 号之间，注解返回值在函数声明末尾添加 -&gt; 和表达式 注解不会做任何处理，只存储在函数 __annotations__ 属性中。 注解只是元数据，可以供 IDE，框架和装饰器等工具使用 inspect.signature() 函数知道怎么提取注解 1234def clip(text: str, max_len: 'int &gt; 0' = 80) -&gt; str: passclip.__annotations__ 12345678from inspect import signaturesig = signature(clip)sig.return_annotationfor param in sig.parameters.values(): note = repr(param.annotation).ljust(13) print(note, ':', param.name, '=', param.default) 支持函数式编程的包 operator 模块 operator 里有很多函数，对应着 Python 中的内置运算符，使用它们可以避免编写很多无趣的 lambda 函数，如： add: lambda a, b: a + b or_: lambda a, b: a or b itemgetter: lambda a, b: a[b] attrgetter: lambda a, b: getattr(a, b) 12345678from functools import reducefrom operator import muldef fact(n): return reduce(lambda a, b: a*b, range(1, n+1))def fact(n): return reduce(mul, range(1, n+1)) 还有一类函数，能替代从序列中取出或读取元素属性的 lambda 表达式。如 itemgetter，attrgetter 1234567891011121314151617181920metro_data = [ ('Tokyo', 'JP', 36.933, (35.689722, 139.691667)), # &lt;1&gt; ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)), ('Mexico City', 'MX', 20.142, (19.433333, -99.133333)), ('New York-Newark', 'US', 20.104, (40.808611, -74.020386)), ('Sao Paulo', 'BR', 19.649, (-23.547778, -46.635833)),]from operator import itemgetterfor city in sorted(metro_data, key=lambda fields: fields[1]): print(city)for city in sorted(metro_data, key=itemgetter(1)): print(city)# itemgetter 返回提取的值构成的元祖，可以用来提取指定字段或调整元祖顺序cc_name = itemgetter(1, 0)for city in metro_data: print(cc_name(city)) itemgetter 使用 [] 运算符，因为它不仅支持序列，还支持映射和任何实现 __getitem__ 的类 attrgetter 作用相似，它创建的函数根据名称提取对象的属性。包含 . 的，会进入到嵌套对象提取属性 12345678910111213141516from collections import namedtupleLatLong = namedtuple('Latlong', 'lat long')Metorpolis = namedtuple('Metorpolis', 'name cc pop coord')metro_areas = [Metorpolis(name, cc, pop, LatLong(lat, long)) for name, cc, pop, (lat, long) in metro_data]metro_areas[0]metro_areas[0].coord.latfrom operator import attrgettername_lat = attrgetter('name', 'coord.lat')for city in sorted(metro_areas, key=attrgetter('coord.lat')): print(name_lat(city)) 12import operator[name for name in dir(operator) if not name.startswith('_')] operator 模块的函数可以通过 dir(operator) 查看。 介绍 methodcaller, 它的作用与前两个函数相似，它创建的函数会在对象调用参数指定的方法 1234567from operator import methodcallers = 'The time has come'upcase = methodcaller('upper')upcase(s)hiphenate = methodcaller('replace', ' ', '-')hiphenate(s) 使用 functools.partial 冻结参数 functools 最常用的函数有 reduce，之前已经介绍过。余下函数中最有用的是 partial 及其变体 partialmethod 它的作用是：把原函数某些参数固定。 partial 第一个函数是可调用对象，后面跟任意个位置参数和关键字参数 1234567891011121314from operator import mulfrom functools import partialtriple = partial(mul, 3)triple(7)list(map(triple, range(1, 10)))picture = partial(tag, 'img', cls='pic-frame')picture(src='wumpus.jepg')picturepicture.funcpicture.argspicture.keywords functoos.partialmethod 作用与 partial 一样，不过适用于处理方法的 小结 探讨 Python 函数的一等特性。意味着可以把函数赋值给变量，传入其他函数，存储于数据结构中，以及访问函数属性。 高阶函数是函数式编程的重要组成。 Python 的可调用对象: 7种 函数及其注解有丰富的特性。可通过 inspect 模块读取 最后介绍了 operator 模块中的一些函数，可以替换掉功能有限的 lambda 表达式。","categories":[{"name":"Python","slug":"Python","permalink":"https://yuechuanx.top/categories/Python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://yuechuanx.top/tags/python/"}]},{"title":"Zen of Python（Python之禅）","slug":"zen-of-python","date":"2020-04-15T08:54:29.000Z","updated":"2020-04-23T03:36:06.724Z","comments":true,"path":"zen-of-python/","link":"","permalink":"https://yuechuanx.top/zen-of-python/","excerpt":"","text":"Beautiful is better than ugly. （优美比丑陋好） Explicit is better than implicit.（清晰比晦涩好） Simple is better than complex.（简单比复杂好） Complex is better than complicated.（复杂比错综复杂好） Flat is better than nested.（扁平比嵌套好） Sparse is better than dense.（稀疏比密集好） Readability counts.（可读性很重要） Special cases aren’t special enough to break the rules.（特殊情况也不应该违反这些规则） Although practicality beats purity.（但现实往往并不那么完美） Errors should never pass silently.（异常不应该被静默处理） Unless explicitly silenced.（除非你希望如此） In the face of ambiguity, refuse the temptation to guess.（遇到模棱两可的地方，不要胡乱猜测） There should be one-- and preferably only one --obvious way to do it.（肯定有一种通常也是唯一一种最佳的解决方案） Although that way may not be obvious at first unless you’re Dutch.（虽然这种方案并不是显而易见的，因为你不是那个荷兰人这里指的是Python之父Guido） Now is better than never.（现在开始做比不做好） Although never is often better than *right* now.（不做比盲目去做好极限编程中的YAGNI原则） If the implementation is hard to explain, it’s a bad idea.（如果一个实现方案难于理解，它就不是一个好的方案） If the implementation is easy to explain, it may be a good idea.（如果一个实现方案易于理解，它很有可能是一个好的方案） Namespaces are one honking great idea – let’s do more of those!（命名空间非常有用，我们应当多加利用）","categories":[],"tags":[]},{"title":"Django 导出和导入数据","slug":"django-dumpdata-and-loaddata","date":"2020-04-13T10:57:03.000Z","updated":"2020-04-23T03:36:06.720Z","comments":true,"path":"django-dumpdata-and-loaddata/","link":"","permalink":"https://yuechuanx.top/django-dumpdata-and-loaddata/","excerpt":"","text":"dumpdata 命令： 它可以用来备份（导出）模型实例或整个数据库 12345678910111213141516171819202122232425262728293031323334./manage.py dumpdata --helpusage: manage.py dumpdata [-h] [--format FORMAT] [--indent INDENT] [--database DATABASE] [-e EXCLUDE] [--natural-foreign] [--natural-primary] [-a] [--pks PRIMARY_KEYS] [-o OUTPUT] [--version] [-v &#123;0,1,2,3&#125;] [--settings SETTINGS] [--pythonpath PYTHONPATH] [--traceback] [--no-color] [--force-color] [app_label[.ModelName] [app_label[.ModelName] ...]]Output the contents of the database as a fixture of the given format (using each model's default manager unless --all is specified).positional arguments: app_label[.ModelName] Restricts dumped data to the specified app_label or app_label.ModelName.optional arguments: -h, --help show this help message and exit --format FORMAT Specifies the output serialization format for fixtures. --indent INDENT Specifies the indent level to use when pretty-printing output. --database DATABASE Nominates a specific database to dump fixtures from. Defaults to the \"default\" database. -e EXCLUDE, --exclude EXCLUDE An app_label or app_label.ModelName to exclude (use multiple --exclude to exclude multiple apps/models). --natural-foreign Use natural foreign keys if they are available. --natural-primary Use natural primary keys if they are available. -a, --all Use Django's base manager to dump all models stored in the database, including those that would otherwise be filtered or modified by a custom manager. --pks PRIMARY_KEYS Only dump objects with given primary keys. Accepts a comma-separated list of keys. This option only works when you specify one model. -o OUTPUT, --output OUTPUT Specifies file to which the output is written. --version show program's version number and exit -v &#123;0,1,2,3&#125;, --verbosity &#123;0,1,2,3&#125; Verbosity level; 0=minimal output, 1=normal output, 2=verbose output, 3=very verbose output --settings SETTINGS The Python path to a settings module, e.g. \"myproject.settings.main\". If this isn't provided, the DJANGO_SETTINGS_MODULE environment variable will be used. --pythonpath PYTHONPATH A directory to add to the Python path, e.g. \"/home/djangoprojects/myproject\". --traceback Raise on CommandError exceptions --no-color Don't colorize the command output. --force-color Force colorization of the command output. 基础数据库导出 1./manage.py dumpdata &gt; db.json 这会导出整个数据库到 db.json 备份指定的 app 1./manage.py dumpdata admin &gt; admin.json 这会导出 admin 应用的内容到 admin.json 备份指定的数据表 1./manage.py dumpdata admin.logentry &gt; logentry.json 这会导出 admin.logentry 数据表的所有数据 1./manage.py dumpdata auth.user &gt; user.json 这会导出 auth.user 数据表的所有数据 dumpdata —exclude —exclude 选项用来指定无需被导出的 apps/tables 1./manage.py dumpdata --exclude auth.permission &gt; db.json 这会导出整个数据库，但不包括 auth.permisson dumpdata —intent 默认情况，dumpdata 的输出会挤在同一行，可读性很差。使用 —indent 可以设定缩进美化输出 1./manage.py dumpdata auth.user --indent 2 &gt; user.json 1234567891011121314151617181920212223242526272829303132333435363738[&#123; \"model\": \"auth.user\", \"pk\": 1, \"fields\": &#123; \"password\": \"pbkdf2_sha256$150000$i8oET981EnSJ$d2RCpfY76gFHbwUs1HekSK+pOLYMJFcJ1wFcuyf6R28=\", \"last_login\": \"2020-04-13T09:21:34.639Z\", \"is_superuser\": true, \"username\": \"xiao\", \"first_name\": \"\", \"last_name\": \"\", \"email\": \"yuechuan.xiao@artosyn.cn\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2020-04-13T08:59:01.310Z\", \"groups\": [], \"user_permissions\": [] &#125;&#125;,&#123; \"model\": \"auth.user\", \"pk\": 2, \"fields\": &#123; \"password\": \"pbkdf2_sha256$150000$PgBKh5sMAE1y$xdFkYi+gprF1v2rlOyw2OOsRn87zSeTVLJ9dGfoXzIw=\", \"last_login\": null, \"is_superuser\": true, \"username\": \"qa\", \"first_name\": \"\", \"last_name\": \"\", \"email\": \"qa@artosyn.cn\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2020-04-13T08:59:16.279Z\", \"groups\": [], \"user_permissions\": [] &#125;&#125;] dumpdata —format 默认输出格式为 JSON。使用 —format 可以指定输出格式 json xml yaml 1./manage.py dumpdata auth.user --indent 2 --format xml &gt; user.xml 这会输出 xml 文件 12345678910111213141516171819202122232425262728293031&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;django-objects version=\"1.0\"&gt; &lt;object model=\"auth.user\" pk=\"1\"&gt; &lt;field name=\"password\" type=\"CharField\"&gt;pbkdf2_sha256$150000$i8oET981EnSJ$d2RCpfY76gFHbwUs1HekSK+pOLYMJFcJ1wFcuyf6R28=&lt;/field&gt; &lt;field name=\"last_login\" type=\"DateTimeField\"&gt;2020-04-13T09:21:34.639297+00:00&lt;/field&gt; &lt;field name=\"is_superuser\" type=\"BooleanField\"&gt;True&lt;/field&gt; &lt;field name=\"username\" type=\"CharField\"&gt;xiao&lt;/field&gt; &lt;field name=\"first_name\" type=\"CharField\"&gt;&lt;/field&gt; &lt;field name=\"last_name\" type=\"CharField\"&gt;&lt;/field&gt; &lt;field name=\"email\" type=\"CharField\"&gt;yuechuan.xiao@artosyn.cn&lt;/field&gt; &lt;field name=\"is_staff\" type=\"BooleanField\"&gt;True&lt;/field&gt; &lt;field name=\"is_active\" type=\"BooleanField\"&gt;True&lt;/field&gt; &lt;field name=\"date_joined\" type=\"DateTimeField\"&gt;2020-04-13T08:59:01.310568+00:00&lt;/field&gt; &lt;field name=\"groups\" rel=\"ManyToManyRel\" to=\"auth.group\"&gt;&lt;/field&gt; &lt;field name=\"user_permissions\" rel=\"ManyToManyRel\" to=\"auth.permission\"&gt;&lt;/field&gt; &lt;/object&gt; &lt;object model=\"auth.user\" pk=\"2\"&gt; &lt;field name=\"password\" type=\"CharField\"&gt;pbkdf2_sha256$150000$PgBKh5sMAE1y$xdFkYi+gprF1v2rlOyw2OOsRn87zSeTVLJ9dGfoXzIw=&lt;/field&gt; &lt;field name=\"last_login\" type=\"DateTimeField\"&gt;&lt;None&gt;&lt;/None&gt;&lt;/field&gt; &lt;field name=\"is_superuser\" type=\"BooleanField\"&gt;True&lt;/field&gt; &lt;field name=\"username\" type=\"CharField\"&gt;qa&lt;/field&gt; &lt;field name=\"first_name\" type=\"CharField\"&gt;&lt;/field&gt; &lt;field name=\"last_name\" type=\"CharField\"&gt;&lt;/field&gt; &lt;field name=\"email\" type=\"CharField\"&gt;qa@artosyn.cn&lt;/field&gt; &lt;field name=\"is_staff\" type=\"BooleanField\"&gt;True&lt;/field&gt; &lt;field name=\"is_active\" type=\"BooleanField\"&gt;True&lt;/field&gt; &lt;field name=\"date_joined\" type=\"DateTimeField\"&gt;2020-04-13T08:59:16.279788+00:00&lt;/field&gt; &lt;field name=\"groups\" rel=\"ManyToManyRel\" to=\"auth.group\"&gt;&lt;/field&gt; &lt;field name=\"user_permissions\" rel=\"ManyToManyRel\" to=\"auth.permission\"&gt;&lt;/field&gt; &lt;/object&gt;&lt;/django-objects&gt; loaddata 命令 用来导入 fixtures（dumpdata 导出的数据）到数据库 1./manage.py loaddata user.json 这会导入 user.json 里的内容到数据库 恢复 fresh database 当你通过 dumpdata 命令备份整个数据库时，它将备份所有数据表。若使用 dump 文件导入到另外的 Django 项目，会导致 IntegrityError。 可以通过备份时加入选项 —exclude contenttypes 和 auth.permissions 数据表修复此问题 1./manage.py dumpdata --exclude auth.permission --exclude contenttypes &gt; db.json 现在再用 loaddata 命令导入 fresh dababase 1./manage.py loaddata db.json","categories":[],"tags":[{"name":"django","slug":"django","permalink":"https://yuechuanx.top/tags/django/"}]},{"title":"Python代码规范 Pep8","slug":"Python/python-codestyle-pep8","date":"2020-04-01T06:12:38.000Z","updated":"2020-04-23T03:36:06.720Z","comments":true,"path":"Python/python-codestyle-pep8/","link":"","permalink":"https://yuechuanx.top/Python/python-codestyle-pep8/","excerpt":"","text":"以下所有内容包含在官方 PEP(Python Enhancement Proposals) 链接为 [pep8][https://www.python.org/dev/peps/pep-0008/] 简要版本 代码编排 缩进。4个空格的缩进（编辑器都可以完成此功能），不使用Tap，更不能混合使用Tap和空格。 针对不同编辑器兼容性，对 tab 可能有不同的标准，导致样式不统一。 每行最大长度79，换行可以使用反斜杠，最好使用圆括号。换行点要在操作符的后边敲回车。 早期 unix 主机终端只能显示 80 个字符。 通过限制所需的编辑器窗口宽度，可以并排打开多个文件，并且在使用在相邻列中显示两个版本的代码查看工具时，效果很好。 类和top-level函数定义之间空两行； 类中的方法定义之间空一行； 函数内逻辑无关段落之间空一行； 其他地方尽量不要再空行。 文档编排 模块内容的顺序： 模块说明和docstring import globals&amp;constants 其他定义。 其中import部分，又按标准、三方和自己编写顺序依次排放，之间空一行。 不要在一句import中多个库，比如import os, sys不推荐。 如果采用from XX import XX引用库，可以省略‘module.’，都是可能出现命名冲突，这时就要采用import XX。 如果有命名冲突。可以使用 from X import Y as Z 1234567891011121314151617181920212223242526272829303132333435# -*- coding: utf-8 -*-#!/bin/python3# -------------------------------------------------------------------------# Author: Yuechuan Xiao# @Date: 2020-01-09 14:56:57# @LastEditors: Yuechuan Xiao# @LastEditTime: 2020-03-30 16:33:48# @Description:# report.py: gen build's jira issues html report.# -------------------------------------------------------------------------\"\"\"Docstringreporter.py is used to generate a html report for specific build.\"\"\"# Standard libraryimport osimport refrom collections import namedtuple# Third party lib# Import multi-subcass from A package.from jinja2 import ( Environment, FileSystemLoader, Template, select_autoescape)from jira import JIRA# If you have lcoal import # from .utils import X# from . import utils 空格的使用 总体原则，避免不必要的空格。 各种右括号前不要加空格。 逗号、冒号、分号前不要加空格。 函数的左括号前不要加空格。如func(1)。 序列的左括号前不要加空格。如list[2]。 操作符左右各加一个空格，不要为了对齐增加空格。 函数默认参数使用的赋值符左右省略空格。 不要将多句语句写在同一行，尽管使用‘；’允许。 if/for/while语句中，即使执行语句只有一句，也必须另起一行。 命名规范 总体原则，新编代码必须按下面命名风格进行，现有库的编码尽量保持风格。 尽量单独使用小写字母l，大写字母O等容易混淆的字母。 模块命名尽量短小，使用全部小写的方式，可以使用下划线。 包命名尽量短小，使用全部小写的方式，不可以使用下划线。 类的命名使用CapWords的方式，模块内部使用的类采用_CapWords的方式。_ 异常命名使用CapWords+Error后缀的方式。 全局变量尽量只在模块内有效，类似C语言中的static。实现方法有两种，一是__all__机制;二是前缀一个下划线 函数命名使用全部小写的方式，可以使用下划线。 常量命名使用全部大写的方式，可以使用下划线。 类的属性（方法和变量）命名使用全部小写的方式，可以使用下划线。 类的属性有3种作用域public、non-public和subclass API，可以理解成C++中的public、private、protected，non-public属性前，前缀一条下划线。 类的属性若与关键字名字冲突，后缀一下划线，尽量不要使用缩略等其他方式。 为避免与子类属性命名冲突，在类的一些属性前，前缀两条下划线。比如：类Foo中声明__a,访问时，只能通过Foo._Foo__a，避免歧义。如果子类也叫Foo，那就无能为力了。 类的方法第一个参数必须是self，而静态方法第一个参数必须是cls。 注释 总体原则，错误的注释不如没有注释。所以当一段代码发生变化时，第一件事就是要修改注释！ 针对团队情况（是否国际化），注释倾向使用英文，最好是完整的句子，首字母大写，句后要有结束符，结束符后跟两个空格，开始下一句。如果是短语，可以省略结束符。 块注释，在一段代码前增加的注释。在‘#’后加一空格。段落之间以只有‘#’的行间隔。比如： 123456# Description : Module config.## Input : None## Output : None 行注释，在一句代码后加注释。比如：x = x + 1 # Increment x 但是这种方式尽量少使用。可以在 Magic Number 时使用。 避免无谓的注释。 文档描述 1 为所有的共有模块、函数、类、方法写docstrings；非共有的没有必要，但是可以写注释（在def的下一行）。 2 如果docstring要换行，参考如下例子,详见PEP 257 12345\"\"\"Return a foobangOptional plotz says to frobnicate the bizbaz first.\"\"\" 编码建议 编码中考虑到其他python实现的效率等问题，比如运算符‘+’在CPython（Python）中效率很高，都是Jython中却非常低，所以应该采用.join()的方式。 2 尽可能使用i s is not取代==，比如if x is not None 要优于if x。 3 使用基于类的异常，每个模块或包都有自己的异常类，此异常类继承自Exception。 4 异常中不要使用裸露的except，except后跟具体的exceptions。 5 异常中try的代码尽可能少。比如： 1234567891011121314try:value = collection[key]except KeyError:return key_not_found(key)else:return handle_value(value)要优于try:# Too broad!return handle_value(collection[key])except KeyError:# Will also catch KeyError raised by handle_value()return key_not_found(key) 使用startswith() and endswith()代替切片进行序列前缀或后缀的检查。比如 12345Yes: if foo.startswith(‘bar’):优于No: if foo[:3] == ‘bar’:- 使用isinstance()比较对象的类型。比如Yes: if isinstance(obj, int): 优于No: if type(obj) is type(1): 判断序列空或不空，有如下规则 12345Yes: if not seq:if seq:优于No: if len(seq)if not len(seq) 字符串不要以空格收尾。 二进制数据判断使用 if boolvalue的方式。 Reference [PEP8][https://www.python.org/dev/peps/pep-0008/] Google Python 开源项目风格指南","categories":[{"name":"Python","slug":"Python","permalink":"https://yuechuanx.top/categories/Python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://yuechuanx.top/tags/python/"}]},{"title":"Django 项目后端模板","slug":"django-backend-template","date":"2020-02-16T06:55:49.000Z","updated":"2020-04-23T03:36:06.720Z","comments":true,"path":"django-backend-template/","link":"","permalink":"https://yuechuanx.top/django-backend-template/","excerpt":"","text":"Django 项目本身可以通过 django-admin 或者直接运行 python manage.py ARGS 来进行脚手架生成。但是生成的项目框架层次不算太好。 首先生成一个 Django 项目： 1django-admin startproject backend 生成的项目框架如下： 1234567backend├── backend│ ├── __init__.py│ ├── settings.py│ ├── urls.py│ └── wsgi.py└── manage.py 其中的两个 backend 分别表示项目，以及 app 全局配置 建立文件夹 apps 用来放置应用，把内层 backend 改为 conf 12345678backend├── apps├── conf│ ├── __init__.py│ ├── settings.py│ ├── urls.py│ └── wsgi.py└── manage.py 注意这里需要配置以下几个文件： 12345# manage.py ...# os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'backend.settings')os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'conf.settings')... 12345678# settings.py...# ROOT_URLCONF = 'backend.urls'ROOT_URLCONF = 'conf.urls'...# WSGI_APPLICATION = 'backend.wsgi.application'WSGI_APPLICATION = 'conf.wsgi.application'... 现在可以测试 python manage.py runserver 是否可以起来。 接下来新建 Apps 12mkdir apps/loginpython manage.py startapp login apps/login 注册 app 1234567891011121314151617181920212223242526272829# settings.pyTEMPLATES = [ &#123; 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': ['apps'], # 添加 apps 文件夹 'APP_DIRS': True, 'OPTIONS': &#123; 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], &#125;, &#125;,]INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'apps.login',] 导入 URL 1234567...from apps.login import urls as login_urlsurlpatterns = [ path('admin/', admin.site.urls), path('login/', include(login_urls)),] 现在一个基本的项目结构就建立好了。 123456789101112131415161718backend├── apps│ └── login│ ├── __init__.py│ ├── admin.py│ ├── apps.py│ ├── migrations│ │ └── __init__.py│ ├── models.py│ ├── tests.py│ └── views.py├── conf│ ├── __init__.py│ ├── settings.py│ ├── urls.py│ └── wsgi.py├── db.sqlite3└── manage.py 相比起来层次更清晰，而且也更适合用作前后端分离的命名","categories":[],"tags":[{"name":"web","slug":"web","permalink":"https://yuechuanx.top/tags/web/"},{"name":"django","slug":"django","permalink":"https://yuechuanx.top/tags/django/"}]},{"title":"如何理解递归","slug":"understand-recursion","date":"2019-12-25T06:19:03.000Z","updated":"2020-04-23T03:36:06.723Z","comments":true,"path":"understand-recursion/","link":"","permalink":"https://yuechuanx.top/understand-recursion/","excerpt":"","text":"转载一篇对递归理解有帮助的小故事 对递归的理解的要点主要在于放弃! 放弃你对于理解和跟踪递归全程的企图，只理解递归两层之间的交接，以及递归终结的条件。 想象你来到某个热带丛林，意外发现了十层之高的汉诺塔。正当你苦苦思索如何搬动它时，林中出来一个土著，毛遂自荐要帮你搬塔。他名叫二傻，戴着一个草帽，草帽上有一个2字，号称会把一到二号盘搬到任意柱。 你灵机一动，问道：“你该不会有个兄弟叫三傻吧？” “对对，老爷你咋知道的？他会搬一到三号盘。“ ”那你去把他叫来，我不需要你了。“ 于是三傻来了，他也带着个草帽，上面有个3字。 你说：”三傻，你帮我把头三个盘子移到c柱吧。“ 三傻沉吟了一会，走进树林，你听见他大叫：”二傻，出来帮我把头两个盘子搬到C!“ 由于天气炎热你开始打瞌睡。朦胧中你没看见二傻是怎么工作的，二傻干完以后，走入林中大叫一声：“老三，我干完了!” 三傻出来，把三号盘从A搬到B，然后又去叫二傻：“老二，帮我把头两个盘子搬回A!” 余下的我就不多说了，总之三傻其实只搬三号盘，其他叫二傻出来干。最后一步是三傻把三号盘搬到C，然后呼叫二傻来把头两个盘子搬回C 事情完了之后你把三傻叫来，对他说：“其实你不知道怎么具体一步一步把三个盘子搬到C，是吧？” 三傻不解地说：“我不是把任务干完了？” 你说：“可你其实叫你兄弟二傻干了大部分工作呀？” 三傻说：“我外包给他和你屁相干？” 你问到：“二傻是不是也外包给了谁？“ 三傻笑了：“这跟我有屁相干？” 你苦苦思索了一夜，第二天，你走入林中大叫：“十傻，你在哪？” 一个头上带着10号草帽的人，十傻，应声而出：“老爷，你有什么事？” “我要你帮把1到10号盘子搬到C柱“ “好的，老爷。“十傻转身就向林内走。 “慢着，你该不是回去叫你兄弟九傻吧“ “老爷你怎么知道的？“ “所以你使唤他把头九个盘子搬过来搬过去，你只要搬几次十号盘就好了，对吗？“ “对呀！“ “你知不知道他是怎么干的？“ “这和我有屁相干？“ 你叹了一口气，决定放弃。十傻开始干活。树林里充满了此起彼伏的叫声：“九傻，来一下！“ “老八，到你了！““五傻！。。。“”三傻！。。。“”大傻！“ 你注意到大傻从不叫人，但是大傻的工作也最简单，他只是把一号盘搬来搬去。 若干年后，工作结束了。十傻来到你面前。你问十傻：“是谁教给你们这么干活的？“ 十傻说：“我爸爸。他给我留了这张纸条。” 他从口袋里掏出一张小纸条，上面写着：“照你帽子的号码搬盘子到目标柱。如果有盘子压住你，叫你上面一位哥哥把他搬走。如果有盘子占住你要去的柱子，叫你哥哥把它搬到不碍事的地方。等你的盘子搬到了目标，叫你哥哥把该压在你上面的盘子搬回到你上头。“ 你不解地问：“那大傻没有哥哥怎么办？“ 十傻笑了：“他只管一号盘，所以永远不会碰到那两个‘如果’，也没有盘子该压在一号上啊。” 但这时他忽然变了颜色，好像泄漏了巨大的机密。他惊慌地看了你一眼，飞快地逃入树林。 第二天，你到树林里去搜寻这十兄弟。他们已经不知去向。你找到了一个小屋，只容一个人居住，但是屋里有十顶草帽，写着一到十号的号码。 作者：Fireman A 链接：https://www.zhihu.com/question/24385418/answer/257751077","categories":[],"tags":[{"name":"recursion","slug":"recursion","permalink":"https://yuechuanx.top/tags/recursion/"}]},{"title":"<流畅的Python> 笔记：字典和集合","slug":"Python/fluent-python-notes-chap-03","date":"2019-12-24T08:08:14.000Z","updated":"2020-04-23T03:36:06.719Z","comments":true,"path":"Python/fluent-python-notes-chap-03/","link":"","permalink":"https://yuechuanx.top/Python/fluent-python-notes-chap-03/","excerpt":"","text":"字典这个数据结构活跃在所有 Python 程序的背后，即便你的源码里并没有直接用到它。 ——A. M. Kuchling dict 是 Python 语言的基石。 可散列对象需要实现 __hash__ 和 __eq__ 函数。 如果两个可散列对象是相等的，那么它们的散列值一定是一样的。 范映射类型 collections.abc 模块中有 Mapping 和 MutableMapping 两个抽象基类，起作用是为 dict 和其他类似的类型定义形式接口。 //pic 但非抽象映射类型一般不会直接继承这些抽象基类，而是直接对 dict 或 collections.User.Dict 进行扩展。 这些抽象基类的主要作用是作为形式化的文档，以及跟 isinstance 一起被用来判定某个数据是否为广义上的映射类型。 12my_dict = &#123;&#125;isinstance(my_dict, collections.abc.Mapping) True 用 instance 而不是用 type 是用来避免参数可能不是 dict 而是其他的映射类型 标准库的所有映射类型都是利用 dict 实现。 什么是可散列的数据类型？ 字典的提供了多种构造方法 link 1234567# 字典提供了很多种构造方法a = dict(one=1, two=2, three=3)b = &#123;'one': 1, 'two': 2, 'three': 3&#125; c = dict(zip(['one', 'two', 'three'], [1, 2, 3])) d = dict([('two', 2), ('one', 1), ('three', 3)]) e = dict(&#123;'three': 3, 'one': 1, 'two': 2&#125;)a == b == c == d == e True 字典推导 字典推导（dictcomp）可以从任何以键值对为元素的可迭代对象构建出字典 12345678DIAL_CODES = [ (86, 'China'), (91, 'India'), (1, 'United States')]country_code = &#123;country: code for code, country in DIAL_CODES&#125;country_code {'China': 86, 'India': 91, 'United States': 1} 常见的映射方法 dict、defaultdict、OrderedDict 的常见方法，后两个数据类型是 dict 的变种，位于 collections 模块内。 setdefault 处理找不到的键 d[k] 无法找到正确的键时，会抛出异常。 用 d.get(k, default) 来代替 d[k], 可以对找不到的键设置默认返回值。 12345678910111213141516171819202122232425\"\"\"03-dict-set/index0.py创建一个从单词到其出现频率的映射\"\"\"import sysimport reWORD_RE = re.compile(r'\\w+')index = &#123;&#125;with open(sys.argv[1], encoding='uft-8') as fp: for line_no, line in enumerate(fp, 1): for match in WORD_RE.finditer(line): word = match.group() column_no = match.start() + 1 location = (line_no, column_no) # 提取单词出现情况，如果没有出现过返回 [] occurences = index.get(word, []) occurences.append(location) index[word] = occurences# 以字符顺序打印结果for word in sorted(index, key=str.upper): print(word, index[word]) 123456789101112131415161718$ python index0.py zen.txta [(19, 48), (20, 53)]Although [(11, 1), (16, 1), (18, 1)]ambiguity [(14, 16)]and [(15, 23)]are [(21, 12)]aren [(10, 15)]at [(16, 38)]bad [(19, 50)]be [(15, 14), (16, 27), (20, 50)]beats [(11, 23)]Beautiful [(3, 1)]better [(3, 14), (4, 13), (5, 11), (6, 12), (7, 9), (8, 11), (17, 8), (18, 25)]break [(10, 40)]by [(1, 20)]cases [(10, 9)]complex [(5, 23)]... 使用 dict.setdefault 123456789101112131415161718192021222324252627\"\"\"03-dict-set/index.py创建一个从单词到其出现频率的映射\"\"\"import sysimport reWORD_RE = re.compile(r'\\w+')index = &#123;&#125;with open(sys.argv[1], encoding='uft-8') as fp: for line_no, line in enumerate(fp, 1): for match in WORD_RE.finditer(line): word = match.group() column_no = match.start() + 1 location = (line_no, column_no) # 注意这行与上面的区别 index.setdefault(word, []).append(location) # 效果等同于： # if key not in my_dict: # my_dict[key] = [] # my_dict[key].append(new_value)# 以字符顺序打印结果for word in sorted(index, key=str.upper): print(word, index[word]) 映射的弹性键查询 某个键不存在时，希望读取时能得到一个默认值，有两个方式： 通过 defaultdict 类型 自定义 dict 子类 defaultdict 处理找不到的键 123456789101112131415161718192021222324\"\"\"03-dict-set/index_default.py创建一个从单词到其出现频率的映射\"\"\"import sysimport reimport collectionsWORD_RE = re.compile(r'\\w+')index = collections.defaultdict(list) with open(sys.argv[1], encoding='utf-8') as fp: for line_no, line in enumerate(fp, 1): for match in WORD_RE.finditer(line): word = match.group() column_no = match.start()+1 location = (line_no, column_no) # index 如何没有 word 的记录， default_factory 会被调用，这里是创建一个空列表返回 index[word].append(location) # print in alphabetical orderfor word in sorted(index, key=str.upper): print(word, index[word]) defaultdict 里的 default_factory 只在 getitem 里调用。 实际上，上面的机制是通过特殊方法 missing 支持的。 missing 如果 dict 继承类提供了 missing 方法，且 getitem 遇到找不到键的情况是会自动调用它，而不是抛出异常 123456789101112131415161718192021222324252627282930313233343536373839404142class StrKeyDict0(dict): # &lt;1&gt; def __missing__(self, key): if isinstance(key, str): # &lt;2&gt; raise KeyError(key) return self[str(key)] # &lt;3&gt; def get(self, key, default=None): try: return self[key] # &lt;4&gt; except KeyError: return default # &lt;5&gt; def __contains__(self, key): return key in self.keys() or str(key) in self.keys() # &lt;6&gt;d = StrKeyDict0([('2', 'Two'), ('4', 'Four')])print(d['2'])print(d['4'])# d[1] errorprint(d.get('2'))print(d.get('4'))print(d.get(1, 'N/A'))# defaultdcit &amp; __missing__class mydefaultdict(dict): def __init__(self, value, value_factory): super().__init__(value) self._value_factory = value_factory def __missing__(self, key): # 要避免循环调用 # return self[key] self[key] = self._value_factory() return self[key]d = mydefaultdict(&#123;1:1&#125;, list)print(d[1])print(d[2])d[3].append(1)print(d) Two Four Two Four 'N/A' 字典的变种 此节总结了标准库 collections 模块中，除了 defaultdict 之外的不同映射类型 collections.OrderedDict collections.ChainMap 容纳多个不同的映射对象，然后在进行键查找操作时会从前到后逐一查找，直到被找到为止 collections.Counter collections.UserDict dict 的纯 Python 实现，让用户集成写子类的 1234567891011# UserDict# 定制化字典时，尽量继承 UserDict 而不是 dictfrom collections import UserDictclass mydict(UserDict): def __getitem__(self, key): print('Getting key', key) return super().__getitem__(key)d = mydict(&#123;1:1&#125;)print(d[1], d[2]) 12345678910111213# MyppingProxyType 用于构建 Mapping 的只读实例from types import MappingProxyTyped = &#123;1: 1&#125;d_proxy = MappingProxyType(d)print(d_proxy[1])try: d_proxy[1] = 1except Exception as e: print(repr(e))d[1] = 2print(d_proxy[1]) 12345678910111213141516# set 的操作# 子集 &amp; 真子集a, b = &#123;1, 2&#125;, &#123;1, 2&#125;print(a &lt;= b, a &lt; b)# discarda = &#123;1, 2, 3&#125;a.discard(3)print(a)# popprint(a.pop(), a.pop())try: a.pop()except Exception as e: print(repr(e)) 集合字面量 除空集之外，集合的字面量——{1}、{1, 2}，等等——看起来跟它的数学形式一模一样。如果是空集，那么必须写成 set() 的形式，否则它会变成一个 dict. 跟 list 一样，字面量句法会比 set 构造方法要更快且更易读。 集合和字典的实现 集合和字典采用散列表来实现： 先计算 key 的 hash, 根据 hash 的某几位（取决于散列表的大小）找到元素后，将该元素与 key 进行比较 若两元素相等，则命中 若两元素不等，则发生散列冲突，使用线性探测再散列法进行下一次查询。 这样导致的后果： 可散列对象必须支持 hash 函数； 必须支持 __eq__ 判断相等性； 若 a == b, 则必须有 hash(a) == hash(b)。 注：所有由用户自定义的对象都是可散列的，因为他们的散列值由 id() 来获取，而且它们都是不相等的。 字典的空间开销 由于字典使用散列表实现，所以字典的空间效率低下。使用 tuple 代替 dict 可以有效降低空间消费。 不过：内存太便宜了，不到万不得已也不要开始考虑这种优化方式，因为优化往往是可维护性的对立面。 往字典中添加键时，如果有散列表扩张的情况发生，则已有键的顺序也会发生改变。所以，不应该在迭代字典的过程各种对字典进行更改。 123456789101112# 字典中就键的顺序取决于添加顺序keys = [1, 2, 3]dict_ = &#123;&#125;for key in keys: dict_[key] = Nonefor key, dict_key in zip(keys, dict_): print(key, dict_key) assert key == dict_key# 字典中键的顺序不会影响字典比较","categories":[{"name":"Python","slug":"Python","permalink":"https://yuechuanx.top/categories/Python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://yuechuanx.top/tags/python/"}]},{"title":"Docker 高级特性","slug":"DevOps/docker-advanced-feature","date":"2019-12-19T07:43:32.000Z","updated":"2020-04-23T03:36:06.711Z","comments":true,"path":"DevOps/docker-advanced-feature/","link":"","permalink":"https://yuechuanx.top/DevOps/docker-advanced-feature/","excerpt":"","text":"本次分享给大家介绍Docker 的高级特性与相应的工具。 它们就是Docker 三剑客，Compose、Machine和Swarm Compose 介绍 Docker Compose 是Docker 官方编排（Orchestration）项目之一，负责快速的部署分布式应用。 Compose 定位是 「定义和运行多个Docker 容器的应用（Defining and running multi-container Docker applications）」 其前身是开源项目Fig。其代码目前在https://github.com/docker/compose 上开源。 安装 1pip install -U docker-compose 或 1sudo curl -L \"https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose 使用 Dockerfile 12345678910111213FROM python:3.7-slimWORKDIR /appCOPY . /appRUN pip install flask -i https://mirrors.aliyun.com/pypi/simple --trusted-host mirrors.aliyun.com EXPOSE 80ENV NAME WorldCMD [\"python\", \"app.py\"] a\u0010pp.py 123456789101112131415from flask import Flaskimport osimport socketapp = Flask(__name__)@app.route(\"/\")def hello(): html = \"&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;\" \\ \"&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;\" return html.format(name=os.getenv(\"NAME\", \"world\"), hostname=socket.gethostname())if __name__ == \"__main__\": app.run(host='0.0.0.0', port=80) docker-compose.yml 1234567891011121314version: \"3\"services: myapp: # build: . image: friendlyhello:v2 container_name: myapp ports: - \"5000:80\" environment: NAME: World redis: image: redis container_name: web 执行 docker-compose build 可生成镜像 执行 docker-compose up 启动容器运行 浏览器访问 命令说明 Machine 介绍 Docker Machine 是Docker 官方编排（Orchestration）项目之一，负责在多种平台上快速安装Docker环境。 使用 使用 virtualbox 类型的驱动，创建一台Docker 主机，命名为 manager。 1docker-machine create -d virtualbox manager 可以在创建时加上如下参数，来配置主机或者主机上的Docker。 1234567--engine-opt dns=114.114.114.114 配置Docker 的默认DNS--engine-registry-mirror https://registry.docker-cn.com 配置Docker 的仓库镜像--virtualbox-memory 2048 配置主机内存--virtualbox-cpu-count 2 配置主机CPU 更多参数请使用 docker-machine create —help 命令查看。 docker-machine ls 查看主机 docker-machine env manager 查看环境变量 切换 docker 主机 manager 为操作对象 1eval $(docker-machine env manager) 或者可以 ssh 登录到 docker 主机 1docker-machine ssh manager 命令说明 Swarm Swarm 是使用SwarmKit 构建的Docker 引擎内置（原生）的集群管理和编排工具。 使用 初始化集群 在上节介绍 docker-machine 的时候，我们创建了manager节点，而初始化集群需要在管理节点内执行 docker swarm init --advertise-addr=IP_ADDR 现在来创建两个工作节点worker1, worker2并加入集群 12345docker-machine create -d virtualbox worker1eval $(docker-machine env worker1)docker swarm join --token SWMTKN-1-59qol34ustn06wtqs6bnsgar4j170k5aj24weu5yegq8qp66cb-26aroyxll4zh9pl8cdwuo7vm4 192.168.99.101:2377 同理worker2 节点 进入manager 节点执行 docker node ls 由此，我们就得到了一个最小化的集群。 命令说明 疑难解答 在docker stack deploy –c docker-compose.yml 后，在docker ps 中无法看到端口映射？ 关于docker swarm mode 部署后端口的问题，可以使用docker service ls来查看端口是否正确暴露，因为此时是通过service来暴露的，并不是直接在container上暴露，所以此时用docker ps是看不到的，但暴露的端口依旧可以访问，这样实现和k8s里的service实现是有些相似的。 执行docker-compose -f docker-compose.yml up -d,返回 123Pulling myapp (friendlyhello:v2)...ERROR: Get https://registry-1.docker.i... net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers) ​ compose文件中如果已经build过，就用image直接指定这个image，注释掉build的指令。如果没有build过，就放开build指令，执行docker-compose的build它，当然也可以使用docker build来构建它。因为这一块在上一章节已经提到过，所以对于部分这次直接切入的同学可能会有疑惑。而到了docker stack时，已经不支持docker stack来build它了，需要统一使用docker build来构建镜像。","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://yuechuanx.top/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://yuechuanx.top/tags/docker/"}]},{"title":"Docker 基础使用","slug":"DevOps/docker-basic","date":"2019-12-19T07:43:19.000Z","updated":"2020-04-23T03:36:06.711Z","comments":true,"path":"DevOps/docker-basic/","link":"","permalink":"https://yuechuanx.top/DevOps/docker-basic/","excerpt":"","text":"安装 官方安装文档 Windows 安装 Debian/Ubuntu 12345678# 官方curl -sSL https://get.docker.com/ | sh# 阿里云curl -sSL http://acs-public-mirror.oss-cn-hangzhou.aliyuncs.com/docker-engine/internet | sh -# Daocloudcurl -sSL https://get.daocloud.io/docker | sh MacOS 1brew cask install docker 简单指令 查看 Docker 版本 版本信息：docker --version 配置信息： docker info help 信息： docker --help 运行第一个 Docker 镜像 docker run hello-world Docker 命令行工具 Docker CLI 指令分为两类，一类是 Management Commands，一类是镜像与容器 Commands。 你可以通过 docker –help 进行查看。 Docker 的命令格式为： docker [OPTIONS] COMMAND 这里我们选取常用的几个命令进行示例: docker pull : 从镜像仓库中拉取镜像 1234567# 从镜像仓库中拉取 Ubuntu 镜像docker pull Ubuntu# 运行 Ubuntu 镜像，分配 tty 进入交互模式# -i : interactive mode # -t: 分配 tty docker run –it ubuntu:latest Docker-CLI 与 Linux 语法具有相似性，例如： 12345678# 列出所有镜像docker image ls # 列出所有容器docker container ls# 查看容器状态docker container ps 如果你有 Linux 基础，那么相信对于 Docker-CLI 上手还是比较容易的。 TRY IT OUT #1 docker run -d -P daocloud.io/daocloud/dao-2048 -d 表示容器启动后在后台运行 用 docker ps 查看容器运行状态如图： 看到端口映射关系 0.0.0.0:32768-&gt;80。指宿主机的 32768 端口映射到容器的 80 端口 用浏览器打开 localhost:32768 Dockerfile 简介 Docker 可以从 Dockerfile 文件中构建镜像. Dockerfile 语法请参考：https://docs.docker.com/engine/reference/builder/ 下面列出一些最常用的语法： FROM : 这会从 Docker Hub 中拉取镜像，目的镜像基于所拉取的镜像进行搭建 WORKDIR: RUN, CMD, ENTRYPOINT, COPY, ADD以此为工作路径 COPY： 拷贝文件或文件夹到指定路径 RUN：镜像的最上层执行命令，执行后的结果会被提交，作为后续操作基于的镜像。 EXPOSE：暴露端口号 ENV： 设置环境变量 CMD [“executable”,“param1”,“param2”]：一个 Dockerfile 应该只有一处 CMD 命令，如果有多处，则最后一处有效。 #TRy it out #2 首先准备一个 Dockerfile 文件 与一个 app.py 文件 分别执行 中间打印输出 Docker 生成 container时会生成一个唯一的 container-id，在上图中 stop 命令用到了 container-id。当然，你可以使用 docker tag 命令对 container 进行重命名。 -p 4000:80 : 指的是从宿主机端口 4000 映射到容器端口 80 现在打开浏览器访问 localhost:4000: Reference docker 官方文档","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://yuechuanx.top/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://yuechuanx.top/tags/docker/"}]},{"title":"<流畅的Python> 笔记: 序列构成的数组","slug":"Python/fluent-python-notes-chap-02","date":"2019-12-16T12:27:00.000Z","updated":"2020-04-23T03:36:06.719Z","comments":true,"path":"Python/fluent-python-notes-chap-02/","link":"","permalink":"https://yuechuanx.top/Python/fluent-python-notes-chap-02/","excerpt":"","text":"你可能注意到了，之前提到的几个操作可以无差别地应用于文本、列表和表格上。 我们把文本、列表和表格叫作数据火车……FOR 命令通常能作用于数据火车上。 ——Geurts、Meertens 和 Pemberton ABC Programmer’s Handbook 内置序列类型概览 容器序列 list、tuple 和 collections.deque 这些序列能存放不同类型的数据。 扁平序列 str、bytes、bytearray、memoryview 和 array.array，这类序列只能容纳一种类型。 容器序列存放的是它们所包含的任意类型的对象的引用，而扁平序列里存放的是值而不是引用。换句话说，扁平序列其实是一段连续的内存空间。由此可见扁平序列其实更加紧凑，但是它里面只能存放诸如字符、字节和数值这种基础类型。 序列类型还能按照能否被修改来分类。 可变序列 list、bytearray、array.array、collections.deque 和 memoryview。 不可变序列 tuple、str 和 bytes 列表推导和生成器表达式 列表推导和可读性 列表推导是构建列表(list)的快捷方式，生成器表达式用来穿件其他任何类型的序列。 12345678910# 比较两段代码symbols = 'abcde'# 1codes = []for symbol in symbols: codes.append(ord(symbol)) print(codes)# 2codes = [ord(symbol) for symbol in symbols]print(codes) 列表推导能够提升可读性。 只用列表推导来创建新的列表，并尽量保持简短（不要超过一行） 列表推导同 filter 和 map 的比较 1234567symbols = 'abcde'beyond_ascii = [ord(s) for s in symbols if ord(s) &gt; 100]print(beyond_ascii)beyond_ascii = list(filter(lambda c: c &gt; 100, map(ord, symbols)))print(beyond_ascii) [101] [101] 笛卡尔积 1234567891011colors = ['black', 'white'] sizes = ['S', 'M', 'L']tshirts = [(color, size) for color in colors for size in sizes]print(tshirts)tshirts = [(color, size) for size in sizes for color in colors]print(tshirts)# 注意顺序是依照 for-loop [('black', 'S'), ('black', 'M'), ('black', 'L'), ('white', 'S'), ('white', 'M'), ('white', 'L')] [('black', 'S'), ('white', 'S'), ('black', 'M'), ('white', 'M'), ('black', 'L'), ('white', 'L')] 生成器表达式 列表推导与生成器表达式的区别： 生成器表达式遵守实现了迭代器接口，可以逐个地产出元素。列表推导是先建立一个完整的列表，再将这个列表传递到构造函数里。 语法上近似，方括号换成圆括号 12345# symbols = 'abcde'print(tuple(ord(symbol) for symbol in symbols))import arrayprint(array.array('I', (ord(symbol) for symbol in symbols))) 如果生成器表达式是一个函数调用过程中的唯一参数，则不需要额外括号 生成器会在 for-loop 运行时才生成一个组合。逐个产出元素 12345colors = ['black', 'white'] sizes = ['S', 'M', 'L']for tshirt in ('%s %s' %(c, s) for c in colors for s in sizes): print(tshirt) black S black M black L white S white M white L 元祖不仅仅是不可变的列表 元祖与记录 元祖是对数据的记录 元祖的位置信息为数据赋予了意义。对元祖内元素排序，位置信息将丢失 12345678910111213# LA 国际机场经纬度lax_coordinates = (33.9425, -118.408056)# 城市，年份，人口（单位：百万），人口变化（单位：百分比），面积city, year, pop, chg, area = ('Tokyo', 2003, 32450, 0.66, 8014)# country_code, passport numbertraveler_ids = [('USA', '31195855'), ('BBA', 'CE342567'), ('ESP', 'XDA205856')]for passport in sorted(traveler_ids): print('%s%s' % passport)# 拆包（unpacking）for country, _ in traveler_ids: print(country) BBACE342567 ESPXDA205856 USA31195855 USA BBA ESP 元祖拆包 平行赋值 12345lax_coordinates = (33.9425, -118.408056)# 元祖拆包latitude, longtitude = lax_coordinatesprint(latitude)print(longtitude) 33.9425 -118.408056 交换变量值，不使用中间变量 12345a = 3b = 4b, a = a, bprint(a)print(b) 4 3 * 运算符，把一个可迭代对象拆开作为函数参数 12345678divmod(20, 8)t = (20, 8)divmod(*t)quotient, remainder = divmod(*t)print(quotient)print(remainder) 2 4 函数用元祖形式返回多个值 _ 用作占位符，可以用来处理不需要的数据 1234import os_, filename = os.path.split('/home/xiao/.ssh/id_rsa.pub')print(filename) id_rsa.pub 用* 处理省下的元素 123456789101112131415a, b, *rest = range(5)print(a, b, rest)a, b, *rest = range(3)print(a, b, rest)a, b, *rest = range(2)print(a, b, rest)# * 前缀只能用在一个变量前，该变量可出现在赋值表达式中任意位置a, *body, c, d = range(5)print(a, body, c, d)*head, b, c, d = range(5)print(head, b, c, d) 0 1 [2, 3, 4] 0 1 [2] 0 1 [] 0 [1, 2] 3 4 [0, 1] 2 3 4 嵌套元祖拆包 12345678910111213metro_areas = [ ('Tokyo', 'JP', 36.933, (35.689722, 139.691667)), # &lt;1&gt; ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)), ('Mexico City', 'MX', 20.142, (19.433333, -99.133333)), ('New York-Newark', 'US', 20.104, (40.808611, -74.020386)), ('Sao Paulo', 'BR', 19.649, (-23.547778, -46.635833)),]print('&#123;:15&#125; | &#123;:^9&#125; | &#123;:^9&#125;'.format('', 'lat.', 'long.'))fmt = '&#123;:15&#125; | &#123;:9.4f&#125; | &#123;:9.4f&#125;'for name, cc, pop, (latitude, longitude) in metro_areas: # &lt;2&gt; if longitude &lt;= 0: # &lt;3&gt; print(fmt.format(name, latitude, longitude)) | lat. | long. Mexico City | 19.4333 | -99.1333 New York-Newark | 40.8086 | -74.0204 Sao Paulo | -23.5478 | -46.6358 将元祖作为记录仍缺少一个功能：字段命名 具名元祖(numedtuple) collections.namedtuple 是一个工厂函数，用来构建带字段名的元祖和一个有名字的 namedtuple 构建的类的实例所消耗的内存和元祖是一样的，因为字段名都存在对应的类里。 实例和普通的对象实例小一点，因为 Python 不会用 __dict__ 存放实例的属性 12345678from collections import namedtuple# 需要两个参数，类名和类各个字段的名字City = namedtuple('City', 'name country population coordinates')tokyo = City('Tokyo', 'JP', 36.933, (35.689722, 129.691667))print(tokyo)print(tokyo.population)print(tokyo.coordinates) City(name='Tokyo', country='JP', population=36.933, coordinates=(35.689722, 129.691667)) 36.933 (35.689722, 129.691667) namedtuple 除了从普通元祖继承的属性外，还有一些专有属性。 常用的有： _fields 类属性 _make(iterable) 类方法 _asdict() 实例方法 12345678print(City._fields)LatLong = namedtuple('LatLong', 'lat long')delhi_data = ('Delhi NCR', 'IN', 21.935, LatLong(28.613889, 77.208889))delhi = City._make(delhi_data)print(delhi._asdict())for key, value in delhi._asdict().items(): print(key + ':', value) ('name', 'country', 'population', 'coordinates') OrderedDict([('name', 'Delhi NCR'), ('country', 'IN'), ('population', 21.935), ('coordinates', LatLong(lat=28.613889, long=77.208889))]) name: Delhi NCR country: IN population: 21.935 coordinates: LatLong(lat=28.613889, long=77.208889) 作为不可变列表的元祖 对比列表和元祖的方法 // 插入表格 结论： 除了增减元素相关的方法和__reversed__ 外，元祖支持列表的其他所有方法。 切片 在 Python 里, 列表（list），元祖（tuple）和字符串（str）这类序列类型都支持切片操作 为什么切片的区间会忽略最后一个元素 Python 以0 作为起始下标 当只有后一个位置信息时，可以快速导出切片和区间的元素数量 当起止位置信息课件是，可以快速计算出切片和区间的长度 （stop - start） 可利用任意一个下标把序列分割成不重叠的两部分。my_list[:x] my_list[x:] 123### 对对象进行切片- 可以通过 s[a:b:c] 的形式对 s 在 a 和 b 区间以 c 为间隔取值 1234s = 'bicycle'print(s[::3])print(s[::-1])print(s[::-2]) bye elcycib eccb 多维切片和省略 [] 运算符可以使用以逗号分开的多个索引或切片。 如 a[i, j]，a[m:n, k:1]得到二维切片 要正确处理[] 运算符，对象的特殊方法 __getitem__，__setitem__ 需要以元祖的形式来接受 a[i, j]的索引。 给切片赋值 切片放在赋值语句左边，或作为 del 操作对象，可以对序列进行嫁接、切除或就地修改 12345678910111213l = list(range(10))print(l)l[2:5] = [20, 30]print(l)del l[5:7]print(l)l[3::2] = [11, 22]print(l)# l[2:5] = 100 WRONG [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0, 1, 20, 30, 5, 6, 7, 8, 9] [0, 1, 20, 30, 5, 8, 9] [0, 1, 20, 11, 5, 22, 9] 对序列使用 + 和 * + 和 * 不修改原有的操作对象，而是构建一个新的序列 1234l = [1, 2, 3]print(l * 5)print(5 * 'abcd') [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3] abcdabcdabcdabcdabcd 建立由列表组成的列表 a * n，如果在序列 a 中存在对其他可变变量的引用的话，得到的序列中包含的是 n 个对指向同一地址的引用 1234567891011121314151617181920board = [['_'] * 3 for i in range(3)]# 换一种形式# board = []# for i in range(3):# row = ['_'] * 3# board.append(row)print(board)board[1][2] = 'X'print(board) # weird_board = [['_'] * 3] * 3# 换一种形式weird_board = []row = ['_'] * 3for i in range(3): weird_board.append(row)weird_board[1][2] = 'O'# 会发现 3 个指向同一列表的引用print(weird_board) [['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']] [['_', '_', '_'], ['_', '_', 'X'], ['_', '_', '_']] [['_', '_', 'O'], ['_', '_', 'O'], ['_', '_', 'O']] 序列的增量赋值 +=、*= += 背后的特殊方法是 __iadd__ 方法，没有则退一步调用 __add__ 同理 *= 的特殊方法是 __imul__ 1234567891011121314l = [1, 2, 3]print(id(l))l *= 2print(l)# 列表ID 无改变print(id(l))t = (1, 2, 3)print(id(t))t *= 2print(t)# 新元祖被创建print(id(t)) 4534358344 [1, 2, 3, 1, 2, 3] 4534358344 4536971408 (1, 2, 3, 1, 2, 3) 4546754024 list.sort方法和内置函数sorted list.sort 会就地排序列表，方法返回值为 None sorted 会新建一个列表作为返回值 两个方法都有 reverse 和 key 作为可选的关键字参数 reserve 为 True 时，降序输出。默认为 false key 只有一个参数的函数，将被用在序列的每一个元素上，其结果作为排序算法依赖的对比关键字 用bisect管理已排序的序列 bisect 模块有两个主要函数： bisect insort 都利用二分查找法来在有序序列中查找或插入人元素 用 bisect 来搜索 bisect(haystack, needle) 默认为升序，haystack 需要保持有序。 使用方法： bisect(index, needle) 查找位置 index，再使用 haystack.insert(index, needle) 插入新值 也可以用 insort 来一步到位，且后者速度更快 123456789101112131415161718192021222324252627# BEGIN BISECT_DEMOimport bisectimport sysHAYSTACK = [1, 4, 5, 6, 8, 12, 15, 20, 21, 23, 23, 26, 29, 30]NEEDLES = [0, 1, 2, 5, 8, 10, 22, 23, 29, 30, 31]ROW_FMT = '&#123;0:2d&#125; @ &#123;1:2d&#125; &#123;2&#125;&#123;0:&lt;2d&#125;'def demo(bisect_fn): for needle in reversed(NEEDLES): position = bisect_fn(HAYSTACK, needle) # &lt;1&gt; offset = position * ' |' # &lt;2&gt; print(ROW_FMT.format(needle, position, offset)) # &lt;3&gt;if __name__ == '__main__': if sys.argv[-1] == 'left': # &lt;4&gt; bisect_fn = bisect.bisect_left else: bisect_fn = bisect.bisect print('DEMO:', bisect_fn.__name__) # &lt;5&gt; print('haystack -&gt;', ' '.join('%2d' % n for n in HAYSTACK)) demo(bisect_fn)# END BISECT_DEMO DEMO: bisect_right haystack -&gt; 1 4 5 6 8 12 15 20 21 23 23 26 29 30 31 @ 14 | | | | | | | | | | | | | |31 30 @ 14 | | | | | | | | | | | | | |30 29 @ 13 | | | | | | | | | | | | |29 23 @ 11 | | | | | | | | | | |23 22 @ 9 | | | | | | | | |22 10 @ 5 | | | | |10 8 @ 5 | | | | |8 5 @ 3 | | |5 2 @ 1 |2 1 @ 1 |1 0 @ 0 0 Array 虽然列表既灵活又简单，但面对各类需求时，我们可能会有更好的选择。比如，要存放 1000 万个浮点数的话，数组（array）的效率要高得多，因为数组在背后存的并不是 float 对象，而是数字的机器翻译，也就是字节表述。这一点就跟 C 语言中的数组一样。再比如说，如果需要频繁对序列做先进先出的操作，deque（双端队列）的速度应该会更快。 array.tofile 和 fromfile 可以将数组以二进制格式写入文件，速度要比写入文本文件快很多，文件的体积也小。 另外一个快速序列化数字类型的方法是使用 pickle（https://docs.python.org/3/library/pickle.html）模块。pickle.dump 处理浮点数组的速度几乎跟array.tofile 一样快。不过前者可以处理几乎所有的内置数字类型，包含复数、嵌套集合，甚至用户自定义的类。前提是这些类没有什么特别复杂的实现。 array 具有 type code 来表示数组类型：具体可见 array 文档. memoryview memoryview.cast 的概念跟数组模块类似，能用不同的方式读写同一块内存数据，而且内容字节不会随意移动。 12345678910111213141516171819202122232425import arrayarr = array.array('h', [1, 2, 3])memv_arr = memoryview(arr)# 把 signed short 的内存使用 char 来呈现memv_char = memv_arr.cast('B') print('Short', memv_arr.tolist())print('Char', memv_char.tolist())memv_char[1] = 2 # 更改 array 第一个数的高位字节# 0x1000000001print(memv_arr.tolist(), arr)print('-' * 10)bytestr = b'123'# bytes 是不允许更改的try: bytestr[1] = '3'except TypeError as e: print(repr(e))memv_byte = memoryview(bytestr)print('Memv_byte', memv_byte.tolist())# 同样这块内存也是只读的try: memv_byte[1] = 1except TypeError as e: print(repr(e)) Deque collections.deque 是比 list 效率更高，且线程安全的双向队列实现。 除了 collections 以外，以下 Python 标准库也有对队列的实现： queue.Queue (可用于线程间通信) multiprocessing.Queue (可用于进程间通信) asyncio.Queue heapq","categories":[{"name":"Python","slug":"Python","permalink":"https://yuechuanx.top/categories/Python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://yuechuanx.top/tags/python/"}]},{"title":"Markdown 语法总结","slug":"markdown-syntax","date":"2019-12-11T08:03:39.000Z","updated":"2020-04-23T03:36:06.721Z","comments":true,"path":"markdown-syntax/","link":"","permalink":"https://yuechuanx.top/markdown-syntax/","excerpt":"","text":"斜体和粗体 1234*斜体*或_斜体_**粗体*****加粗斜体***~~删除线~~ 斜体或_斜体_ 粗体 加粗斜体 删除线 分级标题 123456# 一级标题## 二级标题###三级标题### 四级标题#### 五级标题##### 六级标题 一级标题字号最大，依级递减。 超链接 Markdown 支持两种形式的链接语法： 行内式和参考式两种形式，行内式一般使用较多。 行内式 语法说明：[文字](链接) []里写链接文字，()里写链接地址, ()中的”“中可以为链接指定title属性，title属性可加可不加。title属性的效果是鼠标悬停在链接上会出现指定的 title文字。链接地址与链接标题前有一个空格。 123欢迎来到[Django](https://docs.djangoproject.com/zh-hans/3.0/)欢迎来到[Django](https://docs.djangoproject.com/zh-hans/3.0/ “Django”) 欢迎来到Django 欢迎来到Django 参考式 参考式超链接一般用在学术论文上面，或者另一种情况，如果某一个链接在文章中多处使用，那么使用引用 的方式创建链接将非常好，它可以让你对链接进行统一的管理。 语法说明： [文字][链接文字] 参考式链接分为两部分，文中的写法 [链接文字][链接标记]，在文本的任意位置添加[链接标记]:链接地址 “链接标题”，链接地址与链接标题前有一个空格。 如果链接文字本身可以做为链接标记，你也可以写成[链接文字][] [链接文字]：链接地址的形式，见代码的最后一行。 12345我经常去的几个网站[Google][1],[技术博客1][2],[技术博客2][]。[1]:http://www.google.com[2]:https://yuechuanx.top \"技术博客\"[技术博客]:https://yuechuanx.top/ 我经常去的几个网站Google,Demi的随笔和技术空间,[Demi的随笔和技术空间][]。 我经常去的几个网站Google,技术博客1,[技术博客2][]。 自动链接 语法说明： Markdown 支持以比较简短的自动链接形式来处理网址和电子邮件信箱，只要是用&lt;&gt;包起来， Markdown 就会自动把它转成链接。一般网址的链接文字就和链接地址一样，例如： 12&lt;http://example.com/&gt;&lt;address@example.com&gt; http://example.com/ address@example.com 锚点 网页中，锚点其实就是页内超链接，也就是链接本文档内部的某些元素，实现当前页面中的跳转。比如我这里写下一个锚点，点击回到目录，就能跳转到目录。 在目录中点击这一节，就能跳过来。还有下一节的注脚。这些根本上都是用锚点来实现的。 注意： Markdown Extra 只支持在标题后插入锚点，其它地方无效。 Leanote 编辑器右侧显示效果区域暂时不支持锚点跳转，所以点来点去发现没有跳转不必惊慌，但是你发布成笔记或博文后是支持跳转的。 123## 跳转测试&#123;#index&#125;跳转到[跳转测试](#index) 列表 无序列表 使用 *，+，- 表示无序列表。 123- 无序列表项 一- 无序列表项 二- 无序列表项 三 无序列表项 一 无序列表项 二 无序列表项 三 有序列表 有序列表则使用数字接着一个英文句点。 1231. 有序列表项 一2. 有序列表项 二3. 有序列表项 三 有序列表项 一 有序列表项 二 有序列表项 三 定义型列表 语法说明： 定义型列表由名词和解释组成。一行写上定义，紧跟一行写上解释。解释的写法:紧跟一个缩进(Tab) 1234567代码块 1 Markdown: 轻量级文本标记语言，可以转换成html，pdf等格式（左侧有一个可见的冒号和四个不可见的空格）代码块 2: 这是代码块的定义（左侧有一个可见的冒号和四个不可见的空格） 代码块（左侧有八个不可见的空格） view 代码块 1 Markdown 轻量级文本标记语言，可以转换成html，pdf等格式（左侧有一个可见的冒号和四个不可见的空格） 代码块 2 这是代码块的定义（左侧有一个可见的冒号和四个不可见的空格） 代码块（左侧有八个不可见的空格） 列表缩进 语法说明： 列表项目标记通常是放在最左边，但是其实也可以缩进，最多 3 个空格，项目标记后面则一定要接着至少一个空格或制表符。 1234567* 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ * 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。 但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！ 悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。 view 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。 那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。 但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！ 悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。 包含段落的列表 语法说明： 列表项目可以包含多个段落，每个项目下的段落都必须缩进 4 个空格或是 1 个制表符（显示效果与代码一致）： 123456789* 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。 但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！* 悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。 view 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。 那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。 但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！ 悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。 包含引用的列表 语法说明： 如果要在列表项目内放进引用，那 &gt; 就需要缩进： 123* 阅读的方法: &gt; 打开书本。 &gt; 打开电灯。 view 阅读的方法: 打开书本。 打开电灯。 包含代码区块的引用 语法说明： 如果要放代码区块的话，该区块就需要缩进两次，也就是 8 个空格或是 2 个制表符： 一个特殊情况 在特殊情况下，项目列表很可能会不小心产生，像是下面这样的写法： 11986. What a great season. 会显示成： What a great season. 换句话说，也就是在行首出现数字-句点-空白，要避免这样的状况，你可以在句点前面加上反斜杠： 11986\\. What a great season. 才会正常显示成： 1986. What a great season. 引用 语法说明： 引用需要在被引用的文本前加上&gt;符号。 123456&gt; 这是一个有两段文字的引用,无意义的占行文字1.无意义的占行文字2.&gt; 无意义的占行文字3.无意义的占行文字4. view 这是一个有两段文字的引用, 无意义的占行文字1. 无意义的占行文字2. 无意义的占行文字3. 无意义的占行文字4. 引用的多层嵌套 区块引用可以嵌套（例如：引用内的引用），只要根据层次加上不同数量的 &gt; ： 12345&gt;&gt;&gt; 请问 Markdwon 怎么用？ - 小白&gt;&gt; 自己看教程！ - 愤青&gt; 教程在哪？ - 小白 请问 Markdwon 怎么用？ - 小白 自己看教程！ - 愤青 教程在哪？ - 小白 引用其它要素 引用的区块内也可以使用其他的 Markdown 语法，包括标题、列表、代码区块等： 123456&gt; 1. 这是第一行列表项。&gt; 2. 这是第二行列表项。&gt; &gt; 给出一些例子代码：&gt; &gt; return shell_exec(\"echo $input | $markdown_script\"); 这是第一行列表项。 这是第二行列表项。 给出一些例子代码： return shell_exec(&quot;echo $input | $markdown_script&quot;); 插入图像 图片的创建方式与超链接相似，而且和超链接一样也有两种写法，行内式和参考式写法。 语法中图片Alt的意思是如果图片因为某些原因不能显示，就用定义的图片Alt文字来代替图片。 图片Title则和链接中的Title一样，表示鼠标悬停与图片上时出现的文字。 Alt 和 Title 都不是必须的，可以省略，但建议写上。 行内式 语法说明：![图片Alt](图片地址 “图片Title”) 12美丽风景： ![美丽风景](https://yuhongjun.github.io/assets/media/scenery.jpeg \"美丽风景\") view 美丽风景： 参考式\u0010 语法说明： 在文档要插入图片的地方写![图片Alt][标记] 在文档的最后写上[标记]:图片地址 “Title” 123![美丽风景](https://yuhongjun.github.io/assets/media/scenery.jpeg \"美丽风景\")[scenery]:https://yuhongjun.github.io/assets/media/scenery.jpeg \"美丽风景\" view 内容目录 在段落中填写 {toc} 以显示全文内容的目录结构。 效果参见最上方的目录 注脚 语法说明： 在需要添加注脚的文字后加上脚注名字[^注脚名字],称为加注。 然后在文本的任意位置(一般在最后)添加脚注，脚注前必须有对应的脚注名字。 注意：经测试注脚与注脚之间必须空一行，不然会失效。成功后会发现，即使你没有把注脚写在文末，经Markdown转换后，也会自动归类到文章的最后。 1234567使用 Markdown[^1]可以效率的书写文档, 直接转换成 HTML[^2], 你可以使用 Leanote[^Le] 编辑器进行书写。[^1]:Markdown是一种纯文本标记语言[^2]:HyperText Markup Language 超文本标记语言[^Le]:开源笔记平台，支持Markdown和笔记直接发为博文 view 使用 Markdown[1]可以效率的书写文档, 直接转换成 HTML[2], 你可以使用 Leanote[3] 编辑器进行书写。 注：脚注自动被搬运到最后面，请到文章末尾查看，并且脚注后方的链接可以直接跳转回到加注的地方。 LaTeX 公式 $ 表示行内公式： 1质能守恒方程可以用一个很简洁的方程式 $E=mc^2$ 来表达。 view 质能守恒方程可以用一个很简洁的方程式 E=mc2E=mc^2E=mc2 来表达。 $$ 表示整行公式： 123$$\\sum_&#123;i=1&#125;^n a_i=0$$$$f(x_1,x_x,\\ldots,x_n) = x_1^2 + x_2^2 + \\cdots + x_n^2 $$$$\\sum^&#123;j-1&#125;_&#123;k=0&#125;&#123;\\widehat&#123;\\gamma&#125;_&#123;kj&#125; z_k&#125;$$ ∑i=1nai=0\\sum_{i=1}^n a_i=0 i=1∑n​ai​=0 f(x1,xx,…,xn)=x12+x22+⋯+xn2f(x_1,x_x,\\ldots,x_n) = x_1^2 + x_2^2 + \\cdots + x_n^2 f(x1​,xx​,…,xn​)=x12​+x22​+⋯+xn2​ ∑k=0j−1γ^kjzk\\sum^{j-1}_{k=0}{\\widehat{\\gamma}_{kj} z_k} k=0∑j−1​γ​kj​zk​ 访问 MathJax 参考更多使用方法。 流程图 1234567891011121314st=&gt;start: Start|past:&gt;https://yuhongjun.github.io[blank]e=&gt;end: End:&gt;https://yuhongjun.github.ioop1=&gt;operation: My Operation|pastop2=&gt;operation: Stuff|currentsub1=&gt;subroutine: My Subroutine|invalidcond=&gt;condition: Yesor No?|approved:&gt;https://yuhongjun.github.ioc2=&gt;condition: Good idea|rejectedio=&gt;inputoutput: catch something...|requestst-&gt;op1(right)-&gt;condcond(yes, right)-&gt;c2cond(no)-&gt;sub1(left)-&gt;op1c2(yes)-&gt;io-&gt;ec2(no)-&gt;op2-&gt;e 更多语法参考：流程图语法参考 表格 语法说明： 不管是哪种方式，第一行为表头，第二行分隔表头和主体部分，第三行开始每一行为一个表格行。 列于列之间用管道符|隔开。原生方式的表格每一行的两边也要有管道符。 第二行还可以为不同的列指定对齐方向。默认为左对齐，在-右边加上:就右对齐。 简单方式写表格： 12345学号|姓名|分数-|-|-小明|男|75小红|女|79小陆|男|92 2.原生方式写表格： 12345|学号|姓名|分数||-|-|-||小明|男|75||小红|女|79||小陆|男|92| 3.为表格第二列指定方向： 1234产品|价格-|-:Leanote 高级账号|60元/年Leanote 超级账号|120元/年 view 简单方式写表格： 学号 姓名 分数 小明 男 75 小红 女 79 小陆 男 92 2.原生方式写表格： 学号 姓名 分数 小明 男 75 小红 女 79 小陆 男 92 3.为表格第二列指定方向： 产品 价格 Leanote 高级账号 60元/年 Leanote 超级账号 120元/年 分隔线 你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线： 123456789* * *********- - ---------------------------------------- 显示效果都一样 代码 对于程序员来说这个功能是必不可少的，插入程序代码的方式有两种，一种是利用缩进(Tab), 另一种是利用 ` 符号（一般在ESC键下方）包裹代码。 语法说明： 插入行内代码，即插入一个单词或者一句代码的情况，使用code这样的形式插入。 插入多行代码，可以使用缩进或者“code “,具体看示例。 注意： 缩进式插入前方必须有空行 行内式 1C语言里的函数 `scanf()` 怎么使用？ view C语言里的函数 scanf() 怎么使用？ 缩进式多行代码 缩进 4 个空格或是 1 个制表符 一个代码区块会一直持续到没有缩进的那一行（或是文件结尾）。 12345#include &lt;stdio.h&gt;int main(void)&#123; printf(\"Hello world\\n\");&#125; view #include &lt;stdio.h&gt; int main(void) { printf(&quot;Hello world\\n&quot;); } 包裹多行代码 12345678&lt;!-- 用 ``` 或 ~~~ 包裹多行代码 --&gt;` ` `#include &lt;stdio.h&gt;int main(void)&#123; printf(\"Hello world\\n\");&#125;、、、 HTML 原始码 在代码区块里面， &amp; 、 &lt; 和 &gt; 会自动转成 HTML 实体，这样的方式让你非常容易使用 Markdown 插入范例用的 HTML 原始码，只需要复制贴上，剩下的 Markdown 都会帮你处理，例如： 第一个例子： 123&lt;div class=\"footer\"&gt; © 2016 ***&lt;/div&gt; view © 2016 *** chart st=>start: Start|past:>https://yuhongjun.github.io[blank] e=>end: End:>https://yuhongjun.github.io op1=>operation: My Operation|past op2=>operation: Stuff|current sub1=>subroutine: My Subroutine|invalid cond=>condition: Yes or No?|approved:>https://yuhongjun.github.io c2=>condition: Good idea|rejected io=>inputoutput: catch something...|request st->op1(right)->cond cond(yes, right)->c2 cond(no)->sub1(left)->op1 c2(yes)->io->e c2(no)->op2->e{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-0-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-0-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-0\", options); Markdown是一种纯文本标记语言 ↩︎ HyperText Markup Language 超文本标记语言 ↩︎ 开源笔记平台，支持Markdown和笔记直接发为博文 ↩︎","categories":[],"tags":[{"name":"markdown","slug":"markdown","permalink":"https://yuechuanx.top/tags/markdown/"}]},{"title":"<流畅的Python> 笔记: Python 数据类型","slug":"Python/fluent-python-notes-chap-01","date":"2019-12-11T06:21:56.000Z","updated":"2020-04-23T03:36:06.718Z","comments":true,"path":"Python/fluent-python-notes-chap-01/","link":"","permalink":"https://yuechuanx.top/Python/fluent-python-notes-chap-01/","excerpt":"","text":"Guido 对语言设计美学的深入理解让人震惊。我认识不少很不错的编程语言设计者，他们设计出来的东西确实很精彩，但是从来都不会有用户。Guido 知道如何在理论上做出一定妥协，设计出来的语言让使用者觉得如沐春风，这真是不可多得。 ——Jim Hugunin Jython 的作者，AspectJ 的作者之一，.NET DLR 架构师 Python 最好的品质之一是一致性：你可以轻松理解 Python 语言，并通过 Python 的语言特性在类上定义规范的接口，来支持 Python 的核心语言特性，从而写出具有“Python 风格”的对象。 Python 解释器在碰到特殊的句法时，会使用特殊方法（我们称之为魔术方法）去激活一些基本的对象操作。 __getitem__ 以双下划线开头的特殊方法，称为 dunder-getitem。特殊方法也称为双下方法(dunder-method) 如 my_c[key] 语句执行时，就会调用 my_c.__getitem__ 函数。这些特殊方法名能让你自己的对象实现和支持一下的语言构架，并与之交互： 迭代 集合类 属性访问 运算符重载 函数和方法的调用 对象的创建和销毁 字符串表示形式和格式化 管理上下文（即 with 块） 实现一个 Pythonic 的牌组 12345678910111213141516171819202122# 通过实现魔术方法，来让内置函数支持你的自定义对象# https://github.com/fluentpython/example-code/blob/master/01-data-model/frenchdeck.pyimport collectionsimport randomCard = collections.namedtuple('Card', ['rank', 'suit'])class FrenchDeck: ranks = [str(n) for n in range(2, 11)] + list('JQKA') suits = 'spades diamonds clubs hearts'.split() def __init__(self): self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] def __len__(self): return len(self._cards) def __getitem__(self, position): return self._cards[position] deck = FrenchDeck() 可以容易地获得一个纸牌对象 12beer_card = Card('7', 'diamonds')print(beer_card) 和标准 Python 集合类型一样，使用 len() 查看一叠纸牌有多少张 123deck = FrenchDeck()# 实现 __len__ 以支持下标操作print(len(deck)) 可选取特定一张纸牌，这是由 __getitem__ 方法提供的 123# 实现 __getitem__ 以支持下标操作print(deck[1])print(deck[5::13]) 随机抽取一张纸牌，使用 python 内置函数 random.choice 123from random import choice# 可以多运行几次观察choice(deck) 实现特殊方法的两个好处： 对于标准操作有固定命名 更方便利用 Python 标准库 __getitem__ 方法把 [] 操作交给了 self._cards 列表，deck 类自动支持切片操作 12deck[12::13]deck[:3] 同时 deck 类支持迭代 123456for card in deck: print(card) # 反向迭代for card in reversed(deck): print(card) 迭代通常是隐式的，如果一个集合没有实现 __contains__ 方法，那么 in 运算符会顺序做一次迭代搜索。 12Card('Q', 'hearts') in deck Card('7', 'beasts') in deck False 进行排序，排序规则： 2 最小，A最大。花色 黑桃 &gt; 红桃 &gt; 方块 &gt; 梅花 1card.rank 'A' 123456789suit_values = dict(spades=3, hearts=2, diamonds=1, clubs=0)def spades_high(card): rank_value = FrenchDeck.ranks.index(card.rank) return rank_value * len(suit_values) + suit_values[card.suit]for card in sorted(deck, key=spades_high): print(card) FrenchDeck 继承了 object 类。通过 __len__, __getitem__ 方法，FrenchDeck和 Python 自有序列数据类型一样，可体现 Python 核心语言特性（如迭代和切片）， Python 支持的所有魔术方法，可以参见 Python 文档 Data Model 部分。 比较重要的一点：不要把 len，str 等看成一个 Python 普通方法：由于这些操作的频繁程度非常高，所以 Python 对这些方法做了特殊的实现：它可以让 Python 的内置数据结构走后门以提高效率；但对于自定义的数据结构，又可以在对象上使用通用的接口来完成相应工作。但在代码编写者看来，len(deck) 和 len([1,2,3]) 两个实现可能差之千里的操作，在 Python 语法层面上是高度一致的。 如何使用特殊方法 特殊方法的存在是为了被 Python 解释器调用 除非大量元编程，通常代码无需直接使用特殊方法 通过内置函数来使用特殊方法是最好的选择 模拟数值类型 实现一个二维向量（Vector）类 123456789101112131415161718192021222324252627282930313233343536from math import hypotclass Vector: def __init__(self, x=0, y=0): self.x = x self.y = y def __repr__(self): return 'Vector(%r, %r)' % (self.x, self.y) def __abs__(self): return hypot(self.x, self.y) def __bool__(self): return bool(abs(self)) def __add__(self, other): x = self.x + other.x y = self.y + other.y return Vector(x, y) def __mul__(self, scalar): return Vector(self.x * scalar, self.y * scalar)# 使用 + 运算符v1 = Vector(2, 4)v2 = Vector(2, 1)v1 + v2# 调用 abs 内置函数v = Vector(3, 4)abs(v)# 使用 * 运算符v * 3 Vector 类中 6 个方法（除 __init__ 外）并不会在类自身的代码中调用。一般只有解释器会频繁调用这些方法 字符串的表示形式 内置函数 repr， 通过 __repr__ 特殊方法来得到一个对象的字符串表示形式。 算数运算符 通过 __add__, __mul__， 向量类能够操作 + 和 * 两个算数运算符。 运算符操作对象不发生改变，返回一个产生的新值 自定义的布尔值 任何对象可用于需要布尔值的上下文中（if, while 语句， and, or, not 运算符） Python 调用 bool(x) 判定一个值 x，bool(x) 只能返回 True 或者 False 如果类没有实现 __bool__，则调用 __len__， 若返回 0，则 bool 返回 False 特殊方法一览 Reference 为何 len 不是普通方法 “实用胜于纯粹“ The Zen of Python 为了让 Python 自带的数据结构走后门, CPython 会直接从结构体读取对象的长度,而不会调用方法. 这种处理方式在保持内置类型的效率和语言一致性保持了一个平衡. 小结 通过实现特殊方法，自定义数据类型可以像内置类型一样处理 合理的字符串表示形式是Python对象的基本要求。__repr__, __str__ 序列类型的模拟是特殊方法最常用的地方","categories":[{"name":"Python","slug":"Python","permalink":"https://yuechuanx.top/categories/Python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://yuechuanx.top/tags/python/"}]},{"title":"如何编写最佳的Dockerfile","slug":"DevOps/how-to-write-excellent-dockerfile","date":"2019-12-01T08:29:15.000Z","updated":"2020-04-23T03:36:06.713Z","comments":true,"path":"DevOps/how-to-write-excellent-dockerfile/","link":"","permalink":"https://yuechuanx.top/DevOps/how-to-write-excellent-dockerfile/","excerpt":"","text":"译者按: Dockerfile 的语法非常简单，然而如何加快镜像构建速度，如何减少 Docker 镜像的大小却不是那么直观，需要积累实践经验。这篇博客可以帮助你快速掌握编写 Dockerfile 的技巧。 原文: How to write excellent Dockerfiles 译者: Fundebug 本文采用意译，版权归原作者所有 我已经使用 Docker 有一段时间了，其中编写 Dockerfile 是非常重要的一部分工作。在这篇博客中，我打算分享一些建议，帮助大家编写更好的 Dockerfile。 目标 更快的构建速度 更小的 Docker 镜像大小 更少的 Docker 镜像层 充分利用镜像缓存 增加 Dockerfile 可读性 让 Docker 容器使用起来更简单 总结 编写.dockerignore 文件 容器只运行单个应用 将多个 RUN 指令合并为一个 基础镜像的标签不要用 latest 每个 RUN 指令后删除多余文件 选择合适的基础镜像(alpine 版本最好) 设置 WORKDIR 和 CMD 使用 ENTRYPOINT (可选) 在 entrypoint 脚本中使用 exec COPY 与 ADD 优先使用前者 合理调整 COPY 与 RUN 的顺序 设置默认的环境变量，映射端口和数据卷 使用 LABEL 设置镜像元数据 添加 HEALTHCHECK 示例 示例 Dockerfile 犯了几乎所有的错(当然我是故意的)。接下来，我会一步步优化它。假设我们需要使用 Docker 运行一个 Node.js 应用，下面就是它的 Dockerfile(CMD 指令太复杂了，所以我简化了，它是错误的，仅供参考)。 12345678910111213FROM ubuntuADD . /appRUN apt-get updateRUN apt-get upgrade -yRUN apt-get install -y nodejs ssh mysqlRUN cd /app &amp;&amp; npm install# this should start three processes, mysql and ssh# in the background and node app in foreground# isn't it beautifully terrible? &lt;3CMD mysql &amp; sshd &amp; npm start 构建镜像: docker build -t wtf 编写.dockerignore 文件 构建镜像时，Docker 需要先准备context ，将所有需要的文件收集到进程中。默认的context包含 Dockerfile 目录中的所有文件，但是实际上，我们并不需要.git 目录，node_modules 目录等内容。 .dockerignore 的作用和语法类似于 .gitignore，可以忽略一些不需要的文件，这样可以有效加快镜像构建时间，同时减少 Docker 镜像的大小。示例如下: 123.git/node_modules/dist/ 容器只运行单个应用 从技术角度讲，你可以在 Docker 容器中运行多个进程。你可以将数据库，前端，后端，ssh，supervisor 都运行在同一个 Docker 容器中。但是，这会让你非常痛苦: 非常长的构建时间(修改前端之后，整个后端也需要重新构建) 非常大的镜像大小 多个应用的日志难以处理(不能直接使用 stdout，否则多个应用的日志会混合到一起) 横向扩展时非常浪费资源(不同的应用需要运行的容器数并不相同) 僵尸进程问题 - 你需要选择合适的 init 进程 因此，我建议大家为每个应用构建单独的 Docker 镜像，然后使用 Docker Compose 运行多个 Docker 容器。 现在，我从 Dockerfile 中删除一些不需要的安装包，另外，SSH 可以用docker exec替代。示例如下： 12345678910111213FROM ubuntuADD . /appRUN apt-get updateRUN apt-get upgrade -y# we should remove ssh and mysql, and use# separate container for database RUN apt-get install -y nodejs # ssh mysqlRUN cd /app &amp;&amp; npm installCMD npm start 将多个 RUN 指令合并为一个 Docker 镜像是分层的，下面这些知识点非常重要: Dockerfile 中的每个指令都会创建一个新的镜像层。 镜像层将被缓存和复用 当 Dockerfile 的指令修改了，复制的文件变化了，或者构建镜像时指定的变量不同了，对应的镜像层缓存就会失效 某一层的镜像缓存失效之后，它之后的镜像层缓存都会失效 镜像层是不可变的，如果我们再某一层中添加一个文件，然后在下一层中删除它，则镜像中依然会包含该文件(只是这个文件在 Docker 容器中不可见了)。 Docker 镜像类似于洋葱。它们都有很多层。为了修改内层，则需要将外面的层都删掉。记住这一点的话，其他内容就很好理解了。 现在，我们将所有的RUN指令合并为一个。同时把apt-get upgrade删除，因为它会使得镜像构建非常不确定(我们只需要依赖基础镜像的更新就好了) 12345678910FROM ubuntuADD . /appRUN apt-get update \\ &amp;&amp; apt-get install -y nodejs \\ &amp;&amp; cd /app \\ &amp;&amp; npm installCMD npm start 记住一点，我们只能将变化频率一样的指令合并在一起。将 node.js 安装与 npm 模块安装放在一起的话，则每次修改源代码，都需要重新安装 node.js，这显然不合适。因此，正确的写法是这样的: 1234567FROM ubuntuRUN apt-get update &amp;&amp; apt-get install -y nodejs ADD . /appRUN cd /app &amp;&amp; npm installCMD npm start 基础镜像的标签不要用 latest 当镜像没有指定标签时，将默认使用latest 标签。因此， FROM ubuntu 指令等同于FROM ubuntu:latest。当时，当镜像更新时，latest 标签会指向不同的镜像，这时构建镜像有可能失败。如果你的确需要使用最新版的基础镜像，可以使用 latest 标签，否则的话，最好指定确定的镜像标签。 示例 Dockerfile 应该使用16.04作为标签。 1234567FROM ubuntu:16.04 # it's that easy!RUN apt-get update &amp;&amp; apt-get install -y nodejs ADD . /appRUN cd /app &amp;&amp; npm installCMD npm start 每个 RUN 指令后删除多余文件 假设我们更新了 apt-get 源，下载，解压并安装了一些软件包，它们都保存在/var/lib/apt/lists/目录中。但是，运行应用时 Docker 镜像中并不需要这些文件。我们最好将它们删除，因为它会使 Docker 镜像变大。 示例 Dockerfile 中，我们可以删除/var/lib/apt/lists/目录中的文件(它们是由 apt-get update 生成的)。 1234567891011FROM ubuntu:16.04RUN apt-get update \\ &amp;&amp; apt-get install -y nodejs \\ # added lines &amp;&amp; rm -rf /var/lib/apt/lists/*ADD . /appRUN cd /app &amp;&amp; npm installCMD npm start 选择合适的基础镜像(alpine 版本最好) 在示例中，我们选择了ubuntu作为基础镜像。但是我们只需要运行 node 程序，有必要使用一个通用的基础镜像吗？node镜像应该是更好的选择。 12345678FROM nodeADD . /app# we don't need to install node # anymore and use apt-getRUN cd /app &amp;&amp; npm installCMD npm start 更好的选择是 alpine 版本的node镜像。alpine 是一个极小化的 Linux 发行版，只有 4MB，这让它非常适合作为基础镜像。 123456FROM node:7-alpineADD . /appRUN cd /app &amp;&amp; npm installCMD npm start apk是 Alpine 的包管理工具。它与apt-get有些不同，但是非常容易上手。另外，它还有一些非常有用的特性，比如no-cache和 --virtual选项，它们都可以帮助我们减少镜像的大小。 设置 WORKDIR 和 CMD WORKDIR指令可以设置默认目录，也就是运行RUN / CMD / ENTRYPOINT指令的地方。 CMD指令可以设置容器创建是执行的默认命令。另外，你应该讲命令写在一个数组中，数组中每个元素为命令的每个单词(参考官方文档)。 1234567FROM node:7-alpineWORKDIR /appADD . /appRUN npm installCMD [\"npm\", \"start\"] 使用 ENTRYPOINT (可选) ENTRYPOINT指令并不是必须的，因为它会增加复杂度。ENTRYPOINT是一个脚本，它会默认执行，并且将指定的命令错误其参数。它通常用于构建可执行的 Docker 镜像。entrypoint.sh 如下: 123456789101112131415161718192021222324252627#!/usr/bin/env sh# $0 is a script name, # $1, $2, $3 etc are passed arguments# $1 is our commandCMD=$1case \"$CMD\" in \"dev\" ) npm install export NODE_ENV=development exec npm run dev ;; \"start\" ) # we can modify files here, using ENV variables passed in # \"docker create\" command. It can't be done during build process. echo \"db: $DATABASE_ADDRESS\" &gt;&gt; /app/config.yml export NODE_ENV=production exec npm start ;; * ) # Run custom command. Thanks to this line we can still use # \"docker run our_image /bin/bash\" and it will work exec $CMD $&#123;@:2&#125; ;;esac 示例 Dockerfile: 12345678FROM node:7-alpineWORKDIR /appADD . /appRUN npm installENTRYPOINT [\"./entrypoint.sh\"]CMD [\"start\"] 可以使用如下命令运行该镜像: docker run our-app dev docker run out-app start docker run -ti out-app /bin/bash 在 entrypoint 脚本中使用 exec 在前文的 entrypoint 脚本中，我使用了exec命令运行 node 应用。不使用exec的话，我们则不能顺利地关闭容器，因为 SIGTERM 信号会被 bash 脚本进程吞没。exec命令启动的进程可以取代脚本进程，因此所有的信号都会正常工作。 COPY 与 ADD 优先使用前者 COPY指令非常简单，仅用于将文件拷贝到镜像中。ADD相对来讲复杂一些，可以用于下载远程文件以及解压压缩包(参考官方文档)。 123456789FROM node:7-alpineWORKDIR /appCOPY . /appRUN npm installENTRYPOINT [\"./entrypoint.sh\"]CMD [\"start\"] 合理调整 COPY 与 RUN 的顺序 我们应该把变化最少的部分放在 Dockerfile 的前面，这样可以充分利用镜像缓存。 示例中，源代码会经常变化，则每次构建镜像时都需要重新安装 NPM 模块，这显然不是我们希望看到的。因此我们可以先拷贝package.json，然后安装 NPM 模块，最后才拷贝其余的源代码。这样的话，即使源代码变化，也不需要重新安装 NPM 模块。 12345678910FROM node:7-alpineWORKDIR /appCOPY package.json /appRUN npm installCOPY . /appENTRYPOINT [\"./entrypoint.sh\"]CMD [\"start\"] 设置默认的环境变量，映射端口和数据卷 运行 Docker 容器时很可能需要一些环境变量。在 Dockerfile 设置默认的环境变量是一种很好的方式。另外，我们应该在 Dockerfile 中设置映射端口和数据卷。示例如下: 1234567891011121314151617181920212223FROM node:7-alpine# env variables required during buildENV PROJECT_DIR=/appWORKDIR $PROJECT_DIRCOPY package.json $PROJECT_DIRRUN npm installCOPY . $PROJECT_DIR# env variables that can change# volume and port settings# and defaults for our applicationENV MEDIA_DIR=/media \\ NODE_ENV=production \\ APP_PORT=3000VOLUME $MEDIA_DIREXPOSE $APP_PORTENTRYPOINT [\"./entrypoint.sh\"]CMD [\"start\"] ENV指令指定的环境变量在容器中可以使用。如果你只是需要指定构建镜像时的变量，你可以使用ARG指令。 使用 LABEL 设置镜像元数据 使用LABEL指令，可以为镜像设置元数据，例如镜像创建者或者镜像说明。旧版的 Dockerfile 语法使用MAINTAINER指令指定镜像创建者，但是它已经被弃用了。有时，一些外部程序需要用到镜像的元数据，例如nvidia-docker需要用到com.nvidia.volumes.needed。 示例如下: 123FROM node:7-alpineLABEL maintainer \"jakub.skalecki@example.com\"... 添加 HEALTHCHECK 运行容器时，可以指定–restart always选项。这样的话，容器崩溃时，Docker 守护进程(docker daemon)会重启容器。对于需要长时间运行的容器，这个选项非常有用。但是，如果容器的确在运行，但是不可(陷入死循环，配置错误)用怎么办？使用HEALTHCHECK指令可以让 Docker 周期性的检查容器的健康状况。我们只需要指定一个命令，如果一切正常的话返回 0，否则返回 1。对 HEALTHCHECK 感兴趣的话，可以参考这篇博客。示例如下: 1234567891011121314151617181920FROM node:7-alpineLABEL maintainer \"jakub.skalecki@example.com\"ENV PROJECT_DIR=/appWORKDIR $PROJECT_DIRCOPY package.json $PROJECT_DIRRUN npm installCOPY . $PROJECT_DIRENV MEDIA_DIR=/media \\ NODE_ENV=production \\ APP_PORT=3000VOLUME $MEDIA_DIREXPOSE $APP_PORTHEALTHCHECK CMD curl --fail http://localhost:$APP_PORT || exit 1ENTRYPOINT [\"./entrypoint.sh\"]CMD [\"start\"] 当请求失败时，curl —fail 命令返回非 0 状态。 对进一步了解的使用者 如果你想要了解更多，请参阅 STOPSIGNAL, ONBUILD, 和 SHELL 指令。还要提到在构建镜像中一个非常有用的指令 --no-cache (特别是在 CI 服务器上)，以及--squash here). 以上，Have fun 😃","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://yuechuanx.top/categories/DevOps/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://yuechuanx.top/tags/docker/"}]},{"title":"命令行的艺术(转载)","slug":"the-art-of-command-line","date":"2019-11-28T02:58:43.000Z","updated":"2020-04-23T03:36:06.722Z","comments":false,"path":"the-art-of-command-line/","link":"","permalink":"https://yuechuanx.top/the-art-of-command-line/","excerpt":"","text":"熟练使用命令行是一种常常被忽视，或被认为难以掌握的技能，但实际上，它会提高你作为工程师的灵活性以及生产力。本文是一份我在 Linux 上工作时，发现的一些命令行使用技巧的摘要。有些技巧非常基础，而另一些则相当复杂，甚至晦涩难懂。这篇文章并不长，但当你能够熟练掌握这里列出的所有技巧时，你就学会了很多关于命令行的东西了。 前言 基础 日常使用 文件及数据处理 系统调试 单行脚本 冷门但有用 仅限 OS X 系统 仅限 Windows 系统 更多资源 免责声明 这篇文章是许多作者和译者共同的成果。 这里的部分内容 首次 出现 于 Quora， 但已经迁移到了 Github，并由众多高手做出了许多改进。 如果你在本文中发现了错误或者存在可以改善的地方，请[贡献你的一份力量] 前言 涵盖范围： 这篇文章不仅能帮助刚接触命令行的新手，而且对具有经验的人也大有裨益。本文致力于做到覆盖面广（涉及所有重要的内容），具体（给出具体的最常用的例子），以及简洁（避免冗余的内容，或是可以在其他地方轻松查到的细枝末节）。在特定应用场景下，本文的内容属于基本功或者能帮助您节约大量的时间。 本文主要为 Linux 所写，但在仅限 OS X 系统章节和仅限 Windows 系统章节中也包含有对应操作系统的内容。除去这两个章节外，其它的内容大部分均可在其他类 Unix 系统或 OS X，甚至 Cygwin 中得到应用。 本文主要关注于交互式 Bash，但也有很多技巧可以应用于其他 shell 和 Bash 脚本当中。 除去“标准的”Unix 命令，本文还包括了一些依赖于特定软件包的命令（前提是它们具有足够的价值）。 注意事项： 为了能在一页内展示尽量多的东西，一些具体的信息可以在引用的页面中找到。我们相信机智的你知道如何使用 Google 或者其他搜索引擎来查阅到更多的详细信息。文中部分命令需要您使用 apt-get，yum，dnf，pacman， pip 或 brew（以及其它合适的包管理器）来安装依赖的程序。 遇到问题的话，请尝试使用 Explainshell 去获取相关命令、参数、管道等内容的解释。 基础 学习 Bash 的基础知识。具体地，在命令行中输入 man bash 并至少全文浏览一遍; 它理解起来很简单并且不冗长。其他的 shell 可能很好用，但 Bash 的功能已经足够强大并且到几乎总是可用的（ 如果你只学习 zsh，fish 或其他的 shell 的话，在你自己的设备上会显得很方便，但过度依赖这些功能会给您带来不便，例如当你需要在服务器上工作时）。 熟悉至少一个基于文本的编辑器。通常而言 Vim （vi） 会是你最好的选择，毕竟在终端中编辑文本时 Vim 是最好用的工具（甚至大部分情况下 Vim 要比 Emacs、大型 IDE 或是炫酷的编辑器更好用）。 学会如何使用 man 命令去阅读文档。学会使用 apropos 去查找文档。知道有些命令并不对应可执行文件，而是在 Bash 内置好的，此时可以使用 help 和 help -d 命令获取帮助信息。你可以用 type 命令 来判断这个命令到底是可执行文件、shell 内置命令还是别名。 学会使用 &gt; 和 &lt; 来重定向输出和输入，学会使用 | 来重定向管道。明白 &gt; 会覆盖了输出文件而 &gt;&gt; 是在文件末添加。了解标准输出 stdout 和标准错误 stderr。 学会使用通配符 * （或许再算上 ? 和 […]） 和引用以及引用中 ' 和 &quot; 的区别（后文中有一些具体的例子）。 熟悉 Bash 中的任务管理工具：&amp;，ctrl-z，ctrl-c，jobs，fg，bg，kill 等。 学会使用 ssh 进行远程命令行登录，最好知道如何使用 ssh-agent，ssh-add 等命令来实现基础的无密码认证登录。 学会基本的文件管理工具：ls 和 ls -l （了解 ls -l 中每一列代表的意义），less，head，tail 和 tail -f （甚至 less +F），ln 和 ln -s （了解硬链接与软链接的区别），chown，chmod，du （硬盘使用情况概述：du -hs *）。 关于文件系统的管理，学习 df，mount，fdisk，mkfs，lsblk。知道 inode 是什么（与 ls -i 和 df -i 等命令相关）。 学习基本的网络管理工具：ip 或 ifconfig，dig。 学习并使用一种版本控制管理系统，例如 git。 熟悉正则表达式，学会使用 grep／egrep，它们的参数中 -i，-o，-v，-A，-B 和 -C 这些是很常用并值得认真学习的。 学会使用 apt-get，yum，dnf 或 pacman （具体使用哪个取决于你使用的 Linux 发行版）来查找和安装软件包。并确保你的环境中有 pip 来安装基于 Python 的命令行工具 （接下来提到的部分程序使用 pip 来安装会很方便）。 日常使用 在 Bash 中，可以通过按 Tab 键实现自动补全参数，使用 ctrl-r 搜索命令行历史记录（按下按键之后，输入关键字便可以搜索，重复按下 ctrl-r 会向后查找匹配项，按下 Enter 键会执行当前匹配的命令，而按下右方向键会将匹配项放入当前行中，不会直接执行，以便做出修改）。 在 Bash 中，可以按下 ctrl-w 删除你键入的最后一个单词，ctrl-u 可以删除行内光标所在位置之前的内容，alt-b 和 alt-f 可以以单词为单位移动光标，ctrl-a 可以将光标移至行首，ctrl-e 可以将光标移至行尾，ctrl-k 可以删除光标至行尾的所有内容，ctrl-l 可以清屏。键入 man readline 可以查看 Bash 中的默认快捷键。内容有很多，例如 alt-. 循环地移向前一个参数，而 alt-* 可以展开通配符。 你喜欢的话，可以执行 set -o vi 来使用 vi 风格的快捷键，而执行 set -o emacs 可以把它改回来。 为了便于编辑长命令，在设置你的默认编辑器后（例如 export EDITOR=vim），ctrl-x ctrl-e 会打开一个编辑器来编辑当前输入的命令。在 vi 风格下快捷键则是 escape-v。 键入 history 查看命令行历史记录，再用 !n（n 是命令编号）就可以再次执行。其中有许多缩写，最有用的大概就是 !$， 它用于指代上次键入的参数，而 !! 可以指代上次键入的命令了（参考 man 页面中的“HISTORY EXPANSION”）。不过这些功能，你也可以通过快捷键 ctrl-r 和 alt-. 来实现。 cd 命令可以切换工作路径，输入 cd ~ 可以进入 home 目录。要访问你的 home 目录中的文件，可以使用前缀 ~（例如 ~/.bashrc）。在 sh 脚本里则用环境变量 $HOME 指代 home 目录的路径。 回到前一个工作路径：cd -。 如果你输入命令的时候中途改了主意，按下 alt-# 在行首添加 # 把它当做注释再按下回车执行（或者依次按下 ctrl-a， #， enter）。这样做的话，之后借助命令行历史记录，你可以很方便恢复你刚才输入到一半的命令。 使用 xargs （ 或 parallel）。他们非常给力。注意到你可以控制每行参数个数（-L）和最大并行数（-P）。如果你不确定它们是否会按你想的那样工作，先使用 xargs echo 查看一下。此外，使用 -I{} 会很方便。例如： 12find . -name '*.py' | xargs grep some_functioncat hosts | xargs -I&#123;&#125; ssh root@&#123;&#125; hostname pstree -p 以一种优雅的方式展示进程树。 使用 pgrep 和 pkill 根据名字查找进程或发送信号（-f 参数通常有用）。 了解你可以发往进程的信号的种类。比如，使用 kill -STOP [pid] 停止一个进程。使用 man 7 signal 查看详细列表。 使用 nohup 或 disown 使一个后台进程持续运行。 使用 netstat -lntp 或 ss -plat 检查哪些进程在监听端口（默认是检查 TCP 端口; 添加参数 -u 则检查 UDP 端口）或者 lsof -iTCP -sTCP:LISTEN -P -n (这也可以在 OS X 上运行)。 lsof 来查看开启的套接字和文件。 使用 uptime 或 w 来查看系统已经运行多长时间。 使用 alias 来创建常用命令的快捷形式。例如：alias ll='ls -latr' 创建了一个新的命令别名 ll。 可以把别名、shell 选项和常用函数保存在 ~/.bashrc，具体看下这篇文章。这样做的话你就可以在所有 shell 会话中使用你的设定。 把环境变量的设定以及登陆时要执行的命令保存在 ~/.bash_profile。而对于从图形界面启动的 shell 和 cron 启动的 shell，则需要单独配置文件。 要想在几台电脑中同步你的配置文件（例如 .bashrc 和 .bash_profile），可以借助 Git。 当变量和文件名中包含空格的时候要格外小心。Bash 变量要用引号括起来，比如 &quot;$FOO&quot;。尽量使用 -0 或 -print0 选项以便用 NULL 来分隔文件名，例如 locate -0 pattern | xargs -0 ls -al 或 find / -print0 -type d | xargs -0 ls -al。如果 for 循环中循环访问的文件名含有空字符（空格、tab 等字符），只需用 IFS=$'\\n' 把内部字段分隔符设为换行符。 在 Bash 脚本中，使用 set -x 去调试输出（或者使用它的变体 set -v，它会记录原始输入，包括多余的参数和注释）。尽可能地使用严格模式：使用 set -e 令脚本在发生错误时退出而不是继续运行；使用 set -u 来检查是否使用了未赋值的变量；试试 set -o pipefail，它可以监测管道中的错误。当牵扯到很多脚本时，使用 trap 来检测 ERR 和 EXIT。一个好的习惯是在脚本文件开头这样写，这会使它能够检测一些错误，并在错误发生时中断程序并输出信息： 12set -euo pipefailtrap \"echo 'error: Script failed: see failed command above'\" ERR 在 Bash 脚本中，子 shell（使用括号 (...)）是一种组织参数的便捷方式。一个常见的例子是临时地移动工作路径，代码如下： 123# do something in current dir(cd /some/other/dir &amp;&amp; other-command)# continue in original dir 在 Bash 中，变量有许多的扩展方式。${name:?error message} 用于检查变量是否存在。此外，当 Bash 脚本只需要一个参数时，可以使用这样的代码 input_file=${1:?usage: $0 input_file}。在变量为空时使用默认值：${name:-default}。如果你要在之前的例子中再加一个（可选的）参数，可以使用类似这样的代码 output_file=${2:-logfile}，如果省略了 2，它的值就为空，于是‘outputfile‘就会被设为‘logfile‘。数学表达式：‘i=2，它的值就为空，于是 `output_file` 就会被设为 `logfile`。数学表达式：`i=2，它的值就为空，于是‘outputf​ile‘就会被设为‘logfile‘。数学表达式：‘i=(( (i + 1) % 5 ))。序列：{1…10}。截断字符串：{var%suffix}` 和 `{var#prefix}。例如，假设var=foo.pdf，那么echo ${var%.pdf}.txt将输出foo.txt`。 使用括号扩展（{…}）来减少输入相似文本，并自动化文本组合。这在某些情况下会很有用，例如 mv foo.{txt,pdf} some-dir（同时移动两个文件），cp somefile{,.bak}（会被扩展成 cp somefile somefile.bak）或者 mkdir -p test-{a,b,c}/subtest-{1,2,3}（会被扩展成所有可能的组合，并创建一个目录树）。 通过使用 &lt;(some command) 可以将输出视为文件。例如，对比本地文件 /etc/hosts 和一个远程文件： 1diff /etc/hosts &lt;(ssh somehost cat /etc/hosts) 编写脚本时，你可能会想要把代码都放在大括号里。缺少右括号的话，代码就会因为语法错误而无法执行。如果你的脚本是要放在网上分享供他人使用的，这样的写法就体现出它的好处了，因为这样可以防止下载不完全代码被执行。 123&#123; # 在这里写代码&#125; 了解 Bash 中的“here documents”，例如 cat &lt;&lt;EOF ...。 在 Bash 中，同时重定向标准输出和标准错误：some-command &gt;logfile 2&gt;&amp;1 或者 some-command &amp;&gt;logfile。通常，为了保证命令不会在标准输入里残留一个未关闭的文件句柄捆绑在你当前所在的终端上，在命令后添加 &lt;/dev/null 是一个好习惯。 使用 man ascii 查看具有十六进制和十进制值的ASCII表。man unicode，man utf-8，以及 man latin1 有助于你去了解通用的编码信息。 使用 screen 或 tmux 来使用多份屏幕，当你在使用 ssh 时（保存 session 信息）将尤为有用。而 byobu 可以为它们提供更多的信息和易用的管理工具。另一个轻量级的 session 持久化解决方案是 dtach。 ssh 中，了解如何使用 -L 或 -D（偶尔需要用 -R）开启隧道是非常有用的，比如当你需要从一台远程服务器上访问 web 页面。 对 ssh 设置做一些小优化可能是很有用的，例如这个 ~/.ssh/config 文件包含了防止特定网络环境下连接断开、压缩数据、多通道等选项： 1234567TCPKeepAlive=yesServerAliveInterval=15ServerAliveCountMax=6Compression=yesControlMaster autoControlPath /tmp/%r@%h:%pControlPersist yes 一些其他的关于 ssh 的选项是与安全相关的，应当小心翼翼的使用。例如你应当只能在可信任的网络中启用 StrictHostKeyChecking=no，ForwardAgent=yes。 考虑使用 mosh 作为 ssh 的替代品，它使用 UDP 协议。它可以避免连接被中断并且对带宽需求更小，但它需要在服务端做相应的配置。 获取八进制形式的文件访问权限（修改系统设置时通常需要，但 ls 的功能不那么好用并且通常会搞砸），可以使用类似如下的代码： 1stat -c '%A %a %n' /etc/timezone 使用 percol 或者 fzf 可以交互式地从另一个命令输出中选取值。 使用 fpp（PathPicker）可以与基于另一个命令(例如 git）输出的文件交互。 将 web 服务器上当前目录下所有的文件（以及子目录）暴露给你所处网络的所有用户，使用： python -m SimpleHTTPServer 7777 （使用端口 7777 和 Python 2）或python -m http.server 7777 （使用端口 7777 和 Python 3）。 以其他用户的身份执行命令，使用 sudo。默认以 root 用户的身份执行；使用 -u 来指定其他用户。使用 -i 来以该用户登录（需要输入_你自己的_密码）。 将 shell 切换为其他用户，使用 su username 或者 sudo - username。加入 - 会使得切换后的环境与使用该用户登录后的环境相同。省略用户名则默认为 root。切换到哪个用户，就需要输入_哪个用户的_密码。 了解命令行的 128K 限制。使用通配符匹配大量文件名时，常会遇到“Argument list too long”的错误信息。（这种情况下换用 find 或 xargs 通常可以解决。） 当你需要一个基本的计算器时，可以使用 python 解释器（当然你要用 python 的时候也是这样）。例如： 12&gt;&gt;&gt; 2+35 文件及数据处理 在当前目录下通过文件名查找一个文件，使用类似于这样的命令：find . -iname '*something*'。在所有路径下通过文件名查找文件，使用 locate something （但注意到 updatedb 可能没有对最近新建的文件建立索引，所以你可能无法定位到这些未被索引的文件）。 使用 ag 在源代码或数据文件里检索（grep -r 同样可以做到，但相比之下 ag 更加先进）。 将 HTML 转为文本：lynx -dump -stdin。 Markdown，HTML，以及所有文档格式之间的转换，试试 pandoc。 当你要处理棘手的 XML 时候，xmlstarlet 算是上古时代流传下来的神器。 使用 jq 处理 JSON。 使用 shyaml 处理 YAML。 要处理 Excel 或 CSV 文件的话，csvkit 提供了 in2csv，csvcut，csvjoin，csvgrep 等方便易用的工具。 当你要处理 Amazon S3 相关的工作的时候，s3cmd 是一个很方便的工具而 s4cmd 的效率更高。Amazon 官方提供的 aws 以及 saws 是其他 AWS 相关工作的基础，值得学习。 了解如何使用 sort 和 uniq，包括 uniq 的 -u 参数和 -d 参数，具体内容在后文单行脚本节中。另外可以了解一下 comm。 了解如何使用 cut，paste 和 join 来更改文件。很多人都会使用 cut，但遗忘了 join。 了解如何运用 wc 去计算新行数（-l），字符数（-m），单词数（-w）以及字节数（-c）。 了解如何使用 tee 将标准输入复制到文件甚至标准输出，例如 ls -al | tee file.txt。 要进行一些复杂的计算，比如分组、逆序和一些其他的统计分析，可以考虑使用 datamash。 注意到语言设置（中文或英文等）对许多命令行工具有一些微妙的影响，比如排序的顺序和性能。大多数 Linux 的安装过程会将 LANG 或其他有关的变量设置为符合本地的设置。要意识到当你改变语言设置时，排序的结果可能会改变。明白国际化可能会使 sort 或其他命令运行效率下降许多倍。某些情况下（例如集合运算）你可以放心的使用 export LC_ALL=C 来忽略掉国际化并按照字节来判断顺序。 你可以单独指定某一条命令的环境，只需在调用时把环境变量设定放在命令的前面，例如 TZ=Pacific/Fiji date 可以获取斐济的时间。 了解如何使用 awk 和 sed 来进行简单的数据处理。 参阅 One-liners 获取示例。 替换一个或多个文件中出现的字符串： 1perl -pi.bak -e 's/old-string/new-string/g' my-files-*.txt 使用 repren 来批量重命名文件，或是在多个文件中搜索替换内容。（有些时候 rename 命令也可以批量重命名，但要注意，它在不同 Linux 发行版中的功能并不完全一样。） 123456# 将文件、目录和内容全部重命名 foo -&gt; bar:repren --full --preserve-case --from foo --to bar .# 还原所有备份文件 whatever.bak -&gt; whatever:repren --renames --from '(.*)\\.bak' --to '\\1' *.bak# 用 rename 实现上述功能（若可用）:rename 's/\\.bak$//' *.bak 根据 man 页面的描述，rsync 是一个快速且非常灵活的文件复制工具。它闻名于设备之间的文件同步，但其实它在本地情况下也同样有用。在安全设置允许下，用 rsync 代替 scp 可以实现文件续传，而不用重新从头开始。它同时也是删除大量文件的最快方法之一： 1mkdir empty &amp;&amp; rsync -r --delete empty/ some-dir &amp;&amp; rmdir some-dir 若要在复制文件时获取当前进度，可使用 pv，pycp，progress，rsync --progress。若所执行的复制为block块拷贝，可以使用 dd status=progress。 使用 shuf 可以以行为单位来打乱文件的内容或从一个文件中随机选取多行。 了解 sort 的参数。显示数字时，使用 -n 或者 -h 来显示更易读的数（例如 du -h 的输出）。明白排序时关键字的工作原理（-t 和 -k）。例如，注意到你需要 -k1，1 来仅按第一个域来排序，而 -k1 意味着按整行排序。稳定排序（sort -s）在某些情况下很有用。例如，以第二个域为主关键字，第一个域为次关键字进行排序，你可以使用 sort -k1，1 | sort -s -k2，2。 如果你想在 Bash 命令行中写 tab 制表符，按下 ctrl-v [Tab] 或键入 $'\\t' （后者可能更好，因为你可以复制粘贴它）。 标准的源代码对比及合并工具是 diff 和 patch。使用 diffstat 查看变更总览数据。注意到 diff -r 对整个文件夹有效。使用 diff -r tree1 tree2 | diffstat 查看变更的统计数据。vimdiff 用于比对并编辑文件。 对于二进制文件，使用 hd，hexdump 或者 xxd 使其以十六进制显示，使用 bvi，hexedit 或者 biew 来进行二进制编辑。 同样对于二进制文件，strings（包括 grep 等工具）可以帮助在二进制文件中查找特定比特。 制作二进制差分文件（Delta 压缩），使用 xdelta3。 使用 iconv 更改文本编码。需要更高级的功能，可以使用 uconv，它支持一些高级的 Unicode 功能。例如，这条命令移除了所有重音符号： 1uconv -f utf-8 -t utf-8 -x '::Any-Lower; ::Any-NFD; [:Nonspacing Mark:] &gt;; ::Any-NFC; ' &lt; input.txt &gt; output.txt 拆分文件可以使用 split（按大小拆分）和 csplit（按模式拆分）。 操作日期和时间表达式，可以用 dateutils 中的 dateadd、datediff、strptime 等工具。 使用 zless、zmore、zcat 和 zgrep 对压缩过的文件进行操作。 文件属性可以通过 chattr 进行设置，它比文件权限更加底层。例如，为了保护文件不被意外删除，可以使用不可修改标记：sudo chattr +i /critical/directory/or/file 使用 getfacl 和 setfacl 以保存和恢复文件权限。例如： 12getfacl -R /some/path &gt; permissions.txtsetfacl --restore=permissions.txt 为了高效地创建空文件，请使用 truncate（创建稀疏文件），fallocate（用于 ext4，xfs，btrf 和 ocfs2 文件系统），xfs_mkfile（适用于几乎所有的文件系统，包含在 xfsprogs 包中），mkfile（用于类 Unix 操作系统，比如 Solaris 和 Mac OS）。 系统调试 curl 和 curl -I 可以被轻松地应用于 web 调试中，它们的好兄弟 wget 也是如此，或者也可以试试更潮的 httpie。 获取 CPU 和硬盘的使用状态，通常使用使用 top（htop 更佳），iostat 和 iotop。而 iostat -mxz 15 可以让你获悉 CPU 和每个硬盘分区的基本信息和性能表现。 使用 netstat 和 ss 查看网络连接的细节。 dstat 在你想要对系统的现状有一个粗略的认识时是非常有用的。然而若要对系统有一个深度的总体认识，使用 glances，它会在一个终端窗口中向你提供一些系统级的数据。 若要了解内存状态，运行并理解 free 和 vmstat 的输出。值得留意的是“cached”的值，它指的是 Linux 内核用来作为文件缓存的内存大小，而与空闲内存无关。 Java 系统调试则是一件截然不同的事，一个可以用于 Oracle 的 JVM 或其他 JVM 上的调试的技巧是你可以运行 kill -3 &lt;pid&gt; 同时一个完整的栈轨迹和堆概述（包括 GC 的细节）会被保存到标准错误或是日志文件。JDK 中的 jps，jstat，jstack，jmap 很有用。SJK tools 更高级。 使用 mtr 去跟踪路由，用于确定网络问题。 用 ncdu 来查看磁盘使用情况，它比寻常的命令，如 du -sh *，更节省时间。 查找正在使用带宽的套接字连接或进程，使用 iftop 或 nethogs。 ab 工具（Apache 中自带）可以简单粗暴地检查 web 服务器的性能。对于更复杂的负载测试，使用 siege。 wireshark，tshark 和 ngrep 可用于复杂的网络调试。 了解 strace 和 ltrace。这俩工具在你的程序运行失败、挂起甚至崩溃，而你却不知道为什么或你想对性能有个总体的认识的时候是非常有用的。注意 profile 参数（-c）和附加到一个运行的进程参数 （-p）。 了解使用 ldd 来检查共享库。但是永远不要在不信任的文件上运行。 了解如何运用 gdb 连接到一个运行着的进程并获取它的堆栈轨迹。 学会使用 /proc。它在调试正在出现的问题的时候有时会效果惊人。比如：/proc/cpuinfo，/proc/meminfo，/proc/cmdline，/proc/xxx/cwd，/proc/xxx/exe，/proc/xxx/fd/，/proc/xxx/smaps（这里的 xxx 表示进程的 id 或 pid）。 当调试一些之前出现的问题的时候，sar 非常有用。它展示了 cpu、内存以及网络等的历史数据。 关于更深层次的系统分析以及性能分析，看看 stap（SystemTap），perf，以及sysdig。 查看你当前使用的系统，使用 uname，uname -a（Unix／kernel 信息）或者 lsb_release -a（Linux 发行版信息）。 无论什么东西工作得很欢乐（可能是硬件或驱动问题）时可以试试 dmesg。 如果你删除了一个文件，但通过 du 发现没有释放预期的磁盘空间，请检查文件是否被进程占用： lsof | grep deleted | grep &quot;filename-of-my-big-file&quot; 单行脚本 一些命令组合的例子： 当你需要对文本文件做集合交、并、差运算时，sort 和 uniq 会是你的好帮手。具体例子请参照代码后面的，此处假设 a 与 b 是两内容不同的文件。这种方式效率很高，并且在小文件和上 G 的文件上都能运用（注意尽管在 /tmp 在一个小的根分区上时你可能需要 -T 参数，但是实际上 sort 并不被内存大小约束），参阅前文中关于 LC_ALL 和 sort 的 -u 参数的部分。 123sort a b | uniq &gt; c # c 是 a 并 bsort a b | uniq -d &gt; c # c 是 a 交 bsort a b b | uniq -u &gt; c # c 是 a - b 使用 grep . *（每行都会附上文件名）或者 head -100 *（每个文件有一个标题）来阅读检查目录下所有文件的内容。这在检查一个充满配置文件的目录（如 /sys、/proc、/etc）时特别好用。 计算文本文件第三列中所有数的和（可能比同等作用的 Python 代码快三倍且代码量少三倍）： 1awk '&#123; x += $3 &#125; END &#123; print x &#125;' myfile 如果你想在文件树上查看大小/日期，这可能看起来像递归版的 ls -l 但比 ls -lR 更易于理解： 1find . -type f -ls 假设你有一个类似于 web 服务器日志文件的文本文件，并且一个确定的值只会出现在某些行上，假设一个 acct_id 参数在 URI 中。如果你想计算出每个 acct_id 值有多少次请求，使用如下代码： 1egrep -o 'acct_id=[0-9]+' access.log | cut -d= -f2 | sort | uniq -c | sort -rn 要持续监测文件改动，可以使用 watch，例如检查某个文件夹中文件的改变，可以用 watch -d -n 2 'ls -rtlh | tail'；或者在排查 WiFi 设置故障时要监测网络设置的更改，可以用 watch -d -n 2 ifconfig。 运行这个函数从这篇文档中随机获取一条技巧（解析 Markdown 文件并抽取项目）： 12345678function taocl() &#123; curl -s https://raw.githubusercontent.com/jlevy/the-art-of-command-line/master/README-zh.md| pandoc -f markdown -t html | iconv -f 'utf-8' -t 'unicode' | xmlstarlet fo --html --dropdtd | xmlstarlet sel -t -v \"(html/body/ul/li[count(p)&gt;0])[$RANDOM mod last()+1]\" | xmlstarlet unesc | fmt -80&#125; 冷门但有用 expr：计算表达式或正则匹配 m4：简单的宏处理器 yes：多次打印字符串 cal：漂亮的日历 env：执行一个命令（脚本文件中很有用） printenv：打印环境变量（调试时或在写脚本文件时很有用） look：查找以特定字符串开头的单词或行 cut，paste 和 join：数据修改 fmt：格式化文本段落 pr：将文本格式化成页／列形式 fold：包裹文本中的几行 column：将文本格式化成多个对齐、定宽的列或表格 expand 和 unexpand：制表符与空格之间转换 nl：添加行号 seq：打印数字 bc：计算器 factor：分解因数 gpg：加密并签名文件 toe：terminfo 入口列表 nc：网络调试及数据传输 socat：套接字代理，与 netcat 类似 slurm：网络流量可视化 dd：文件或设备间传输数据 file：确定文件类型 tree：以树的形式显示路径和文件，类似于递归的 ls stat：文件信息 time：执行命令，并计算执行时间 timeout：在指定时长范围内执行命令，并在规定时间结束后停止进程 lockfile：使文件只能通过 rm -f 移除 logrotate： 切换、压缩以及发送日志文件 watch：重复运行同一个命令，展示结果并／或高亮有更改的部分 when-changed：当检测到文件更改时执行指定命令。参阅 inotifywait 和 entr。 tac：反向输出文件 shuf：文件中随机选取几行 comm：一行一行的比较排序过的文件 strings：从二进制文件中抽取文本 tr：转换字母 iconv 或 uconv：文本编码转换 split 和 csplit：分割文件 sponge：在写入前读取所有输入，在读取文件后再向同一文件写入时比较有用，例如 grep -v something some-file | sponge some-file units：将一种计量单位转换为另一种等效的计量单位（参阅 /usr/share/units/definitions.units） apg：随机生成密码 xz：高比例的文件压缩 ldd：动态库信息 nm：提取 obj 文件中的符号 ab 或 wrk：web 服务器性能分析 strace：调试系统调用 mtr：更好的网络调试跟踪工具 cssh：可视化的并发 shell rsync：通过 ssh 或本地文件系统同步文件和文件夹 wireshark 和 tshark：抓包和网络调试工具 ngrep：网络层的 grep host 和 dig：DNS 查找 lsof：列出当前系统打开文件的工具以及查看端口信息 dstat：系统状态查看 glances：高层次的多子系统总览 iostat：硬盘使用状态 mpstat： CPU 使用状态 vmstat： 内存使用状态 htop：top 的加强版 last：登入记录 w：查看处于登录状态的用户 id：用户/组 ID 信息 sar：系统历史数据 iftop 或 nethogs：套接字及进程的网络利用情况 ss：套接字数据 dmesg：引导及系统错误信息 sysctl： 在内核运行时动态地查看和修改内核的运行参数 hdparm：SATA/ATA 磁盘更改及性能分析 lsblk：列出块设备信息：以树形展示你的磁盘以及磁盘分区信息 lshw，lscpu，lspci，lsusb 和 dmidecode：查看硬件信息，包括 CPU、BIOS、RAID、显卡、USB设备等 lsmod 和 modinfo：列出内核模块，并显示其细节 fortune，ddate 和 sl：额，这主要取决于你是否认为蒸汽火车和莫名其妙的名人名言是否“有用” 仅限 OS X 系统 以下是仅限于 OS X 系统的技巧。 用 brew （Homebrew）或者 port （MacPorts）进行包管理。这些可以用来在 OS X 系统上安装以上的大多数命令。 用 pbcopy 复制任何命令的输出到桌面应用，用 pbpaste 粘贴输入。 若要在 OS X 终端中将 Option 键视为 alt 键（例如在上面介绍的 alt-b、alt-f 等命令中用到），打开 偏好设置 -&gt; 描述文件 -&gt; 键盘 并勾选“使用 Option 键作为 Meta 键”。 用 open 或者 open -a /Applications/Whatever.app 使用桌面应用打开文件。 Spotlight：用 mdfind 搜索文件，用 mdls 列出元数据（例如照片的 EXIF 信息）。 注意 OS X 系统是基于 BSD UNIX 的，许多命令（例如 ps，ls，tail，awk，sed）都和 Linux 中有微妙的不同（ Linux 很大程度上受到了 System V-style Unix 和 GNU 工具影响）。你可以通过标题为 “BSD General Commands Manual” 的 man 页面发现这些不同。在有些情况下 GNU 版本的命令也可能被安装（例如 gawk 和 gsed 对应 GNU 中的 awk 和 sed ）。如果要写跨平台的 Bash 脚本，避免使用这些命令（例如，考虑 Python 或者 perl ）或者经过仔细的测试。 用 sw_vers 获取 OS X 的版本信息。 仅限 Windows 系统 以下是仅限于 Windows 系统的技巧。 在 Winodws 下获取 Unix 工具 可以安装 Cygwin 允许你在 Microsoft Windows 中体验 Unix shell 的威力。这样的话，本文中介绍的大多数内容都将适用。 在 Windows 10 上，你可以使用 Bash on Ubuntu on Windows，它提供了一个熟悉的 Bash 环境，包含了不少 Unix 命令行工具。好处是它允许 Linux 上编写的程序在 Windows 上运行，而另一方面，Windows 上编写的程序却无法在 Bash 命令行中运行。 如果你在 Windows 上主要想用 GNU 开发者工具（例如 GCC），可以考虑 MinGW 以及它的 MSYS 包，这个包提供了例如 bash，gawk，make 和 grep 的工具。MSYS 并不包含所有可以与 Cygwin 媲美的特性。当制作 Unix 工具的原生 Windows 端口时 MinGW 将特别地有用。 另一个在 Windows 下实现接近 Unix 环境外观效果的选项是 Cash。注意在此环境下只有很少的 Unix 命令和命令行可用。 实用 Windows 命令行工具 可以使用 wmic 在命令行环境下给大部分 Windows 系统管理任务编写脚本以及执行这些任务。 Windows 实用的原生命令行网络工具包括 ping，ipconfig，tracert，和 netstat。 可以使用 Rundll32 命令来实现许多有用的 Windows 任务 。 Cygwin 技巧 通过 Cygwin 的包管理器来安装额外的 Unix 程序。 使用 mintty 作为你的命令行窗口。 要访问 Windows 剪贴板，可以通过 /dev/clipboard。 运行 cygstart 以通过默认程序打开一个文件。 要访问 Windows 注册表，可以使用 regtool。 注意 Windows 驱动器路径 C:\\ 在 Cygwin 中用 /cygdrive/c 代表，而 Cygwin 的 / 代表 Windows 中的 C:\\cygwin。要转换 Cygwin 和 Windows 风格的路径可以用 cygpath。这在需要调用 Windows 程序的脚本里很有用。 学会使用 wmic，你就可以从命令行执行大多数 Windows 系统管理任务，并编成脚本。 要在 Windows 下获得 Unix 的界面和体验，另一个办法是使用 Cash。需要注意的是，这个环境支持的 Unix 命令和命令行参数非常少。 要在 Windows 上获取 GNU 开发者工具（比如 GCC）的另一个办法是使用 MinGW 以及它的 MSYS 软件包，该软件包提供了 bash、gawk、make、grep 等工具。然而 MSYS 提供的功能没有 Cygwin 完善。MinGW 在创建 Unix 工具的 Windows 原生移植方面非常有用。 更多资源 awesome-shell：一份精心组织的命令行工具及资源的列表。 awesome-osx-command-line：一份针对 OS X 命令行的更深入的指南。 Strict mode：为了编写更好的脚本文件。 shellcheck：一个静态 shell 脚本分析工具，本质上是 bash／sh／zsh 的 lint。 Filenames and Pathnames in Shell：有关如何在 shell 脚本里正确处理文件名的细枝末节。 Data Science at the Command Line：用于数据科学的一些命令和工具，摘自同名书籍。 免责声明 除去特别小的工作，你编写的代码应当方便他人阅读。能力往往伴随着责任，你 有能力 在 Bash 中玩一些奇技淫巧并不意味着你应该去做！😉 授权条款 本文使用授权协议 Creative Commons Attribution-ShareAlike 4.0 International License。","categories":[],"tags":[{"name":"command-line","slug":"command-line","permalink":"https://yuechuanx.top/tags/command-line/"}]},{"title":"关于串口调试自动化的解决方案","slug":"DevOps/serial-port-debug-env-automation","date":"2019-11-27T12:16:23.000Z","updated":"2020-04-23T03:36:06.714Z","comments":true,"path":"DevOps/serial-port-debug-env-automation/","link":"","permalink":"https://yuechuanx.top/DevOps/serial-port-debug-env-automation/","excerpt":"","text":"问题 在使用串口调试过程中，需要手动输入执行命令，交互性输入，以及等待执行结果。基本所有的信息都在 tty 中串行的进行显示。痛点有下面几个 重复命令手动输入执行 交互性输入 等待执行信息，不能自动保存到文件 串口调试环境本身edit 便利性 基于以上的问题，需要存在需求： 可以将执行命令存放脚本中，而且可以去调用执行 可处理交互性输入 对于执行命令输出可以保存到 log 文件 基本方案 基于 SecureCRT SecureCRT 脚本，使用 python 语言 优点： GUI 界面，操作直观 python syntax 语法特性支持强大 缺点： SecureCRT 过重，本身安装麻烦 仍然需要基本交互，SecureCRT 内调用脚本 与 jenkins 的集成 基于 Terminal 环境 首先要解决的是串口环境，这里使用 picocom 命令行工具，类似的有 minicom 等。 其次，针对需要交互行输入，使用 Expect 处理，Expect 基于 TCL (Tool control language） 最后，得到的 .expect 脚本可以通过 Jenkins pipeline 进行调用。 优点： 轻量化，可通过命令行安装 所有过程都在 Terminal 操作 集成到 Jenkins，完全支持自动化流程 缺点： picocom 在功能性方面较弱 ##实际解决 针对上面两种方案，如果是非重复性调试，使用前者上手更快。 如果有需要多次重复性，或者自动化测试需求，选择后者。 下面给出使用 Expect 的一个 demo： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#!/usr/bin/expect # -d: debug mode# expect configset timeout 30log_file test-expect.log# picocom configset baudrate \"115200\"set device \"/dev/ttyUSB0\"set prompt \"=&gt;\"# function defineset interval 5set iter_cnt 10proc start_xvr_debug &#123; prompt &#125; &#123; send \"xvr_client_dbus\\r\" expect $prompt&#125;proc test_switch_channel_display &#123; iter_cnt interval prompt &#125; &#123; for &#123; set i 1 &#125; &#123; $i &lt; $iter_cnt &#125; &#123; incr i 1 &#125; &#123; send \"switch_channel_display -cam 0 -ch 0 -onoff 1\\r\" expect $prompt exec sleep $interval send \"switch_channel_display -cam 0 -ch 0 -onoff 0\\r\" expect $prompt exec sleep $interval send \"switch_channel_display -cam 0 -ch 1 -onoff 1\\r\" expect $prompt exec sleep $interval send \"switch_channel_display -cam 0 -ch 1 -onoff 0\\r\" expect $prompt exec sleep $interval &#125;&#125;proc test_start_stop_pipeline &#123; iter_cnt interval prompt &#125; &#123; for &#123; set i 1 &#125; &#123; $i &lt; $iter_cnt &#125; &#123; incr i 1 &#125; &#123; send \"stop_pipeline /dev/xvr_pipeline-0\\r\" expect $prompt exec sleep $interval send \"stop_pipeline /dev/xvr_pipeline-1\\r\" expect $prompt exec sleep $interval send \"start_pipeline /dev/xvr_pipeline-0\\r\" expect $prompt exec sleep $interval send \"start_pipeline /dev/xvr_pipeline-1\\r\" expect $prompt exec sleep $interval &#125;&#125; spawn picocom -b $baudrate $deviceexpect \"Terminal ready\\r\"send \"\\r\"# send \"xvr_client_dbus\\r\" # expect $promptstart_xvr_debug $prompttest_switch_channel_display $iter_cnt $interval $prompt # test_start_stop_pipeline $iter_cnt $interval $prompt expect eof# interactwait 在具体使用中遇到的有几个小坑: 集成到 jenkins 时，jenkins 用户无法获得 /dev/ttyUSB0 权限。 sudo 执行 Expect 脚本进程 kill 详情见尾注意小节。 参考 SecureCRT-python-scripts Expect manual Expect 使用教程 Expect interact &amp; expect eof 注意 关于 jenkins 用户无法获取 /dev/ttyUSB0 权限 在这里最好不要直接使用 sudo ，使用 root 权限执行的坏处在于，当你想要中断 expect 脚本时，也必须使用 root 权限。并且在集成到 Jenkins 时，jenkins 用户起了 root 权限的进程，在中断 job 的时候。expect 任然在 jenkins node 上继续执行。 解决的方案是将 jenkins 用户加入拥有 dev 设备权限的用户组。 1sudo usermod aG dialout jenkins sudo 执行的 expect 进程kill sudo killall -u USER expect","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://yuechuanx.top/categories/DevOps/"}],"tags":[{"name":"automation","slug":"automation","permalink":"https://yuechuanx.top/tags/automation/"},{"name":"tool","slug":"tool","permalink":"https://yuechuanx.top/tags/tool/"}]},{"title":"HTTP 1.1 状态码分类及解释","slug":"http-status-code","date":"2019-11-26T11:34:49.000Z","updated":"2020-04-23T03:36:06.721Z","comments":true,"path":"http-status-code/","link":"","permalink":"https://yuechuanx.top/http-status-code/","excerpt":"","text":"HTTP 协议中状态码繁多，本文介绍 HPPT/1.1 协议中各种状态码 Hypertext Transfer Protocol – HTTP/1.1 123456789101112131415161718192021222324252627282930313233343536373839404142Status-Code = \"100\" ; Section 10.1.1: Continue | \"101\" ; Section 10.1.2: Switching Protocols | \"200\" ; Section 10.2.1: OK | \"201\" ; Section 10.2.2: Created | \"202\" ; Section 10.2.3: Accepted | \"203\" ; Section 10.2.4: Non-Authoritative Information | \"204\" ; Section 10.2.5: No Content | \"205\" ; Section 10.2.6: Reset Content | \"206\" ; Section 10.2.7: Partial Content | \"300\" ; Section 10.3.1: Multiple Choices | \"301\" ; Section 10.3.2: Moved Permanently | \"302\" ; Section 10.3.3: Found | \"303\" ; Section 10.3.4: See Other | \"304\" ; Section 10.3.5: Not Modified | \"305\" ; Section 10.3.6: Use Proxy | \"307\" ; Section 10.3.8: Temporary Redirect | \"400\" ; Section 10.4.1: Bad Request | \"401\" ; Section 10.4.2: Unauthorized | \"402\" ; Section 10.4.3: Payment Required | \"403\" ; Section 10.4.4: Forbidden | \"404\" ; Section 10.4.5: Not Found | \"405\" ; Section 10.4.6: Method Not Allowed | \"406\" ; Section 10.4.7: Not Acceptable | \"407\" ; Section 10.4.8: Proxy Authentication Required | \"408\" ; Section 10.4.9: Request Time-out | \"409\" ; Section 10.4.10: Conflict | \"410\" ; Section 10.4.11: Gone | \"411\" ; Section 10.4.12: Length Required | \"412\" ; Section 10.4.13: Precondition Failed | \"413\" ; Section 10.4.14: Request Entity Too Large | \"414\" ; Section 10.4.15: Request-URI Too Large | \"415\" ; Section 10.4.16: Unsupported Media Type | \"416\" ; Section 10.4.17: Requested range not satisfiable | \"417\" ; Section 10.4.18: Expectation Failed | \"500\" ; Section 10.5.1: Internal Server Error | \"501\" ; Section 10.5.2: Not Implemented | \"502\" ; Section 10.5.3: Bad Gateway | \"503\" ; Section 10.5.4: Service Unavailable | \"504\" ; Section 10.5.5: Gateway Time-out | \"505\" ; Section 10.5.6: HTTP Version not supported | extension-code 状态码分类 这些状态码被分为五大类： 100-199 用于指定客户端应相应的某些动作。 200-299 用于表示请求成功。 300-399 用于已经移动的文件并且常被包含在定位头信息中指定新的地址信息。 400-499 用于指出客户端的错误。 500-599 用于支持服务器错误。 HttpServletResponse中的常量代表关联不同标准消息的状态码。在servlet程序中，你会更多地用到这些常量的标识来使用状态码。例如：你一般会使用response.setStatus(response.SC_NO_CONTENT)而不是 response.setStatus(204)，因为后者不易理解而且容易导致错误。但是，你应当注意到服务器允许对消息轻微的改变，而客户端只注意状态码的数字值。所以服务器可能只返回 HTTP/1.1 200 而不是 HTTP/1.1 200 OK。 状态码详解 100 (Continue/继续) 如果服务器收到头信息中带有100-continue的请求，这是指客户端询问是否可以在后续的请求中发送附件。在这种情况下，服务器用100(SC_CONTINUE)允许客户端继续或用417 (Expectation Failed)告诉客户端不同意接受附件。这个状态码是 HTTP 1.1中新加入的。 101 (Switching Protocols/转换协议) 101 (SC_SWITCHING_PROTOCOLS)状态码是指服务器将按照其上的头信息变为一个不同的协议。这是 HTTP 1.1中新加入的。 200 (OK/正常) 200 (SC_OK)的意思是一切正常。一般用于相应GET和POST请求。这个状态码对servlet是缺省的；如果没有调用setStatus方法的话，就会得到200。 201 (Created/已创建) 201 (SC_CREATED)表示服务器在请求的响应中建立了新文档；应在定位头信息中给出它的URL。 202 (Accepted/接受) 202 (SC_ACCEPTED)告诉客户端请求正在被执行，但还没有处理完。 203 (Non-Authoritative Information/非官方信息) 状态码203 (SC_NON_AUTHORITATIVE_INFORMATION)是表示文档被正常的返回，但是由于正在使用的是文档副本所以某些响应头信息可能不正确。这是 HTTP 1.1中新加入的。 204 (No Content/无内容) 在并没有新文档的情况下，204 (SC_NO_CONTENT)确保浏览器继续显示先前的文档。这各状态码对于用户周期性的重载某一页非常有用，并且你可以确定先前的页面是否已经更新。例如，某个servlet可能作如下操作： 1234567891011int pageVersion =Integer.parseInt(request.getParameter(\"pageVersion\"));if (pageVersion &gt;;= currentVersion) &#123; response.setStatus(response.SC_NO_CONTENT);&#125; else &#123;​ // Create regular page&#125; 但是，这种方法对通过刷新响应头信息或等价的HTML标记自动重载的页面起作用，因为它会返回一个204状态码停止以后的重载。但基于JavaScript脚本的自动重载在这种情况下仍然需要能够起作用。可以阅读本书7.2 ( HTTP 1.1 Response Headers and Their Meaning/HTTP 1.1响应头信息以及他们的意义)部分的详细讨论。 205 (Reset Content/重置内容) 重置内容205 (SC_RESET_CONTENT)的意思是虽然没有新文档但浏览器要重置文档显示。这个状态码用于强迫浏览器清除表单域。这是 HTTP 1.1中新加入的。 206 (Partial Content/局部内容) 206 (SC_PARTIAL_CONTENT)是在服务器完成了一个包含Range头信息的局部请求时被发送的。这是 HTTP 1.1中新加入的。 300 (Multiple Choices/多重选择) 300 (SC_MULTIPLE_CHOICES)表示被请求的文档可以在多个地方找到，并将在返回的文档中列出来。如果服务器有首选设置，首选项将会被列于定位响应头信息中。 301 (Moved Permanently) 301 (SC_MOVED_PERMANENTLY)状态是指所请求的文档在别的地方；文档新的URL会在定位响应头信息中给出。浏览器会自动连接到新的URL。 302 (Found/找到) 与301有些类似，只是定位头信息中所给的URL应被理解为临时交换地址而不是永久的。注意：在 HTTP 1.0中，消息是临时移动(Moved Temporarily)的而不是被找到，因此HttpServletResponse中的常量是SC_MOVED_TEMPORARILY不是我们以为的SC_FOUND。 Notice 代表状态码302的常量是SC_MOVED_TEMPORARILY而不是SC_FOUND。 状态码302是非常有用的因为浏览器自动连接在定为响应头信息中给出的新URL。这非常有用，而且为此有一个专门的方法——sendRedirect。使用response.sendRedirect(url)比调用response.setStatus(response.SC_MOVED_TEMPORARILY)和response.setHeader(“Location”, url)多几个好处。首先，response.sendRedirect(url)方法明显要简单和容易。第二，servlet自动建立一页保存这一连接以提供给那些不能自动转向的浏览器显示。最后，在servlet 2.2版本（J2EE中的版本）中，sendRedirect能够处理相对路径，自动转换为绝对路径。但是你只能在2.1版本中使用绝对路径。 如果你将用户转向到站点的另一页中，你要用 HttpServletResponse 中的 encodeURL 方法传送URL。这么做可预防不断使用基于URL重写的会话跟踪的情况。URL重写是一种在你的网站跟踪不使用 cookies 的用户的方法。这是通过在每一个URL尾部附加路径信息实现的，但是 servlet 会话跟踪API会自动的注意这些细节。会话跟踪在第九章讨论，并且养成使用 encodeURL 的习惯会使以后添加会话跟踪的功能更容易很多。 核心技巧 如果你将用户转向到你的站点的其他页面，用 response.sendRedirect(response.encodeURL(url)) 的方式事先计划好会话跟踪(session tracking)要比只是调用 response.sendRedirect(url) 好的多。 这个状态码有时可以与301交换使用。例如，如果你错误的访问了http://www.talentdigger.cn/home/link.php?url=aG9zdC9%2BdXNlcg%3D%3D（路径信息不完整），有些服务器就会回复301状态码而有些则回复302。从技术上说，如果最初的请求是GET浏览器只是被假定自动转向。如果想了解更多细节，请看状态码307的讨论。 303 (See Other/参见其他信息) 这个状态码和 301、302 相似，只是如果最初的请求是 POST，那么新文档（在定位头信息中给出）药用 GET 找回。这个状态码是新加入 HTTP 1.1中的。 304 (Not Modified/为修正) 当客户端有一个缓存的文档，通过提供一个 If-Modified-Since 头信息可指出客户端只希望文档在指定日期之后有所修改时才会重载此文档，用这种方式可以进行有条件的请求。304 (SC_NOT_MODIFIED)是指缓冲的版本已经被更新并且客户端应刷新文档。另外，服务器将返回请求的文档及状态码 200。servlet一般情况下不会直接设置这个状态码。它们会实现getLastModified方法并根据修正日期让默认服务方法处理有条件的请求。这个方法的例程已在2.8部分(An Example Using Servlet Initialization and Page Modification Dates/一个使用servlet初始化和页面修正日期的例子)给出。 305 (Use Proxy/使用代理) 305 (SC_USE_PROXY)表示所请求的文档要通过定位头信息中的代理服务器获得。这个状态码是新加入 HTTP 1.1中的。 307 (Temporary Redirect/临时重定向) 浏览器处理307状态的规则与302相同。307状态被加入到 HTTP 1.1中是由于许多浏览器在收到302响应时即使是原始消息为POST的情况下仍然执行了错误的转向。只有在收到303响应时才假定浏览器会在POST请求时重定向。添加这个新的状态码的目的很明确：在响应为303时按照GET和POST请求转向；而在307响应时则按照GET请求转向而不是POST请求。注意：由于某些原因在HttpServletResponse中还没有与这个状态对应的常量。该状态码是新加入HTTP 1.1中的。 注意 在 HttpServletResponse 中没有 SC_TEMPORARY_REDIRECT 常量，所以你只能显示的使用307状态码。 400 (Bad Request/错误请求) 400 (SC_BAD_REQUEST)指出客户端请求中的语法错误。 401 (Unauthorized/未授权) 401 (SC_UNAUTHORIZED)表示客户端在授权头信息中没有有效的身份信息时访问受到密码保护的页面。这个响应必须包含一个WWW-Authenticate的授权信息头。例如，在本书4.5部分中的“Restricting Access to Web Pages./限制访问Web页。” 403 (Forbidden/禁止) 403 (SC_FORBIDDEN)的意思是除非拥有授权否则服务器拒绝提供所请求的资源。这个状态经常会由于服务器上的损坏文件或目录许可而引起。 404 (Not Found/未找到) 404 (SC_NOT_FOUND)状态每个网络程序员可能都遇到过，他告诉客户端所给的地址无法找到任何资源。它是表示“没有所访问页面”的标准方式。这个状态码是常用的响应并且在HttpServletResponse类中有专门的方法实现它：sendError(“message”)。相对于setStatus使用sendError得好处是：服务器会自动生成一个错误页来显示错误信息。但是，Internet Explorer 5浏览器却默认忽略你发挥的错误页面并显示其自定义的错误提示页面，虽然微软这么做违反了 HTTP 规范。要关闭此功能，在工具菜单里，选择Internet选项，进入高级标签页，并确认“显示友好的 HTTP 错误信息”选项（在我的浏览器中是倒数第8各选项）没有被选。但是很少有用户知道此选项，因此这个特性被IE5隐藏了起来使用户无法看到你所返回给用户的信息。而其他主流浏览器及IE4都完全的显示服务器生成的错误提示页面。可以参考图6-3及6-4中的例子。 核心警告 默认情况下，IE5忽略服务端生成的错误提示页面。 405 (Method Not Allowed/方法未允许) 405 (SC_METHOD_NOT_ALLOWED)指出请求方法(GET, POST, HEAD, PUT, DELETE, 等)对某些特定的资源不允许使用。该状态码是新加入 HTTP 1.1中的。 406 (Not Acceptable/无法访问) 406 (SC_NOT_ACCEPTABLE)表示请求资源的MIME类型与客户端中Accept头信息中指定的类型不一致。见本书7.2部分中的表7.1(HTTP 1.1 Response Headers and Their Meaning/HTTP 1.1响应头信息以及他们的意义)中对MIME类型的介绍。406是新加入 HTTP 1.1中的。 407 (Proxy Authentication Required/代理服务器认证要求) 407 (SC_PROXY_AUTHENTICATION_REQUIRED)与401状态有些相似，只是这个状态用于代理服务器。该状态指出客户端必须通过代理服务器的认证。代理服务器返回一个Proxy-Authenticate响应头信息给客户端，这会引起客户端使用带有Proxy-Authorization请求的头信息重新连接。该状态码是新加入 HTTP 1.1中的。 408 (Request Timeout/请求超时) 408 (SC_REQUEST_TIMEOUT)是指服务端等待客户端发送请求的时间过长。该状态码是新加入 HTTP 1.1中的。 409 (Conflict/冲突) 该状态通常与PUT请求一同使用，409 (SC_CONFLICT)状态常被用于试图上传版本不正确的文件时。该状态码是新加入 HTTP 1.1中的。 410 (Gone/已经不存在) 410 (SC_GONE)告诉客户端所请求的文档已经不存在并且没有更新的地址。410状态不同于404，410是在指导文档已被移走的情况下使用，而404则用于未知原因的无法访问。该状态码是新加入 HTTP 1.1中的。 411 (Length Required/需要数据长度) 411 (SC_LENGTH_REQUIRED)表示服务器不能处理请求（假设为带有附件的POST请求），除非客户端发送Content-Length头信息指出发送给服务器的数据的大小。该状态是新加入 HTTP 1.1的。 412 (Precondition Failed/先决条件错误) 412 (SC_PRECONDITION_FAILED)状态指出请求头信息中的某些先决条件是错误的。该状态是新加入 HTTP 1.1的。 413 (Request Entity Too Large/请求实体过大) 413 (SC_REQUEST_ENTITY_TOO_LARGE)告诉客户端现在所请求的文档比服务器现在想要处理的要大。如果服务器认为能够过一段时间处理，则会包含一个Retry-After的响应头信息。该状态是新加入 HTTP 1.1的。 414 (Request URI Too Long/请求URI过长) 414 (SC_REQUEST_URI_TOO_LONG)状态用于在URI过长的情况时。这里所指的“URI”是指URL中主机、域名及端口号之后的内容。例如：在URL–http://www.y2k-disaster.com:8080/we/look/silly/now/中URI是指/we/look/silly/now/。该状态是新加入 HTTP 1.1的。 415 (Unsupported Media Type/不支持的媒体格式) 415 (SC_UNSUPPORTED_MEDIA_TYPE)意味着请求所带的附件的格式类型服务器不知道如何处理。该状态是新加入 HTTP 1.1的。 416 (Requested Range Not Satisfiable/请求范围无法满足) 416表示客户端包含了一个服务器无法满足的Range头信息的请求。该状态是新加入 HTTP 1.1的。奇怪的是，在servlet 2.1版本API的HttpServletResponse中并没有相应的常量代表该状态。 注意 在servlet 2.1的规范中，类HttpServletResponse并没有SC_REQUESTED_RANGE_NOT_SATISFIABLE 这样的常量，所以你只能直接使用416。在servlet 2.2版本之后都包含了此常量。 417 (Expectation Failed/期望失败) 如果服务器得到一个带有100-continue值的Expect请求头信息，这是指客户端正在询问是否可以在后面的请求中发送附件。在这种情况下，服务器也会用该状态(417)告诉浏览器服务器不接收该附件或用100 (SC_CONTINUE)状态告诉客户端可以继续发送附件。该状态是新加入 HTTP 1.1的。 500 (Internal Server Error/内部服务器错误) 500 (SC_INTERNAL_SERVER_ERROR) 是常用的“服务器错误”状态。该状态经常由CGI程序引起也可能（但愿不会如此！）由无法正常运行的或返回头信息格式不正确的servlet引起。 501 (Not Implemented/未实现) 501 (SC_NOT_IMPLEMENTED)状态告诉客户端服务器不支持请求中要求的功能。例如，客户端执行了如PUT这样的服务器并不支持的命令。 502 (Bad Gateway/错误的网关) 502 (SC_BAD_GATEWAY)被用于充当代理或网关的服务器；该状态指出接收服务器接收到远端服务器的错误响应。 503 (Service Unavailable/服务无法获得) 状态码503 (SC_SERVICE_UNAVAILABLE)表示服务器由于在维护或已经超载而无法响应。例如，如果某些线程或数据库连接池已经没有空闲则servlet会返回这个头信息。服务器可提供一个Retry-After头信息告诉客户端什么时候可以在试一次。 504 (Gateway Timeout/网关超时) 该状态也用于充当代理或网关的服务器；它指出接收服务器没有从远端服务器得到及时的响应。该状态是新加入 HTTP 1.1的。 505 (HTTP Version Not Supported/不支持的 HTTP 版本) 505 (SC_HTTP_VERSION_NOT_SUPPORTED)状态码是说服务器并不支持在请求中所标明 HTTP 版本。该状态是新加入 HTTP 1.1的。","categories":[],"tags":[{"name":"http","slug":"http","permalink":"https://yuechuanx.top/tags/http/"}]},{"title":"Git LFS 上手指南","slug":"DevOps/git-with-large-file-storage","date":"2019-11-02T15:43:39.000Z","updated":"2020-04-23T03:36:06.712Z","comments":true,"path":"DevOps/git-with-large-file-storage/","link":"","permalink":"https://yuechuanx.top/DevOps/git-with-large-file-storage/","excerpt":"","text":"毫无疑问, git 是一个伟大的工具. 但 git 适合管理文件类型是文本类型. 在处理二进制文件的时候就相对乏力了. 如何解决 git 对于二进制文件的处理, 需要介绍 git-lfs 工具 Git LFS 简介 Git LFS（Large File Storage, 大文件存储）是 Github 开发的一个 Git 的扩展，用于实现 Git 对大文件的支持。 Git LFS可以把音乐、图片、视频等指定的任意文件存在 Git 仓库之外，而在 Git 仓库中用一个占用空间 1KB 不到的文本指针来代替文件的存在。 通过把大文件存储在 Git 仓库之外，可以减小 Git 仓库本身的体积，使克隆 Git 仓库的速度加快，也使得 Git 不会因为仓库中充满大文件而损失性能。 使用 Git LFS，在默认情况下，只有当前签出的 commit 下的 LFS 对象的当前版本会被下载。此外，我们也可以做配置，只取由 Git LFS 管理的某些特定文件的实际内容，而对于其他由 Git LFS 管理的文件则只保留文件指针，从而节省带宽，加快克隆仓库的速度；也可以配置一次获取大文件的最近版本，从而能方便地检查大文件的近期变动。详见后文进阶使用。 要使用 Git LFS 只需要经过一次下载安装后，指定需要由 Git LFS 管理的文件即可。 Git LFS 下载和安装 注意：安装 Git LFS 需要 Git 的版本不低于 1.8.5 Windows 系统 通过官方地址下载 Git LFS 安装包 Windows Installer. 双击安装包，打开安装 git-lfs 在命令行中执行 git lfs install（需要确认 git-lfs 命令已经被包含在环境变量中） BSD / Linux 系统 12345curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bashsudo apt-get install git-lfsgit lfs install macOS 系统 123brew install git-lfsgit lfs install Git LFS 配置 使用 git lfs track 追踪需要使用 Git LFS 管理的文件。如： git lfs track &quot;*.psd” 也可以手动编辑 Git 仓库根目录下的 .gitattributes 文件，如： *.psd filter=lfs diff=lfs merge=lfs -text 常用 Git LFS 命令 查看当前使用 Git LFS 管理的匹配列表 git lfs track 使用 Git LFS 管理指定的文件 git lfs track &quot;*.psd” 不再使用 Git LFS 管理指定的文件 git lfs untrack &quot;*.psd” 类似 git status，查看当前 Git LFS 对象的状态 git lfs status 枚举目前所有被 Git LFS 管理的具体文件 git lfs ls-files 检查当前所用 Git LFS 的版本 git lfs version 针对使用了 LFS 的仓库进行了特别优化的 clone 命令，显著提升获取LFS 对象的速度，接受和 git clone 一样的参数。 git lfs clone https://gitee.com/user/repo.git git lfs clone 通过合并获取 LFS 对象的请求，减少了 LFS API 的调用，并行化 LFS 对象的下载，从而达到显著的速度提升。git lfs clone 命令同样也兼容没有使用 LFS 的仓库。即无论要克隆的仓库是否使用 LFS，都可以使用 git lfs clone 命令来进行克隆。 目前最新版本的 git clone 已经能够提供与 git lfs clone 一致的性能，因此自 Git LFS 2.3.0 版本起，git lfs clone 已不再推荐使用。 Git LFS 进阶使用 使用 Git LFS 的核心思想就是把需要进行版本管理、但又占用很大空间的那部分文件独立于 Git 仓库进行管理。从而加快克隆仓库本身的速度，同时获得灵活的管理 LFS 对象的能力。 默认情况下，只有当前 commit 下的 LFS 对象的当前版本才会被获取。 只获取仓库本身，而不获取任何 LFS 对象 如果自己的相关工作不涉及到被 Git LFS 所管理的文件的话，可以选择只获取 Git 仓库自身的内容，而完全跳过 LFS 对象的获取。 123GIT_LFS_SKIP_SMUDGE=1 git clone https://gitee.com/user/repo.git# 或git -c filter.lfs.smudge= -c filter.lfs.required=false clone https://gitee.com/user/repo.git 注：GIT_LFS_SKIP_SMUDGE=1 及 git -c filter.lfs.smudge= -c filter.lfs.required=false 同样使用于其他 git 命令，如 checkout, reset 等。 获取当前 commit 下包含的 LFS 对象的当前版本 如果起初获取代码时，没有一并获取 LFS 对象，而随后又需要这些被 LFS 管理的文件时，可以单独执行 LFS 命令来获取并签出 LFS 对象： 1234git lfs fetchgit lfs checkout# 或git lfs pull 仅获取指定目录下的 LFS 对象 比如说，我们有一仓库，里面包含了许多源代码文件，以及一些图像、视频等资源文件，其目录结构如下： 123456789101112zzz.buzz├── images│ ├── cat.png│ ├── dog.gif│ └── rabbit.webp├── src│ ├── buzz.css│ ├── index.html│ └── zzz.js└── videos├── chameleon.mp4└── iguana.webm 其中的 images/** 以及 videos/** 是被 LFS 所管理的。 但是，如果只想取 images 文件夹，而不想获取 videos 文件夹下的文件的话，我们就可以选择配置 LFS 下载对象时仅包含 images 文件夹： git config lfs.fetchinclude 'images/**’ 随后，git checkout, git reset, git lfs fetch, git lfs pull 等命令就都会只处理所指定的文件夹。 类似地，我们也可以选择仅排除指定的文件夹： git config lfs.fetchexclude 'videos/**’ 也可以同时使用黑白名单规则，这样只有同时满足 include 规则和 exclude 规则的大文件才会被获取： 123git config lfs.fetchinclude 'videos/**'git config lfs.fetchexclude 'videos/chameleon.mp4'# 在此例中，如此配置将只会获取 videos/iguana.webm 一个文件。 一次获取 LFS 对象的最近版本 Git LFS 相关命令在获取 LFS 对象时，默认仅会获取该对象当前被引用的版本，如果想要一次获取 LFS 对象的当前及最近版本的话，我们首先需要对最近进行定义： git config lfs.fetchrecentcommitsdays 7 7 表示同时下载过去 7 天内的版本（相对于获取的 LFS 对象的时间），该项配置默认值为 0，即不获取过去的版本，而仅获取指定的版本。 有了对最近的定义后，我们可以选择在执行 git lfs fetch 命令时，加上 --recent 参数以同时获取最近版本； 或者配置 git config lfs.fetchrecentalways true 从而总是同时获取 LFS 对象的最近版本。 常见问题 在安装 Git LFS 之前，克隆了使用 Git LFS 的仓库，则被 Git LFS 管理的文件会被显示为文本指针，而非具体的文件。 查看这些文件指针，会发现类似如下内容： 12version https://git-lfs.gitee.com/spec/v1oid sha256:4b99dbe6fe6f646b2026de93481045bbf34f995559db15fce34d192f1f320ef4size 156154 解决办法就是，手动执行获取 Git LFS 对象的命令： 1234git lfs fetchgit lfs checkout# 或git lfs pull Git LFS 对象在本地仓库的存放位置？ 通过 Git LFS 所管理的对象实际在本地的存储位置是在 .git/lfs/objects 目录下，该目录根据对象的 sha256 值来组织。 作为对比，Git 自身所管理的对象则是存储在 .git/objects 目录下，根据 commit, tree, blob, tag 的 sha1 值来组织。 已经使用 git lfs track somefile 追踪了某个文件，但该文件并未以 LFS 存储。 如果被 LFS 追踪管理的文件的大小为 0 的话，则该文件不会以 LFS 的形式存储起来。 只有当一个文件至少有 1 个字节时，其才会以 LFS 的形式存储。 注：一般使用 LFS 时，我们也不会用其追踪空文件，即使追踪了空文件，对于使用也没有任何影响。提到这点主要是为了消除在测试使用 LFS 时可能遇到的困惑。 执行 git lfs fetch 或 git lfs pull 时报错 batch request: exit status 255: Permission denied (publickey,gssapi-keyex,gssapi-with-mic). 如果在克隆仓库时使用了 SSH 协议，而本地的 SSH 私钥又有密码保护，那么向服务器获取文件时就会报错，因为目前 Git LFS 不会向用户请求密码，从而导致认证失败。 解决办法是使用 ssh-add 命令，预先加载好本地的 SSH 私钥，从而使得 Git LFS 能够访问到私钥。 GitLFS 参考文章 https://zzz.buzz/zh/2016/04/19/the-guide-to-git-lfs/","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://yuechuanx.top/categories/DevOps/"}],"tags":[]},{"title":"GitLab 迁移与升级","slug":"DevOps/gitlab-data-migrate-and-upgrade","date":"2019-11-01T12:16:23.000Z","updated":"2020-04-23T03:36:06.712Z","comments":true,"path":"DevOps/gitlab-data-migrate-and-upgrade/","link":"","permalink":"https://yuechuanx.top/DevOps/gitlab-data-migrate-and-upgrade/","excerpt":"","text":"公司内部的 SDK 版本是通过 GItlab 进行版本管理，而在 SDK 中存在着大量的二进制文件，在进行多次版本发布之后，.git 文件越来越大，pull 新版本的时间也越来越长。 背景 Git LFS 工具可以很好的解决这个问题，通过将二进制文件直接上传的方式，git 只需要保存字符链接，关于 git LFS 的原理可以看这里： 那么问题来了，由于 gitlab 的开始对 LFS 的版本高于目前公司使用的版本，所以我们需要给 gitlab 进行升级。 思路 之前的 gitlab 的部署是通过 bitnami 的 VM 部署到 host 机器上的，想转到用 docker 来进行部署。 首先我预想的方式是，将之前的 bitnami VM 的备份导入到 dockerhub 对应版本的镜像，在 Restore 之后换成更高版本的 gitlab image。不过很遗憾，这个方法失败了，gitlab 的升级需要递进的升级，在这里给出官方推荐的升级路线： pic 那么换一种思路，先把之前的备份先恢复到对应的 gitlab image 上，在容器内部进行升级，之后再做一个备份，迁移到更高版本的 gitlab image。结论是，这个方法是可行的。 踩坑 前期准备： gitlab 8.5.1 备份 Linux server with docker 了解关于与备份恢复相关的一些命令： 12345678910111213# 查看 gitlab 版本gitlab-rake gitlab:env:info# 创建备份gitlab-rake gitlab:backup:create# 恢复备份# 停止相关数据连接服务gitlab-ctl stop unicorngitlab-ctl stop sidekiq# 从备份中恢复，通过备份文件名前缀选择gitlab-rake gitlab:backup:restore BACKUP=1572508219_2019_10_31_11.3.4 创建备份后得到一个文件 1572508219_2019_10_31_11.3.4_gitlab_backup.tar 根据查看的 gitlab 版本为 8.5.1 docker pull gitlab/gitlab-ce:8.5.1-ce.0 运行： 12345678910111213#!/bin/bashsudo docker run --detach \\ --hostname gitlab.qa \\ --publish 443:443 --publish 80:80 --publish 22:22 \\ --name gitlab \\ --restart always \\ --volume /srv/gitlab/config:/etc/gitlab \\ --volume /srv/gitlab/logs:/var/log/gitlab \\ --volume /srv/gitlab/data:/var/opt/gitlab \\ --volume /srv/gitlab/logs/reconfigure:/var/log/gitlab/reconfigure \\ --env GITLAB_OMNIBUS_CONFIG=\"external_url 'http://192.168.205.236';\" \\ gitlab/gitlab-ce:8.5.1-ce.0 关于--volume /srv/gitlab/logs/reconfigure:/var/log/gitlab/reconfigure \\： 如果去掉会有如下错误 ![image-20191101120624086](/Users/Xiaoy/Library/Application Support/typora-user-images/image-20191101120624086.png) docker exec -ti gitlab /bin/bash 进入容器， 首先进行恢复 123sudo gitlab-ctl stop unicornsudo gitlab-ctl stop sidekiqgitlab-rake gitlab:backup:restore BACKUP=1572508219_xxxx 如果在恢复前对 gitlab 进行过设置，恢复时候将会覆盖掉，所以最好是在一个干净的 server 上进行恢复 恢复后按照官方推荐的方式逐个版本升级 GitLab Release and Maintenance Policy 升级过程： Tips:由于某ZZ的墙的原因,使用Gitlab的官方apt源会出现下载不了，可以选择清华的镜像，你也可以使用apt-mirror来自建本地的apt源(https://packages.gitlab.com/gitlab/gitlab-ce/mirror)但是版本可能会跟不上官方的更新。 先进行数据的备份,这一步可以省略，因为gitlab在升级的时候会自动为你备份 gitlab-rake gitlab :backup :create RAILS_ENV=production 下载官方的提供的apt源自动更新脚本 我的是ubuntu系统，所以选择的是apt源官方的package list 地址: 手动更新apt源，最终我采用的是官方提供的这个文档：https://packages.gitlab.com/gitlab/gitlab-ce/install#manual refreshing package cache : sudo apt-get update Ensure the required tools are installed before proceeding sudo apt-get install curl gnupg apt-transport-https install GPG Key: curl -L https://packages.gitlab.com/gitlab/gitlab-ce/gpgkey | sudo apt-key add – create apt file: /etc/apt/sources.list.d/gitlab_gitlab_ce.list ,please include repository configuration below : 如果是ubuntu 系统如下: 12deb https://packages.gitlab.com/gitlab/gitlab-ce/ubuntu/ trusty maindeb-src https://packages.gitlab.com/gitlab/gitlab-ce/ubuntu/ trusty main 如果是别的Linux Distribution and version ，参考如下的文档: https://packagecloud.io/docs#os_distro_version sudo apt-get update apt源配置完毕，下面可是执行上面的安装命令: 先升级到9.5.0 sudo apt-get install gitlab-ce=9.5.1-ce.0 完毕后没有问题,要重启gitlab-ctl restart 升级到10.8.7 sudo apt-get install gitlab-ce=10.8.7-ce.0 没有问题，重启sudo gitlab-ctl restart 升级到最新版: sudo apt-get install gitlab-ce 最后一部，如果没有大的版本发布，直接执行install 就行 没有问题，重启sudo gitlab-ctl restart 至此，gitlab的升级完成 在升级好的 gitlab 上进行备份gitlab-rake gitlab:backup:create 再次迁移，即可 关于常见报错 访问 500 错误 Reference Gitlab 升级总结 Gitlab 无损升级 Git 迁移到 Git LFS 实践 GitLab数据备份与恢复 Migrate a Git repo into Git LFS with BFG 化繁为简的企业级 Git 管理实战（五）：二进制大文件的版本控制","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://yuechuanx.top/categories/DevOps/"}],"tags":[{"name":"gitlab","slug":"gitlab","permalink":"https://yuechuanx.top/tags/gitlab/"}]},{"title":"Jenkins Testlink Plugin 源码笔记","slug":"DevOps/jenkins-testlink-plugin-source-code-note","date":"2019-10-27T12:16:23.000Z","updated":"2020-04-23T03:36:06.713Z","comments":true,"path":"DevOps/jenkins-testlink-plugin-source-code-note/","link":"","permalink":"https://yuechuanx.top/DevOps/jenkins-testlink-plugin-source-code-note/","excerpt":"","text":"需求 Testlink 的 testcase 可以通过 Jenkins 去执行，当 Jenkins job 执行完之后，可以将执行结果保存到 Testlink 中。 jenkins 中 testlink plugin 仅仅可以在 freestyle 项目类型中使用，但目前大多数的 job 已经转移到 pipeline 类型，所以 testlink plugin 支持 pipeline 是一个自然的需要。 思路 首先查到官方 Testlink-plugin 的 repo https://github.com/jenkinsci/testlink-plugin pull 到本地查看一下项目结构 123456789├── pom.xml ├── src │ ├── main│ │ ├── java│ │ ├── resources│ │ └── webapp│ └── test│ ├── java│ └── resources 其中主要代码存放在 src/main/hudson/plugins/testlink 下： 123456789101112131415161718192021222324252627282930313233├── AbstractTestLinkBuilder.java├── AbstractTestLinkProjectAction.java├── GraphHelper.java├── Report.java├── TestLinkBuildAction.java├── TestLinkBuilder.java├── TestLinkBuilderDescriptor.java├── TestLinkInstallation.java├── TestLinkJunitWrapper.java├── TestLinkProjectAction.java├── TestLinkResult.java├── TestLinkSite.java├── result│ ├── AbstractJUnitResultSeeker.java│ ├── AbstractTAPFileNameResultSeeker.java│ ├── AbstractTestNGResultSeeker.java│ ├── JUnitCaseClassNameResultSeeker.java│ ├── JUnitCaseNameResultSeeker.java│ ├── JUnitMethodNameResultSeeker.java│ ├── JUnitSuiteNameResultSeeker.java│ ├── ResultSeeker.java│ ├── ResultSeekerDescriptor.java│ ├── ResultSeekerException.java│ ├── TAPFileNameMultiTestPointsResultSeeker.java│ ├── TAPFileNameResultSeeker.java│ ├── TestCaseWrapper.java│ ├── TestNGClassNameResultSeeker.java│ ├── TestNGMethodNameDataProviderNameResultSeeker.java│ ├── TestNGMethodNameResultSeeker.java│ └── TestNGSuiteNameResultSeeker.java└── util ├── ExecutionOrderComparator.java └── TestLinkHelper.java 现在可以来对代码进行分析了，首先我们寻找到调用的入口 TestlinkBuilder.java 定位到 perfrom() 函数 123public boolean perform(AbstractBuild&lt;?, ?&gt; build, Launcher launcher, BuildListener listener) throws InterruptedException, IOException &#123; // function body &#125; 可以看到入参列表： AbstractBuild&lt;?, ?&gt; build Launcher BuildListener 接下来看函数体内容： 1234567// TestLink installationlistener.getLogger().println(Messages.TestLinkBuilder_PreparingTLAPI());final TestLinkInstallation installation = DESCRIPTOR.getInstallationByTestLinkName(this.testLinkName);if (installation == null) &#123;throw new AbortException(Messages.TestLinkBuilder_InvalidTLAPI());&#125; TestlinkInstallation 保存 configuration 里面对 Testlink 的配置信息: 包括 name, url, devKey, testlinkJavaAPIProperties 接下来是初始化其他的东西 12345678910TestLinkHelper.setTestLinkJavaAPIProperties(installation.getTestLinkJavaAPIProperties(), listener);final TestLinkSite testLinkSite;final TestCaseWrapper[] automatedTestCases;final String testLinkUrl = installation.getUrl();final String testLinkDevKey = installation.getDevKey();TestPlan testPlan;listener.getLogger().println(Messages.TestLinkBuilder_UsedTLURL(testLinkUrl));...testLinkSite = this.getTestLinkSite(testLinkUrl, testLinkDevKey, testProjectName, testPlanName, platformName, buildName, buildCustomFields, buildNotes); TestlinkSite 成员里有 TestlinkAPI, 可以通过传入 configuration 里面所设置的参数对 Testlink 进行操作。 12345678910final String[] testCaseCustomFieldsNames = TestLinkHelper.createArrayOfCustomFieldsNames(build.getBuildVariableResolver(), build.getEnvironment(listener), this.getCustomFields());// Array of automated test casesTestCase[] testCases = testLinkSite.getAutomatedTestCases(testCaseCustomFieldsNames);// Retrieve custom fields in test planfinal String[] testPlanCustomFieldsNames = TestLinkHelper.createArrayOfCustomFieldsNames(build.getBuildVariableResolver(), build.getEnvironment(listener), this.getTestPlanCustomFields());testPlan = testLinkSite.getTestPlanWithCustomFields(testPlanCustomFieldsNames);// Transforms test cases into test case wrappersautomatedTestCases = this.transform(testCases); 获取 CustomFields ， 通过TestlinkSite 拿到对应的 (List)Testcase，转换为(List)TestlinkWrapper, 针对其进行了一层封装，具体细节看 result/TestcaseWrapper.java. 123456for(TestCaseWrapper tcw : automatedTestCases) &#123; testLinkSite.getReport().addTestCase(tcw); if(LOGGER.isLoggable(Level.FINE)) &#123; LOGGER.log(Level.FINE, \"TestLink automated test case ID [\" + tcw.getId() + \"], name [\" +tcw.getName()+ \"]\"); &#125;&#125; TestSite中有成员 Report，用来存储基本的 Testcase，以及 TestStatus 这些信息 123456if(getResultSeekers() != null) &#123; for (ResultSeeker resultSeeker : getResultSeekers()) &#123; LOGGER.log(Level.INFO, \"Seeking test results. Using: \" + resultSeeker.getDescriptor().getDisplayName()); resultSeeker.seek(automatedTestCases, build, build.getWorkspace(), launcher, listener, testLinkSite); &#125;&#125; ResultSeeker 通过执行测试用例得到的 *report.xml 文件解析得到相应 Testcase 的执行结果。 123456final Report report = testLinkSite.getReport();report.tally();...final TestLinkResult result = new TestLinkResult(report);final TestLinkBuildAction buildAction = new TestLinkBuildAction(result);build.addAction(buildAction); 最后一步，生成 TestlinkReport，这里的对应的是 Jenkins 显示的report，而不是 TestlinkAPI 的 report。 执行逻辑结束。 后记 在完成这篇文章之前，我对于能否清晰的表达出我的分析有很大的怀疑。我之前也曾阅读过源码，是关于数据结构的。针对大的，互相有依赖的，以一定代码规模的，我不曾分析过。 在阅读源码的时候，获得了以下几个小的知识点 从入口到各个模块的调用，是阅读源码的脉络 不要一开始纠结于细节。大致了解各个功能模块的作用就行 良好的抽象能力是关键技能","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://yuechuanx.top/categories/DevOps/"}],"tags":[{"name":"jenkins","slug":"jenkins","permalink":"https://yuechuanx.top/tags/jenkins/"},{"name":"testlink","slug":"testlink","permalink":"https://yuechuanx.top/tags/testlink/"},{"name":"plugin","slug":"plugin","permalink":"https://yuechuanx.top/tags/plugin/"}]},{"title":"VSCode 插件开发入门","slug":"vscode-plugin-dev-intro","date":"2019-04-02T05:49:04.000Z","updated":"2020-04-23T03:36:06.723Z","comments":true,"path":"vscode-plugin-dev-intro/","link":"","permalink":"https://yuechuanx.top/vscode-plugin-dev-intro/","excerpt":"","text":"核心组件 Electron Monaco Editor Language Server Protocol Debug Adapter Protocol Electorn (formerly Atom Shell) 基于 Node.js（作为后端）和 Chromium（作为前端) 使用 HTML, CSS 和 JavaScript 开发跨平台桌面GUI应用程序 使用者：Atom, Skype, GitHub Desktop, Slack, Microsoft Teams … Github传送门 Monaca Editor 基于浏览器的代码编辑器：IntelliSense，代码验证，语法高亮，文件比较 … 支持主流浏览器：IE 11, Edge, Chrome, Firefox, Safari 和 Opera 使用者：Gitee Web IDE, Cloud Studio, Eclipse Che, Eclipse Theia, Azure DevOps (原为 Visual Studio Team Services), OneDrive, Edge Dev Tools GitHub传送门 Language Server Protocol (LSP) 它是 Editor/IDE 与语言服务器之间的一种协议，可以让不同的 Editor/IDE 方便嵌入各种程序语言，允许开发人员在最喜爱的工具中使用各种语言来撰写程序。 支持 LSP 的开发工具: Eclipse IDE, Eclipse Theia, Atom, Sublime Text, Emacs GitHub传送门 Debug Adapter Protocol (DAP) DAP 与 LSP 的目的类似，DAP 把 Editor/IDE 与 不同语言的 debugger 解耦，极大地方便了 Editor/IDE 与其他 Debugger 的集成。 支持 DAP 的开发工具: Eclipse IDE, Eclipse Theia, Emacs, Vim GitHub传送门 插件开发流程 开发环境 Visual Studio Code Node.js npm -v 查看是否安装成功 Yeoman and VS Code Extension generator: npm install -g yo generator-code 插件类型 Themes Snippets Formatters Linters Debuggers Programming Languages Keymaps SCM Provides Extensions Packs Others 如何搭建工程 yo code 选择你搭建项目的类型 是否导入相关资源 选择名字 e.g. Color Thems e.g. Code Snippet VSCode 界面功能拓展 Workbench Editor area Workbench Editor Area Codelens Decoration Gutter Hover Context Menu e.g. Translator Extension","categories":[],"tags":[{"name":"vscode","slug":"vscode","permalink":"https://yuechuanx.top/tags/vscode/"}]},{"title":"<Java容器> ArrayList扩容源码分析","slug":"Java/ArrayList-Grow","date":"2019-01-03T12:10:39.000Z","updated":"2020-04-23T03:36:06.714Z","comments":true,"path":"Java/ArrayList-Grow/","link":"","permalink":"https://yuechuanx.top/Java/ArrayList-Grow/","excerpt":"","text":"一 先从 ArrayList 的构造函数说起 ArrayList有三种方式来初始化，构造方法源码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 默认初始容量大小 */ private static final int DEFAULT_CAPACITY = 10; private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; /** *默认构造函数，使用初始容量10构造一个空列表(无参数构造) */ public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; /** * 带初始容量参数的构造函数。（用户自己指定容量） */ public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123;//初始容量大于0 //创建initialCapacity大小的数组 this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123;//初始容量等于0 //创建空数组 this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123;//初始容量小于0，抛出异常 throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); &#125; &#125;/** *构造包含指定collection元素的列表，这些元素利用该集合的迭代器按顺序返回 *如果指定的集合为null，throws NullPointerException。 */ public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; 细心的同学一定会发现 ：以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为10。 下面在我们分析 ArrayList 扩容时会讲到这一点内容！ 二 一步一步分析 ArrayList 扩容机制 这里以无参构造函数创建的 ArrayList 为例分析 1. 先来看 add 方法 12345678910 /** * 将指定的元素追加到此列表的末尾。 */ public boolean add(E e) &#123;//添加元素之前，先调用ensureCapacityInternal方法 ensureCapacityInternal(size + 1); // Increments modCount!! //这里看到ArrayList添加元素的实质就相当于为数组赋值 elementData[size++] = e; return true; &#125; 2. 再来看看 ensureCapacityInternal() 方法 可以看到 add 方法 首先调用了ensureCapacityInternal(size + 1) 123456789//得到最小扩容量 private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; // 获取默认的容量和传入参数的较大值 minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity); &#125; 当 要 add 进第1个元素时，minCapacity为1，在Math.max()方法比较后，minCapacity 为10。 3. ensureExplicitCapacity() 方法 如果调用 ensureCapacityInternal() 方法就一定会进过（执行）这个方法，下面我们来研究一下这个方法的源码！ 123456789//判断是否需要扩容 private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) //调用grow方法进行扩容，调用此方法代表已经开始扩容了 grow(minCapacity); &#125; 我们来仔细分析一下： 当我们要 add 进第1个元素到 ArrayList 时，elementData.length 为0 （因为还是一个空的 list），因为执行了 ensureCapacityInternal() 方法 ，所以 minCapacity 此时为10。此时，minCapacity - elementData.length &gt; 0成立，所以会进入 grow(minCapacity) 方法。 当add第2个元素时，minCapacity 为2，此时e lementData.length(容量)在添加第一个元素后扩容成 10 了。此时，minCapacity - elementData.length &gt; 0 不成立，所以不会进入 （执行）grow(minCapacity) 方法。 添加第3、4···到第10个元素时，依然不会执行grow方法，数组容量都为10。 直到添加第11个元素，minCapacity(为11)比elementData.length（为10）要大。进入grow方法进行扩容。 4. grow() 方法 123456789101112131415161718192021222324/** * 要分配的最大数组大小 */private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;/** * ArrayList扩容的核心方法。 */private void grow(int minCapacity) &#123; // oldCapacity为旧容量，newCapacity为新容量 int oldCapacity = elementData.length; //将oldCapacity 右移一位，其效果相当于oldCapacity /2， //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍， int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量， if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 如果新容量大于 MAX_ARRAY_SIZE,进入(执行) `hugeCapacity()` 方法来比较 minCapacity 和 MAX_ARRAY_SIZE， //如果minCapacity大于最大容量，则新容量则为`Integer.MAX_VALUE`，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 `Integer.MAX_VALUE - 8`。 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1),所以 ArrayList 每次扩容之后容量都会变为原来的 1.5 倍！（JDK1.6版本以后） JDk1.6版本时，扩容之后容量为 1.5 倍+1！详情请参考源码 “&gt;&gt;”（移位运算符）：&gt;&gt;1 右移一位相当于除2，右移n位相当于除以 2 的 n 次方。这里 oldCapacity 明显右移了1位所以相当于oldCapacity /2。对于大数据的2进制运算,位移运算符比那些普通运算符的运算要快很多,因为程序仅仅移动一下而已,不去计算,这样提高了效率,节省了资源 我们再来通过例子探究一下grow() 方法 ： 当add第1个元素时，oldCapacity 为0，经比较后第一个if判断成立，newCapacity = minCapacity(为10)。但是第二个if判断不会成立，即newCapacity 不比 MAX_ARRAY_SIZE大，则不会进入 hugeCapacity 方法。数组容量为10，add方法中 return true,size增为1。 当add第11个元素进入grow方法时，newCapacity为15，比minCapacity（为11）大，第一个if判断不成立。新容量没有大于数组最大size，不会进入hugeCapacity方法。数组容量扩为15，add方法中return true,size增为11。 以此类推······ 这里补充一点比较重要，但是容易被忽视掉的知识点： java 中的 length属性是针对数组说的,比如说你声明了一个数组,想知道这个数组的长度则用到了 length 这个属性. java 中的 length() 方法是针对字符串说的,如果想看这个字符串的长度则用到 length() 这个方法. java 中的 size() 方法是针对泛型集合说的,如果想看这个泛型有多少个元素,就调用此方法来查看! 5. hugeCapacity() 方法。 从上面 grow() 方法源码我们知道： 如果新容量大于 MAX_ARRAY_SIZE,进入(执行) hugeCapacity() 方法来比较 minCapacity 和 MAX_ARRAY_SIZE，如果minCapacity大于最大容量，则新容量则为Integer.MAX_VALUE，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 Integer.MAX_VALUE - 8。 1234567891011private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); //对minCapacity和MAX_ARRAY_SIZE进行比较 //若minCapacity大，将Integer.MAX_VALUE作为新数组的大小 //若MAX_ARRAY_SIZE大，将MAX_ARRAY_SIZE作为新数组的大小 //MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; 三 System.arraycopy() 和 Arrays.copyOf()方法 阅读源码的话，我们就会发现 ArrayList 中大量调用了这两个方法。比如：我们上面讲的扩容操作以及add(int index, E element)、toArray() 等方法中都用到了该方法！ 3.1 System.arraycopy() 方法 123456789101112131415/** * 在此列表中的指定位置插入指定的元素。 *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大； *再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。 */public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! //arraycopy()方法实现数组自己复制自己 //elementData:源数组;index:源数组中的起始位置;elementData：目标数组；index + 1：目标数组中的起始位置； size - index：要复制的数组元素的数量； System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++;&#125; 我们写一个简单的方法测试以下： 1234567891011121314151617public class ArraycopyTest &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub int[] a = new int[10]; a[0] = 0; a[1] = 1; a[2] = 2; a[3] = 3; System.arraycopy(a, 2, a, 3, 3); a[2]=99; for (int i = 0; i &lt; a.length; i++) &#123; System.out.println(a[i]); &#125; &#125;&#125; 结果： 10 1 99 2 3 0 0 0 0 0 3.2 Arrays.copyOf()方法 1234567/** 以正确的顺序返回一个包含此列表中所有元素的数组（从第一个到最后一个元素）; 返回的数组的运行时类型是指定数组的运行时类型。 */ public Object[] toArray() &#123; //elementData：要复制的数组；size：要复制的长度 return Arrays.copyOf(elementData, size); &#125; 个人觉得使用 Arrays.copyOf()方法主要是为了给原有数组扩容，测试代码如下： 1234567891011public class ArrayscopyOfTest &#123; public static void main(String[] args) &#123; int[] a = new int[3]; a[0] = 0; a[1] = 1; a[2] = 2; int[] b = Arrays.copyOf(a, 10); System.out.println(\"b.length\"+b.length); &#125;&#125; 结果： 110 3.3 两者联系和区别 联系： 看两者源代码可以发现 copyOf() 内部实际调用了 System.arraycopy() 方法 区别： arraycopy() 需要目标数组，将原数组拷贝到你自己定义的数组里或者原数组，而且可以选择拷贝的起点和长度以及放入新数组中的位置 copyOf() 是系统自动在内部新建一个数组，并返回该数组。 四 ensureCapacity方法 ArrayList 源码中有一个 ensureCapacity 方法不知道大家注意到没有，这个方法 ArrayList 内部没有被调用过，所以很显然是提供给用户调用的，那么这个方法有什么作用呢？ 1234567891011121314151617/**如有必要，增加此 ArrayList 实例的容量，以确保它至少可以容纳由minimum capacity参数指定的元素数。 * * @param minCapacity 所需的最小容量 */public void ensureCapacity(int minCapacity) &#123; int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table ? 0 // larger than default for default empty table. It's already // supposed to be at default size. : DEFAULT_CAPACITY; if (minCapacity &gt; minExpand) &#123; ensureExplicitCapacity(minCapacity); &#125;&#125; 最好在 add 大量元素之前用 ensureCapacity 方法，以减少增量重新分配的次数 我们通过下面的代码实际测试以下这个方法的效果： 123456789101112131415161718192021public class EnsureCapacityTest &#123; public static void main(String[] args) &#123; ArrayList&lt;Object&gt; list = new ArrayList&lt;Object&gt;(); final int N = 10000000; long startTime = System.currentTimeMillis(); for (int i = 0; i &lt; N; i++) &#123; list.add(i); &#125; long endTime = System.currentTimeMillis(); System.out.println(\"使用ensureCapacity方法前：\"+(endTime - startTime)); list = new ArrayList&lt;Object&gt;(); long startTime1 = System.currentTimeMillis(); list.ensureCapacity(N); for (int i = 0; i &lt; N; i++) &#123; list.add(i); &#125; long endTime1 = System.currentTimeMillis(); System.out.println(\"使用ensureCapacity方法后：\"+(endTime1 - startTime1)); &#125;&#125; 运行结果： 12使用ensureCapacity方法前：4637使用ensureCapacity方法后：241 通过运行结果，我们可以很明显的看出向 ArrayList 添加大量元素之前最好先使用ensureCapacity 方法，以减少增量重新分配的次数","categories":[{"name":"Java","slug":"Java","permalink":"https://yuechuanx.top/categories/Java/"}],"tags":[{"name":"array-list","slug":"array-list","permalink":"https://yuechuanx.top/tags/array-list/"}]},{"title":"<Java容器> LinkedList","slug":"Java/LinkedList","date":"2019-01-03T12:10:39.000Z","updated":"2020-04-23T03:36:06.716Z","comments":true,"path":"Java/LinkedList/","link":"","permalink":"https://yuechuanx.top/Java/LinkedList/","excerpt":"","text":"简介 内部结构分析 LinkedList源码分析 构造方法 添加（add）方法 根据位置取数据的方法 根据对象得到索引的方法 检查链表是否包含某对象的方法： 删除（remove/pop）方法 LinkedList类常用方法测试： 简介 LinkedList是一个实现了List接口和Deque接口的双端链表。 LinkedList底层的链表结构使它支持高效的插入和删除操作，另外它实现了Deque接口，使得LinkedList类也具有队列的特性; LinkedList不是线程安全的，如果想使LinkedList变成线程安全的，可以调用静态类Collections类中的synchronizedList方法： 1List list=Collections.synchronizedList(new LinkedList(...)); 内部结构分析 如下图所示： 看完了图之后，我们再看LinkedList类中的一个内部私有类Node就很好理解了： 1234567891011private static class Node&lt;E&gt; &#123; E item;//节点值 Node&lt;E&gt; next;//后继节点 Node&lt;E&gt; prev;//前驱节点 Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125; &#125; 这个类就代表双端链表的节点Node。这个类有三个属性，分别是前驱节点，本节点的值，后继结点。 LinkedList源码分析 构造方法 空构造方法： 12public LinkedList() &#123;&#125; 用已有的集合创建链表的构造方法： 1234public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125; add方法 add(E e) 方法：将元素添加到链表尾部 1234public boolean add(E e) &#123; linkLast(e);//这里就只调用了这一个方法 return true; &#125; 1234567891011121314/** * 链接使e作为最后一个元素。 */ void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode;//新建节点 if (l == null) first = newNode; else l.next = newNode;//指向后继元素也就是指向下一个元素 size++; modCount++; &#125; add(int index,E e)：在指定位置添加元素 12345678public void add(int index, E element) &#123; checkPositionIndex(index); //检查索引是否处于[0-size]之间 if (index == size)//添加在链表尾部 linkLast(element); else//添加在链表中间 linkBefore(element, node(index)); &#125; linkBefore方法需要给定两个参数，一个插入节点的值，一个指定的node，所以我们又调用了Node(index)去找到index对应的node addAll(Collection c )：将集合插入到链表尾部 123public boolean addAll(Collection&lt;? extends E&gt; c) &#123; return addAll(size, c); &#125; addAll(int index, Collection c)： 将集合从指定位置开始插入 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; //1:检查index范围是否在size之内 checkPositionIndex(index); //2:toArray()方法把集合的数据存到对象数组中 Object[] a = c.toArray(); int numNew = a.length; if (numNew == 0) return false; //3：得到插入位置的前驱节点和后继节点 Node&lt;E&gt; pred, succ; //如果插入位置为尾部，前驱节点为last，后继节点为null if (index == size) &#123; succ = null; pred = last; &#125; //否则，调用node()方法得到后继节点，再得到前驱节点 else &#123; succ = node(index); pred = succ.prev; &#125; // 4：遍历数据将数据插入 for (Object o : a) &#123; @SuppressWarnings(\"unchecked\") E e = (E) o; //创建新节点 Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); //如果插入位置在链表头部 if (pred == null) first = newNode; else pred.next = newNode; pred = newNode; &#125; //如果插入位置在尾部，重置last节点 if (succ == null) &#123; last = pred; &#125; //否则，将插入的链表与先前链表连接起来 else &#123; pred.next = succ; succ.prev = pred; &#125; size += numNew; modCount++; return true; &#125; 上面可以看出addAll方法通常包括下面四个步骤： 检查index范围是否在size之内 toArray()方法把集合的数据存到对象数组中 得到插入位置的前驱和后继节点 遍历数据，将数据插入到指定位置 addFirst(E e)： 将元素添加到链表头部 123public void addFirst(E e) &#123; linkFirst(e); &#125; 12345678910111213private void linkFirst(E e) &#123; final Node&lt;E&gt; f = first; final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f);//新建节点，以头节点为后继节点 first = newNode; //如果链表为空，last节点也指向该节点 if (f == null) last = newNode; //否则，将头节点的前驱指针指向新节点，也就是指向前一个元素 else f.prev = newNode; size++; modCount++; &#125; addLast(E e)： 将元素添加到链表尾部，与 add(E e) 方法一样 123public void addLast(E e) &#123; linkLast(e); &#125; 根据位置取数据的方法 get(int index)： 根据指定索引返回数据 123456public E get(int index) &#123; //检查index范围是否在size之内 checkElementIndex(index); //调用Node(index)去找到index对应的node然后返回它的值 return node(index).item; &#125; 获取头节点（index=0）数据方法: 123456789101112131415161718public E getFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item; &#125;public E element() &#123; return getFirst(); &#125;public E peek() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item; &#125;public E peekFirst() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item; &#125; 区别： getFirst(),element(),peek(),peekFirst() 这四个获取头结点方法的区别在于对链表为空时的处理，是抛出异常还是返回null，其中getFirst() 和element() 方法将会在链表为空时，抛出异常 element()方法的内部就是使用getFirst()实现的。它们会在链表为空时，抛出NoSuchElementException 获取尾节点（index=-1）数据方法: 12345678910public E getLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return l.item; &#125;public E peekLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : l.item; &#125; 两者区别： getLast() 方法在链表为空时，会抛出NoSuchElementException，而peekLast() 则不会，只是会返回 null。 根据对象得到索引的方法 int indexOf(Object o)： 从头遍历找 12345678910111213141516171819public int indexOf(Object o) &#123; int index = 0; if (o == null) &#123; //从头遍历 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) return index; index++; &#125; &#125; else &#123; //从头遍历 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) return index; index++; &#125; &#125; return -1; &#125; int lastIndexOf(Object o)： 从尾遍历找 12345678910111213141516171819public int lastIndexOf(Object o) &#123; int index = size; if (o == null) &#123; //从尾遍历 for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; index--; if (x.item == null) return index; &#125; &#125; else &#123; //从尾遍历 for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; index--; if (o.equals(x.item)) return index; &#125; &#125; return -1; &#125; 检查链表是否包含某对象的方法： contains(Object o)： 检查对象o是否存在于链表中 123public boolean contains(Object o) &#123; return indexOf(o) != -1; &#125; 删除方法 remove() ,removeFirst(),pop(): 删除头节点 123456789101112public E pop() &#123; return removeFirst(); &#125;public E remove() &#123; return removeFirst(); &#125;public E removeFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f); &#125; removeLast(),pollLast(): 删除尾节点 12345678910public E removeLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return unlinkLast(l); &#125;public E pollLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : unlinkLast(l); &#125; 区别： removeLast()在链表为空时将抛出NoSuchElementException，而pollLast()方法返回null。 remove(Object o): 删除指定元素 12345678910111213141516171819202122232425public boolean remove(Object o) &#123; //如果删除对象为null if (o == null) &#123; //从头开始遍历 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; //找到元素 if (x.item == null) &#123; //从链表中移除找到的元素 unlink(x); return true; &#125; &#125; &#125; else &#123; //从头开始遍历 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; //找到元素 if (o.equals(x.item)) &#123; //从链表中移除找到的元素 unlink(x); return true; &#125; &#125; &#125; return false; &#125; 当删除指定对象时，只需调用remove(Object o)即可，不过该方法一次只会删除一个匹配的对象，如果删除了匹配对象，返回true，否则false。 unlink(Node x) 方法： 123456789101112131415161718192021222324252627E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next;//得到后继节点 final Node&lt;E&gt; prev = x.prev;//得到前驱节点 //删除前驱指针 if (prev == null) &#123; first = next;//如果删除的节点是头节点,令头节点指向该节点的后继节点 &#125; else &#123; prev.next = next;//将前驱节点的后继节点指向后继节点 x.prev = null; &#125; //删除后继指针 if (next == null) &#123; last = prev;//如果删除的节点是尾节点,令尾节点指向该节点的前驱节点 &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element; &#125; remove(int index)：删除指定位置的元素 123456public E remove(int index) &#123; //检查index范围 checkElementIndex(index); //将节点删除 return unlink(node(index)); &#125; LinkedList类常用方法测试 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121package list;import java.util.Iterator;import java.util.LinkedList;public class LinkedListDemo &#123; public static void main(String[] srgs) &#123; //创建存放int类型的linkedList LinkedList&lt;Integer&gt; linkedList = new LinkedList&lt;&gt;(); /************************** linkedList的基本操作 ************************/ linkedList.addFirst(0); // 添加元素到列表开头 linkedList.add(1); // 在列表结尾添加元素 linkedList.add(2, 2); // 在指定位置添加元素 linkedList.addLast(3); // 添加元素到列表结尾 System.out.println(\"LinkedList（直接输出的）: \" + linkedList); System.out.println(\"getFirst()获得第一个元素: \" + linkedList.getFirst()); // 返回此列表的第一个元素 System.out.println(\"getLast()获得第最后一个元素: \" + linkedList.getLast()); // 返回此列表的最后一个元素 System.out.println(\"removeFirst()删除第一个元素并返回: \" + linkedList.removeFirst()); // 移除并返回此列表的第一个元素 System.out.println(\"removeLast()删除最后一个元素并返回: \" + linkedList.removeLast()); // 移除并返回此列表的最后一个元素 System.out.println(\"After remove:\" + linkedList); System.out.println(\"contains()方法判断列表是否包含1这个元素:\" + linkedList.contains(1)); // 判断此列表包含指定元素，如果是，则返回true System.out.println(\"该linkedList的大小 : \" + linkedList.size()); // 返回此列表的元素个数 /************************** 位置访问操作 ************************/ System.out.println(\"-----------------------------------------\"); linkedList.set(1, 3); // 将此列表中指定位置的元素替换为指定的元素 System.out.println(\"After set(1, 3):\" + linkedList); System.out.println(\"get(1)获得指定位置（这里为1）的元素: \" + linkedList.get(1)); // 返回此列表中指定位置处的元素 /************************** Search操作 ************************/ System.out.println(\"-----------------------------------------\"); linkedList.add(3); System.out.println(\"indexOf(3): \" + linkedList.indexOf(3)); // 返回此列表中首次出现的指定元素的索引 System.out.println(\"lastIndexOf(3): \" + linkedList.lastIndexOf(3));// 返回此列表中最后出现的指定元素的索引 /************************** Queue操作 ************************/ System.out.println(\"-----------------------------------------\"); System.out.println(\"peek(): \" + linkedList.peek()); // 获取但不移除此列表的头 System.out.println(\"element(): \" + linkedList.element()); // 获取但不移除此列表的头 linkedList.poll(); // 获取并移除此列表的头 System.out.println(\"After poll():\" + linkedList); linkedList.remove(); System.out.println(\"After remove():\" + linkedList); // 获取并移除此列表的头 linkedList.offer(4); System.out.println(\"After offer(4):\" + linkedList); // 将指定元素添加到此列表的末尾 /************************** Deque操作 ************************/ System.out.println(\"-----------------------------------------\"); linkedList.offerFirst(2); // 在此列表的开头插入指定的元素 System.out.println(\"After offerFirst(2):\" + linkedList); linkedList.offerLast(5); // 在此列表末尾插入指定的元素 System.out.println(\"After offerLast(5):\" + linkedList); System.out.println(\"peekFirst(): \" + linkedList.peekFirst()); // 获取但不移除此列表的第一个元素 System.out.println(\"peekLast(): \" + linkedList.peekLast()); // 获取但不移除此列表的第一个元素 linkedList.pollFirst(); // 获取并移除此列表的第一个元素 System.out.println(\"After pollFirst():\" + linkedList); linkedList.pollLast(); // 获取并移除此列表的最后一个元素 System.out.println(\"After pollLast():\" + linkedList); linkedList.push(2); // 将元素推入此列表所表示的堆栈（插入到列表的头） System.out.println(\"After push(2):\" + linkedList); linkedList.pop(); // 从此列表所表示的堆栈处弹出一个元素（获取并移除列表第一个元素） System.out.println(\"After pop():\" + linkedList); linkedList.add(3); linkedList.removeFirstOccurrence(3); // 从此列表中移除第一次出现的指定元素（从头部到尾部遍历列表） System.out.println(\"After removeFirstOccurrence(3):\" + linkedList); linkedList.removeLastOccurrence(3); // 从此列表中移除最后一次出现的指定元素（从头部到尾部遍历列表） System.out.println(\"After removeFirstOccurrence(3):\" + linkedList); /************************** 遍历操作 ************************/ System.out.println(\"-----------------------------------------\"); linkedList.clear(); for (int i = 0; i &lt; 100000; i++) &#123; linkedList.add(i); &#125; // 迭代器遍历 long start = System.currentTimeMillis(); Iterator&lt;Integer&gt; iterator = linkedList.iterator(); while (iterator.hasNext()) &#123; iterator.next(); &#125; long end = System.currentTimeMillis(); System.out.println(\"Iterator：\" + (end - start) + \" ms\"); // 顺序遍历(随机遍历) start = System.currentTimeMillis(); for (int i = 0; i &lt; linkedList.size(); i++) &#123; linkedList.get(i); &#125; end = System.currentTimeMillis(); System.out.println(\"for：\" + (end - start) + \" ms\"); // 另一种for循环遍历 start = System.currentTimeMillis(); for (Integer i : linkedList) ; end = System.currentTimeMillis(); System.out.println(\"for2：\" + (end - start) + \" ms\"); // 通过pollFirst()或pollLast()来遍历LinkedList LinkedList&lt;Integer&gt; temp1 = new LinkedList&lt;&gt;(); temp1.addAll(linkedList); start = System.currentTimeMillis(); while (temp1.size() != 0) &#123; temp1.pollFirst(); &#125; end = System.currentTimeMillis(); System.out.println(\"pollFirst()或pollLast()：\" + (end - start) + \" ms\"); // 通过removeFirst()或removeLast()来遍历LinkedList LinkedList&lt;Integer&gt; temp2 = new LinkedList&lt;&gt;(); temp2.addAll(linkedList); start = System.currentTimeMillis(); while (temp2.size() != 0) &#123; temp2.removeFirst(); &#125; end = System.currentTimeMillis(); System.out.println(\"removeFirst()或removeLast()：\" + (end - start) + \" ms\"); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://yuechuanx.top/categories/Java/"}],"tags":[{"name":"linked-list","slug":"linked-list","permalink":"https://yuechuanx.top/tags/linked-list/"}]},{"title":"<Java容器> HashMap","slug":"Java/HashMap","date":"2019-01-03T12:10:39.000Z","updated":"2020-04-23T03:36:06.715Z","comments":true,"path":"Java/HashMap/","link":"","permalink":"https://yuechuanx.top/Java/HashMap/","excerpt":"","text":"HashMap 简介 底层数据结构分析 JDK1.8之前 JDK1.8之后 HashMap源码分析 构造方法 put方法 get方法 resize方法 HashMap常用方法测试 感谢 changfubai 对本文的改进做出的贡献！ HashMap 简介 HashMap 主要用来存放键值对，它基于哈希表的Map接口实现，是常用的Java集合之一。 JDK1.8 之前 HashMap 由 数组+链表 组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）.JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树，以减少搜索时间。 底层数据结构分析 JDK1.8之前 JDK1.8 之前 HashMap 底层是 数组和链表 结合在一起使用也就是 链表散列。HashMap 通过 key 的 hashCode 经过扰动函数处理过后得到 hash 值，然后通过 (n - 1) &amp; hash 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。 所谓扰动函数指的就是 HashMap 的 hash 方法。使用 hash 方法也就是扰动函数是为了防止一些实现比较差的 hashCode() 方法 换句话说使用扰动函数之后可以减少碰撞。 JDK 1.8 HashMap 的 hash 方法源码: JDK 1.8 的 hash方法 相比于 JDK 1.7 hash 方法更加简化，但是原理不变。 1234567 static final int hash(Object key) &#123; int h; // key.hashCode()：返回散列值也就是hashcode // ^ ：按位异或 // &gt;&gt;&gt;:无符号右移，忽略符号位，空位都以0补齐 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 对比一下 JDK1.7的 HashMap 的 hash 方法源码. 12345678static int hash(int h) &#123; // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125; 相比于 JDK1.8 的 hash 方法 ，JDK 1.7 的 hash 方法的性能会稍差一点点，因为毕竟扰动了 4 次。 所谓 “拉链法” 就是：将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。 JDK1.8之后 相比于之前的版本，jdk1.8在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。 类的属性： 12345678910111213141516171819202122232425262728public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; // 序列号 private static final long serialVersionUID = 362498820763181265L; // 默认的初始容量是16 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 最大容量 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 默认的填充因子 static final float DEFAULT_LOAD_FACTOR = 0.75f; // 当桶(bucket)上的结点数大于这个值时会转成红黑树 static final int TREEIFY_THRESHOLD = 8; // 当桶(bucket)上的结点数小于这个值时树转链表 static final int UNTREEIFY_THRESHOLD = 6; // 桶中结构转化为红黑树对应的table的最小大小 static final int MIN_TREEIFY_CAPACITY = 64; // 存储元素的数组，总是2的幂次倍 transient Node&lt;k,v&gt;[] table; // 存放具体元素的集 transient Set&lt;map.entry&lt;k,v&gt;&gt; entrySet; // 存放元素的个数，注意这个不等于数组的长度。 transient int size; // 每次扩容和更改map结构的计数器 transient int modCount; // 临界值 当实际大小(容量*填充因子)超过临界值时，会进行扩容 int threshold; // 加载因子 final float loadFactor;&#125; loadFactor加载因子 loadFactor加载因子是控制数组存放数据的疏密程度，loadFactor越趋近于1，那么 数组中存放的数据(entry)也就越多，也就越密，也就是会让链表的长度增加，loadFactor越小，也就是趋近于0，数组中存放的数据(entry)也就越少，也就越稀疏。 loadFactor太大导致查找元素效率低，太小导致数组的利用率低，存放的数据会很分散。loadFactor的默认值为0.75f是官方给出的一个比较好的临界值。 给定的默认容量为 16，负载因子为 0.75。Map 在使用过程中不断的往里面存放数据，当数量达到了 16 * 0.75 = 12 就需要将当前 16 的容量进行扩容，而扩容这个过程涉及到 rehash、复制数据等操作，所以非常消耗性能。 threshold threshold = capacity * loadFactor，当Size&gt;=threshold的时候，那么就要考虑对数组的扩增了，也就是说，这个的意思就是 衡量数组是否需要扩增的一个标准。 Node节点类源码: 123456789101112131415161718192021222324252627282930313233343536373839// 继承自 Map.Entry&lt;K,V&gt;static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash;// 哈希值，存放元素到hashmap中时用来与其他元素hash值比较 final K key;//键 V value;//值 // 指向下一个节点 Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + \"=\" + value; &#125; // 重写hashCode()方法 public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; // 重写 equals() 方法 public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; 树节点类源码: 12345678910111213141516static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // 父 TreeNode&lt;K,V&gt; left; // 左 TreeNode&lt;K,V&gt; right; // 右 TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; // 判断颜色 TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; super(hash, key, val, next); &#125; // 返回根节点 final TreeNode&lt;K,V&gt; root() &#123; for (TreeNode&lt;K,V&gt; r = this, p;;) &#123; if ((p = r.parent) == null) return r; r = p; &#125; HashMap源码分析 构造方法 123456789101112131415161718192021222324252627// 默认构造函数。public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125; // 包含另一个“Map”的构造函数 public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);//下面会分析到这个方法 &#125; // 指定“容量大小”的构造函数 public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; // 指定“容量大小”和“加载因子”的构造函数 public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); &#125; putMapEntries方法： 123456789101112131415161718192021222324final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size(); if (s &gt; 0) &#123; // 判断table是否已经初始化 if (table == null) &#123; // pre-size // 未初始化，s为m的实际元素个数 float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); // 计算得到的t大于阈值，则初始化阈值 if (t &gt; threshold) threshold = tableSizeFor(t); &#125; // 已初始化，并且m元素个数大于阈值，进行扩容处理 else if (s &gt; threshold) resize(); // 将m中的所有元素添加至HashMap中 for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125;&#125; put方法 HashMap只提供了put用于添加元素，putVal方法只是给put方法调用的一个方法，并没有提供给用户使用。 对putVal方法添加元素的分析如下： ①如果定位到的数组位置没有元素 就直接插入。 ②如果定位到的数组位置有元素就和要插入的key比较，如果key相同就直接覆盖，如果key不相同，就判断p是否是一个树节点，如果是就调用e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value)将元素添加进入。如果不是就遍历链表插入。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // table未初始化或者长度为0，进行扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // (n - 1) &amp; hash 确定元素存放在哪个桶中，桶为空，新生成结点放入桶中(此时，这个结点是放在数组中) if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // 桶中已经存在元素 else &#123; Node&lt;K,V&gt; e; K k; // 比较桶中第一个元素(数组中的结点)的hash值相等，key相等 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 将第一个元素赋值给e，用e来记录 e = p; // hash值不相等，即key不相等；为红黑树结点 else if (p instanceof TreeNode) // 放入树中 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 为链表结点 else &#123; // 在链表最末插入结点 for (int binCount = 0; ; ++binCount) &#123; // 到达链表的尾部 if ((e = p.next) == null) &#123; // 在尾部插入新结点 p.next = newNode(hash, key, value, null); // 结点数量达到阈值，转化为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); // 跳出循环 break; &#125; // 判断链表中结点的key值与插入的元素的key值是否相等 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) // 相等，跳出循环 break; // 用于遍历桶中的链表，与前面的e = p.next组合，可以遍历链表 p = e; &#125; &#125; // 表示在桶中找到key值、hash值与插入元素相等的结点 if (e != null) &#123; // 记录e的value V oldValue = e.value; // onlyIfAbsent为false或者旧值为null if (!onlyIfAbsent || oldValue == null) //用新值替换旧值 e.value = value; // 访问后回调 afterNodeAccess(e); // 返回旧值 return oldValue; &#125; &#125; // 结构性修改 ++modCount; // 实际大小大于阈值则扩容 if (++size &gt; threshold) resize(); // 插入后回调 afterNodeInsertion(evict); return null;&#125; 我们再来对比一下 JDK1.7 put方法的代码 对于put方法的分析如下： ①如果定位到的数组位置没有元素 就直接插入。 ②如果定位到的数组位置有元素，遍历以这个元素为头结点的链表，依次和插入的key比较，如果key相同就直接覆盖，不同就采用头插法插入元素。 12345678910111213141516171819202122public V put(K key, V value) if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; // 先遍历 Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(hash, key, value, i); // 再插入 return null;&#125; get方法 12345678910111213141516171819202122232425262728public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 数组元素相等 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 桶中不止一个节点 if ((e = first.next) != null) &#123; // 在树中get if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 在链表中get do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; resize方法 进行扩容，会伴随着一次重新hash分配，并且会遍历hash表中所有的元素，是非常耗时的。在编写程序中，要尽量避免resize。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 超过最大值就不再扩充了，就只好随你碰撞去吧 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 没超过最大值，就扩充为原来的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 计算新的resize上限 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 把每个bucket都移动到新的buckets中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 原索引 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 原索引+oldCap else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 原索引放到bucket里 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 原索引+oldCap放到bucket里 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; HashMap常用方法测试 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package map;import java.util.Collection;import java.util.HashMap;import java.util.Set;public class HashMapDemo &#123; public static void main(String[] args) &#123; HashMap&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); // 键不能重复，值可以重复 map.put(\"san\", \"张三\"); map.put(\"si\", \"李四\"); map.put(\"wu\", \"王五\"); map.put(\"wang\", \"老王\"); map.put(\"wang\", \"老王2\");// 老王被覆盖 map.put(\"lao\", \"老王\"); System.out.println(\"-------直接输出hashmap:-------\"); System.out.println(map); /** * 遍历HashMap */ // 1.获取Map中的所有键 System.out.println(\"-------foreach获取Map中所有的键:------\"); Set&lt;String&gt; keys = map.keySet(); for (String key : keys) &#123; System.out.print(key+\" \"); &#125; System.out.println();//换行 // 2.获取Map中所有值 System.out.println(\"-------foreach获取Map中所有的值:------\"); Collection&lt;String&gt; values = map.values(); for (String value : values) &#123; System.out.print(value+\" \"); &#125; System.out.println();//换行 // 3.得到key的值的同时得到key所对应的值 System.out.println(\"-------得到key的值的同时得到key所对应的值:-------\"); Set&lt;String&gt; keys2 = map.keySet(); for (String key : keys2) &#123; System.out.print(key + \"：\" + map.get(key)+\" \"); &#125; /** * 另外一种不常用的遍历方式 */ // 当我调用put(key,value)方法的时候，首先会把key和value封装到 // Entry这个静态内部类对象中，把Entry对象再添加到数组中，所以我们想获取 // map中的所有键值对，我们只要获取数组中的所有Entry对象，接下来 // 调用Entry对象中的getKey()和getValue()方法就能获取键值对了 Set&lt;java.util.Map.Entry&lt;String, String&gt;&gt; entrys = map.entrySet(); for (java.util.Map.Entry&lt;String, String&gt; entry : entrys) &#123; System.out.println(entry.getKey() + \"--\" + entry.getValue()); &#125; /** * HashMap其他常用方法 */ System.out.println(\"after map.size()：\"+map.size()); System.out.println(\"after map.isEmpty()：\"+map.isEmpty()); System.out.println(map.remove(\"san\")); System.out.println(\"after map.remove()：\"+map); System.out.println(\"after map.get(si)：\"+map.get(\"si\")); System.out.println(\"after map.containsKey(si)：\"+map.containsKey(\"si\")); System.out.println(\"after containsValue(李四)：\"+map.containsValue(\"李四\")); System.out.println(map.replace(\"si\", \"李四2\")); System.out.println(\"after map.replace(si, 李四2):\"+map); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://yuechuanx.top/categories/Java/"}],"tags":[{"name":"map","slug":"map","permalink":"https://yuechuanx.top/tags/map/"},{"name":"hashmap","slug":"hashmap","permalink":"https://yuechuanx.top/tags/hashmap/"}]},{"title":"<Java容器> ArrayList","slug":"Java/ArrayList","date":"2019-01-03T12:10:39.000Z","updated":"2020-04-23T03:36:06.715Z","comments":true,"path":"Java/ArrayList/","link":"","permalink":"https://yuechuanx.top/Java/ArrayList/","excerpt":"","text":"ArrayList简介 ArrayList 的底层是数组队列，相当于动态数组。与 Java 中的数组相比，它的容量能动态增长。在添加大量元素前，应用程序可以使用 ensureCapacity 操作来增加 ArrayList 实例的容量。这可以减少递增式再分配的数量。 它继承于 AbstractList，实现了 List, RandomAccess, Cloneable, java.io.Serializable 这些接口。 - ArrayList 继承了AbstractList，实现了List。它是一个数组队列，提供了相关的添加、删除、修改、遍历等功能。 - ArrayList 实现了RandomAccess 接口。 RandomAccess 是一个标志接口，表明实现这个这个接口的 List 集合是支持快速随机访问的。在 ArrayList 中，我们即可以通过元素的序号快速获取元素对象，这就是快速随机访问。 - ArrayList 实现了Cloneable 接口。即覆盖了函数 clone()，能被克隆。 - ArrayList 实现java.io.Serializable 接口。这意味着ArrayList支持序列化，能通过序列化去传输。 和 Vector 不同，**ArrayList 中的操作不是线程安全的！**所以，建议在单线程中才使用 ArrayList，而在多线程中可以选择 Vector 或者 CopyOnWriteArrayList。 ArrayList核心源码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498package java.util;import java.util.function.Consumer;import java.util.function.Predicate;import java.util.function.UnaryOperator;public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123; private static final long serialVersionUID = 8683452581122892189L; /** * 默认初始容量大小 */ private static final int DEFAULT_CAPACITY = 10; /** * 空数组（用于空实例）。 */ private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; //用于默认大小空实例的共享空数组实例。 //我们把它从EMPTY_ELEMENTDATA数组中区分出来，以知道在添加第一个元素时容量需要增加多少。 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; /** * 保存ArrayList数据的数组 */ transient Object[] elementData; // non-private to simplify nested class access /** * ArrayList 所包含的元素个数 */ private int size; /** * 带初始容量参数的构造函数。（用户自己指定容量） */ public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; //创建initialCapacity大小的数组 this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; //创建空数组 this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); &#125; &#125; /** *默认构造函数，DEFAULTCAPACITY_EMPTY_ELEMENTDATA 为0.初始化为10，也就是说初始其实是空数组 当添加第一个元素的时候数组容量才变成10 */ public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; /** * 构造一个包含指定集合的元素的列表，按照它们由集合的迭代器返回的顺序。 */ public ArrayList(Collection&lt;? extends E&gt; c) &#123; // elementData = c.toArray(); //如果指定集合元素个数不为0 if ((size = elementData.length) != 0) &#123; // c.toArray 可能返回的不是Object类型的数组所以加上下面的语句用于判断， //这里用到了反射里面的getClass()方法 if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // 用空数组代替 this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; /** * 修改这个ArrayList实例的容量是列表的当前大小。 应用程序可以使用此操作来最小化ArrayList实例的存储。 */ public void trimToSize() &#123; modCount++; if (size &lt; elementData.length) &#123; elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125; &#125;//下面是ArrayList的扩容机制//ArrayList的扩容机制提高了性能，如果每次只扩充一个，//那么频繁的插入会导致频繁的拷贝，降低性能，而ArrayList的扩容机制避免了这种情况。 /** * 如有必要，增加此ArrayList实例的容量，以确保它至少能容纳元素的数量 * @param minCapacity 所需的最小容量 */ public void ensureCapacity(int minCapacity) &#123; int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table ? 0 // larger than default for default empty table. It's already // supposed to be at default size. : DEFAULT_CAPACITY; if (minCapacity &gt; minExpand) &#123; ensureExplicitCapacity(minCapacity); &#125; &#125; //得到最小扩容量 private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; // 获取默认的容量和传入参数的较大值 minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity); &#125; //判断是否需要扩容 private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) //调用grow方法进行扩容，调用此方法代表已经开始扩容了 grow(minCapacity); &#125; /** * 要分配的最大数组大小 */ private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; /** * ArrayList扩容的核心方法。 */ private void grow(int minCapacity) &#123; // oldCapacity为旧容量，newCapacity为新容量 int oldCapacity = elementData.length; //将oldCapacity 右移一位，其效果相当于oldCapacity /2， //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍， int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量， if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //再检查新容量是否超出了ArrayList所定义的最大容量， //若超出了，则调用hugeCapacity()来比较minCapacity和 MAX_ARRAY_SIZE， //如果minCapacity大于MAX_ARRAY_SIZE，则新容量则为Interger.MAX_VALUE，否则，新容量大小则为 MAX_ARRAY_SIZE。 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); &#125; //比较minCapacity和 MAX_ARRAY_SIZE private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; /** *返回此列表中的元素数。 */ public int size() &#123; return size; &#125; /** * 如果此列表不包含元素，则返回 true 。 */ public boolean isEmpty() &#123; //注意=和==的区别 return size == 0; &#125; /** * 如果此列表包含指定的元素，则返回true 。 */ public boolean contains(Object o) &#123; //indexOf()方法：返回此列表中指定元素的首次出现的索引，如果此列表不包含此元素，则为-1 return indexOf(o) &gt;= 0; &#125; /** *返回此列表中指定元素的首次出现的索引，如果此列表不包含此元素，则为-1 */ public int indexOf(Object o) &#123; if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) //equals()方法比较 if (o.equals(elementData[i])) return i; &#125; return -1; &#125; /** * 返回此列表中指定元素的最后一次出现的索引，如果此列表不包含元素，则返回-1。. */ public int lastIndexOf(Object o) &#123; if (o == null) &#123; for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; /** * 返回此ArrayList实例的浅拷贝。 （元素本身不被复制。） */ public Object clone() &#123; try &#123; ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) super.clone(); //Arrays.copyOf功能是实现数组的复制，返回复制后的数组。参数是被复制的数组和复制的长度 v.elementData = Arrays.copyOf(elementData, size); v.modCount = 0; return v; &#125; catch (CloneNotSupportedException e) &#123; // 这不应该发生，因为我们是可以克隆的 throw new InternalError(e); &#125; &#125; /** *以正确的顺序（从第一个到最后一个元素）返回一个包含此列表中所有元素的数组。 *返回的数组将是“安全的”，因为该列表不保留对它的引用。 （换句话说，这个方法必须分配一个新的数组）。 *因此，调用者可以自由地修改返回的数组。 此方法充当基于阵列和基于集合的API之间的桥梁。 */ public Object[] toArray() &#123; return Arrays.copyOf(elementData, size); &#125; /** * 以正确的顺序返回一个包含此列表中所有元素的数组（从第一个到最后一个元素）; *返回的数组的运行时类型是指定数组的运行时类型。 如果列表适合指定的数组，则返回其中。 *否则，将为指定数组的运行时类型和此列表的大小分配一个新数组。 *如果列表适用于指定的数组，其余空间（即数组的列表数量多于此元素），则紧跟在集合结束后的数组中的元素设置为null 。 *（这仅在调用者知道列表不包含任何空元素的情况下才能确定列表的长度。） */ @SuppressWarnings(\"unchecked\") public &lt;T&gt; T[] toArray(T[] a) &#123; if (a.length &lt; size) // 新建一个运行时类型的数组，但是ArrayList数组的内容 return (T[]) Arrays.copyOf(elementData, size, a.getClass()); //调用System提供的arraycopy()方法实现数组之间的复制 System.arraycopy(elementData, 0, a, 0, size); if (a.length &gt; size) a[size] = null; return a; &#125; // Positional Access Operations @SuppressWarnings(\"unchecked\") E elementData(int index) &#123; return (E) elementData[index]; &#125; /** * 返回此列表中指定位置的元素。 */ public E get(int index) &#123; rangeCheck(index); return elementData(index); &#125; /** * 用指定的元素替换此列表中指定位置的元素。 */ public E set(int index, E element) &#123; //对index进行界限检查 rangeCheck(index); E oldValue = elementData(index); elementData[index] = element; //返回原来在这个位置的元素 return oldValue; &#125; /** * 将指定的元素追加到此列表的末尾。 */ public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! //这里看到ArrayList添加元素的实质就相当于为数组赋值 elementData[size++] = e; return true; &#125; /** * 在此列表中的指定位置插入指定的元素。 *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大； *再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。 */ public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! //arraycopy()这个实现数组之间复制的方法一定要看一下，下面就用到了arraycopy()方法实现数组自己复制自己 System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; &#125; /** * 删除该列表中指定位置的元素。 将任何后续元素移动到左侧（从其索引中减去一个元素）。 */ public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work //从列表中删除的元素 return oldValue; &#125; /** * 从列表中删除指定元素的第一个出现（如果存在）。 如果列表不包含该元素，则它不会更改。 *返回true，如果此列表包含指定的元素 */ public boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false; &#125; /* * Private remove method that skips bounds checking and does not * return the value removed. */ private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work &#125; /** * 从列表中删除所有元素。 */ public void clear() &#123; modCount++; // 把数组中所有的元素的值设为null for (int i = 0; i &lt; size; i++) elementData[i] = null; size = 0; &#125; /** * 按指定集合的Iterator返回的顺序将指定集合中的所有元素追加到此列表的末尾。 */ public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0; &#125; /** * 将指定集合中的所有元素插入到此列表中，从指定的位置开始。 */ public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; rangeCheckForAdd(index); Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount int numMoved = size - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0; &#125; /** * 从此列表中删除所有索引为fromIndex （含）和toIndex之间的元素。 *将任何后续元素移动到左侧（减少其索引）。 */ protected void removeRange(int fromIndex, int toIndex) &#123; modCount++; int numMoved = size - toIndex; System.arraycopy(elementData, toIndex, elementData, fromIndex, numMoved); // clear to let GC do its work int newSize = size - (toIndex-fromIndex); for (int i = newSize; i &lt; size; i++) &#123; elementData[i] = null; &#125; size = newSize; &#125; /** * 检查给定的索引是否在范围内。 */ private void rangeCheck(int index) &#123; if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; /** * add和addAll使用的rangeCheck的一个版本 */ private void rangeCheckForAdd(int index) &#123; if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; /** * 返回IndexOutOfBoundsException细节信息 */ private String outOfBoundsMsg(int index) &#123; return \"Index: \"+index+\", Size: \"+size; &#125; /** * 从此列表中删除指定集合中包含的所有元素。 */ public boolean removeAll(Collection&lt;?&gt; c) &#123; Objects.requireNonNull(c); //如果此列表被修改则返回true return batchRemove(c, false); &#125; /** * 仅保留此列表中包含在指定集合中的元素。 *换句话说，从此列表中删除其中不包含在指定集合中的所有元素。 */ public boolean retainAll(Collection&lt;?&gt; c) &#123; Objects.requireNonNull(c); return batchRemove(c, true); &#125; /** * 从列表中的指定位置开始，返回列表中的元素（按正确顺序）的列表迭代器。 *指定的索引表示初始调用将返回的第一个元素为next 。 初始调用previous将返回指定索引减1的元素。 *返回的列表迭代器是fail-fast 。 */ public ListIterator&lt;E&gt; listIterator(int index) &#123; if (index &lt; 0 || index &gt; size) throw new IndexOutOfBoundsException(\"Index: \"+index); return new ListItr(index); &#125; /** *返回列表中的列表迭代器（按适当的顺序）。 *返回的列表迭代器是fail-fast 。 */ public ListIterator&lt;E&gt; listIterator() &#123; return new ListItr(0); &#125; /** *以正确的顺序返回该列表中的元素的迭代器。 *返回的迭代器是fail-fast 。 */ public Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; ArrayList源码分析 System.arraycopy()和Arrays.copyOf()方法 通过上面源码我们发现这两个实现数组复制的方法被广泛使用而且很多地方都特别巧妙。比如下面add(int index, E element)方法就很巧妙的用到了arraycopy()方法让数组自己复制自己实现让index开始之后的所有成员后移一个位置: 123456789101112131415/** * 在此列表中的指定位置插入指定的元素。 *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大； *再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。 */public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! //arraycopy()方法实现数组自己复制自己 //elementData:源数组;index:源数组中的起始位置;elementData：目标数组；index + 1：目标数组中的起始位置； size - index：要复制的数组元素的数量； System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++;&#125; 又如toArray()方法中用到了copyOf()方法 12345678910/** *以正确的顺序（从第一个到最后一个元素）返回一个包含此列表中所有元素的数组。 *返回的数组将是“安全的”，因为该列表不保留对它的引用。 （换句话说，这个方法必须分配一个新的数组）。 *因此，调用者可以自由地修改返回的数组。 此方法充当基于阵列和基于集合的API之间的桥梁。 */public Object[] toArray() &#123;//elementData：要复制的数组；size：要复制的长度 return Arrays.copyOf(elementData, size);&#125; 两者联系与区别 联系： 看两者源代码可以发现copyOf()内部调用了System.arraycopy()方法 区别： arraycopy()需要目标数组，将原数组拷贝到你自己定义的数组里，而且可以选择拷贝的起点和长度以及放入新数组中的位置 copyOf()是系统自动在内部新建一个数组，并返回该数组。 ArrayList 核心扩容技术 1234567891011121314151617181920212223242526272829303132333435363738//下面是ArrayList的扩容机制//ArrayList的扩容机制提高了性能，如果每次只扩充一个，//那么频繁的插入会导致频繁的拷贝，降低性能，而ArrayList的扩容机制避免了这种情况。 /** * 如有必要，增加此ArrayList实例的容量，以确保它至少能容纳元素的数量 * @param minCapacity 所需的最小容量 */ public void ensureCapacity(int minCapacity) &#123; int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table ? 0 // larger than default for default empty table. It's already // supposed to be at default size. : DEFAULT_CAPACITY; if (minCapacity &gt; minExpand) &#123; ensureExplicitCapacity(minCapacity); &#125; &#125; //得到最小扩容量 private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; // 获取默认的容量和传入参数的较大值 minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity); &#125; //判断是否需要扩容,上面两个方法都要调用 private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // 如果说minCapacity也就是所需的最小容量大于保存ArrayList数据的数组的长度的话，就需要调用grow(minCapacity)方法扩容。 //这个minCapacity到底为多少呢？举个例子在添加元素(add)方法中这个minCapacity的大小就为现在数组的长度加1 if (minCapacity - elementData.length &gt; 0) //调用grow方法进行扩容，调用此方法代表已经开始扩容了 grow(minCapacity); &#125; 12345678910111213141516171819202122/** * ArrayList扩容的核心方法。 */private void grow(int minCapacity) &#123; //elementData为保存ArrayList数据的数组 ///elementData.length求数组长度elementData.size是求数组中的元素个数 // oldCapacity为旧容量，newCapacity为新容量 int oldCapacity = elementData.length; //将oldCapacity 右移一位，其效果相当于oldCapacity /2， //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍， int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量， if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //再检查新容量是否超出了ArrayList所定义的最大容量， //若超出了，则调用hugeCapacity()来比较minCapacity和 MAX_ARRAY_SIZE， //如果minCapacity大于MAX_ARRAY_SIZE，则新容量则为Interger.MAX_VALUE，否则，新容量大小则为 MAX_ARRAY_SIZE。 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125; 扩容机制代码已经做了详细的解释。另外值得注意的是大家很容易忽略的一个运算符：移位运算符 简介：移位运算符就是在二进制的基础上对数字进行平移。按照平移的方向和填充数字的规则分为三种:&lt;&lt;(左移)、&gt;&gt;(带符号右移)和&gt;&gt;&gt;(无符号右移)。 作用：对于大数据的2进制运算,位移运算符比那些普通运算符的运算要快很多,因为程序仅仅移动一下而已,不去计算,这样提高了效率,节省了资源 比如这里：int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); 右移一位相当于除2，右移n位相当于除以 2 的 n 次方。这里 oldCapacity 明显右移了1位所以相当于oldCapacity /2。 另外需要注意的是： java 中的length 属性是针对数组说的,比如说你声明了一个数组,想知道这个数组的长度则用到了 length 这个属性. java 中的length()方法是针对字符串String说的,如果想看这个字符串的长度则用到 length()这个方法. .java 中的size()方法是针对泛型集合说的,如果想看这个泛型有多少个元素,就调用此方法来查看! 内部类 1234(1)private class Itr implements Iterator&lt;E&gt; (2)private class ListItr extends Itr implements ListIterator&lt;E&gt; (3)private class SubList extends AbstractList&lt;E&gt; implements RandomAccess (4)static final class ArrayListSpliterator&lt;E&gt; implements Spliterator&lt;E&gt; ArrayList有四个内部类，其中的Itr是实现了Iterator接口，同时重写了里面的hasNext()，next()，remove()等方法；其中的ListItr继承Itr，实现了ListIterator接口，同时重写了hasPrevious()，nextIndex()，previousIndex()，previous()，set(E e)，**add(E e)**等方法，所以这也可以看出了 **Iterator和ListIterator的区别:**ListIterator在Iterator的基础上增加了添加对象，修改对象，逆向遍历等方法，这些是Iterator不能实现的。 ArrayList经典Demo 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package list;import java.util.ArrayList;import java.util.Iterator;public class ArrayListDemo &#123; public static void main(String[] srgs)&#123; ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;(); System.out.printf(\"Before add:arrayList.size() = %d\\n\",arrayList.size()); arrayList.add(1); arrayList.add(3); arrayList.add(5); arrayList.add(7); arrayList.add(9); System.out.printf(\"After add:arrayList.size() = %d\\n\",arrayList.size()); System.out.println(\"Printing elements of arrayList\"); // 三种遍历方式打印元素 // 第一种：通过迭代器遍历 System.out.print(\"通过迭代器遍历:\"); Iterator&lt;Integer&gt; it = arrayList.iterator(); while(it.hasNext())&#123; System.out.print(it.next() + \" \"); &#125; System.out.println(); // 第二种：通过索引值遍历 System.out.print(\"通过索引值遍历:\"); for(int i = 0; i &lt; arrayList.size(); i++)&#123; System.out.print(arrayList.get(i) + \" \"); &#125; System.out.println(); // 第三种：for循环遍历 System.out.print(\"for循环遍历:\"); for(Integer number : arrayList)&#123; System.out.print(number + \" \"); &#125; // toArray用法 // 第一种方式(最常用) Integer[] integer = arrayList.toArray(new Integer[0]); // 第二种方式(容易理解) Integer[] integer1 = new Integer[arrayList.size()]; arrayList.toArray(integer1); // 抛出异常，java不支持向下转型 //Integer[] integer2 = new Integer[arrayList.size()]; //integer2 = arrayList.toArray(); System.out.println(); // 在指定位置添加元素 arrayList.add(2,2); // 删除指定位置上的元素 arrayList.remove(2); // 删除指定元素 arrayList.remove((Object)3); // 判断arrayList是否包含5 System.out.println(\"ArrayList contains 5 is: \" + arrayList.contains(5)); // 清空ArrayList arrayList.clear(); // 判断ArrayList是否为空 System.out.println(\"ArrayList is empty: \" + arrayList.isEmpty()); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://yuechuanx.top/categories/Java/"}],"tags":[{"name":"array-list","slug":"array-list","permalink":"https://yuechuanx.top/tags/array-list/"}]},{"title":"问题梳理-Java多线程","slug":"Java/questiones-multithread-in-java","date":"2019-01-03T12:10:39.000Z","updated":"2020-04-23T03:36:06.717Z","comments":true,"path":"Java/questiones-multithread-in-java/","link":"","permalink":"https://yuechuanx.top/Java/questiones-multithread-in-java/","excerpt":"","text":"1. 简述线程，程序、进程的基本概念。以及他们之间关系是什么？ 线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享同一块内存空间和一组系统资源，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。 程序是含有指令和数据的文件，被存储在磁盘或其他的数据存储设备中，也就是说程序是静态的代码。 进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。简单来说，一个进程就是一个执行中的程序，它在计算机中一个指令接着一个指令地执行着，同时，每个进程还占有某些系统资源如CPU时间，内存空间，文件，文件，输入输出设备的使用权等等。换句话说，当程序在执行时，将会被操作系统载入内存中。 线程 是 进程 划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。从另一角度来说，进程属于操作系统的范畴，主要是同一段时间内，可以同时执行一个以上的程序，而线程则是在同一程序内几乎同时执行一个以上的程序段。 线程上下文的切换比进程上下文切换要快很多 进程切换时，涉及到当前进程的CPU环境的保存和新被调度运行进程的CPU环境的设置。 线程切换仅需要保存和设置少量的寄存器内容，不涉及存储管理方面的操作。 2. 线程有哪些基本状态？这些状态是如何定义的? 新建(new)：新创建了一个线程对象。 可运行(runnable)：线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获 取cpu的使用权。 运行(running)：可运行状态(runnable)的线程获得了cpu时间片（timeslice），执行程序代码。 阻塞(block)：阻塞状态是指线程因为某种原因放弃了cpu使用权，也即让出了cpu timeslice，暂时停止运行。直到线程进入可运行(runnable)状态，才有 机会再次获得cpu timeslice转到运行(running)状态。阻塞的情况分三种： (一). 等待阻塞：运行(running)的线程执行o.wait()方法，JVM会把该线程放 入等待队列(waiting queue)中。 (二). 同步阻塞：运行(running)的线程在获取对象的同步锁时，若该同步 锁 被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。 (三). 其他阻塞: 运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。 死亡(dead)：线程run()、main()方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。 备注： 可以用早起坐地铁来比喻这个过程（下面参考自牛客网某位同学的回答）： 还没起床：sleeping 起床收拾好了，随时可以坐地铁出发：Runnable 等地铁来：Waiting 地铁来了，但要排队上地铁：I/O阻塞 上了地铁，发现暂时没座位：synchronized阻塞 地铁上找到座位：Running 到达目的地：Dead 3. 何为多线程？ 多线程就是多个线程同时运行或交替运行。单核CPU的话是顺序执行，也就是交替运行。多核CPU的话，因为每个CPU有自己的运算器，所以在多个CPU中可以同时运行。 4. 为什么多线程是必要的？ 使用线程可以把占据长时间的程序中的任务放到后台去处理。 用户界面可以更加吸引人，这样比如用户点击了一个按钮去触发某些事件的处理，可以弹出一个进度条来显示处理的进度。 程序的运行速度可能加快。 5 使用多线程常见的三种方式 ①继承Thread类 MyThread.java 1234567public class MyThread extends Thread &#123; @Override public void run() &#123; super.run(); System.out.println(\"MyThread\"); &#125;&#125; Run.java 123456789public class Run &#123; public static void main(String[] args) &#123; MyThread mythread = new MyThread(); mythread.start(); System.out.println(\"运行结束\"); &#125;&#125; 运行结果： 从上面的运行结果可以看出：线程是一个子任务，CPU以不确定的方式，或者说是以随机的时间来调用线程中的run方法。 ②实现Runnable接口 推荐实现Runnable接口方式开发多线程，因为Java单继承但是可以实现多个接口。 MyRunnable.java 123456public class MyRunnable implements Runnable &#123; @Override public void run() &#123; System.out.println(\"MyRunnable\"); &#125;&#125; Run.java 12345678910public class Run &#123; public static void main(String[] args) &#123; Runnable runnable=new MyRunnable(); Thread thread=new Thread(runnable); thread.start(); System.out.println(\"运行结束！\"); &#125;&#125; 运行结果： ③使用线程池 在《阿里巴巴Java开发手册》“并发处理”这一章节，明确指出线程资源必须通过线程池提供，不允许在应用中自行显示创建线程。 为什么呢？ 使用线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源开销，解决资源不足的问题。如果不使用线程池，有可能会造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。 另外《阿里巴巴Java开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险 Executors 返回线程池对象的弊端如下： FixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列长度为 Integer.MAX_VALUE,可能堆积大量的请求，从而导致OOM。 CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM。 对于线程池感兴趣的可以查看我的这篇文章：《Java多线程学习（八）线程池与Executor 框架》 点击阅读原文即可查看到该文章的最新版。 6 线程的优先级 每个线程都具有各自的优先级，线程的优先级可以在程序中表明该线程的重要性，如果有很多线程处于就绪状态，系统会根据优先级来决定首先使哪个线程进入运行状态。但这个并不意味着低 优先级的线程得不到运行，而只是它运行的几率比较小，如垃圾回收机制线程的优先级就比较低。所以很多垃圾得不到及时的回收处理。 线程优先级具有继承特性。 比如A线程启动B线程，则B线程的优先级和A是一样的。 线程优先级具有随机性。 也就是说线程优先级高的不一定每一次都先执行完。 Thread类中包含的成员变量代表了线程的某些优先级。如Thread.MIN_PRIORITY（常数1），Thread.NORM_PRIORITY（常数5）, Thread.MAX_PRIORITY（常数10）。其中每个线程的优先级都在Thread.MIN_PRIORITY（常数1） 到Thread.MAX_PRIORITY（常数10） 之间，在默认情况下优先级都是Thread.NORM_PRIORITY（常数5）。 学过操作系统这门课程的话，我们可以发现多线程优先级或多或少借鉴了操作系统对进程的管理。 7 Java多线程分类 用户线程 运行在前台，执行具体的任务，如程序的主线程、连接网络的子线程等都是用户线程 守护线程 运行在后台，为其他前台线程服务.也可以说守护线程是JVM中非守护线程的 “佣人”。 特点： 一旦所有用户线程都结束运行，守护线程会随JVM一起结束工作 应用： 数据库连接池中的检测线程，JVM虚拟机启动后的检测线程 最常见的守护线程： 垃圾回收线程 如何设置守护线程？ 可以通过调用 Thead 类的 setDaemon(true) 方法设置当前的线程为守护线程。 注意事项： 1. setDaemon(true)必须在start（）方法前执行，否则会抛出IllegalThreadStateException异常 2. 在守护线程中产生的新线程也是守护线程 3. 不是所有的任务都可以分配给守护线程来执行，比如读写操作或者计算逻辑 8 sleep()方法和wait()方法简单对比 两者最主要的区别在于：sleep方法没有释放锁，而wait方法释放了锁 。 两者都可以暂停线程的执行。 Wait通常被用于线程间交互/通信，sleep通常被用于暂停执行。 wait()方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的notify()或者notifyAll()方法。sleep()方法执行完成后，线程会自动苏醒。 9 为什么我们调用start()方法时会执行run()方法，为什么我们不能直接调用run()方法？ 这是另一个非常经典的java多线程面试问题，而且在面试中会经常被问到。很简单，但是很多人都会答不上来！ new一个Thread，线程进入了新建状态;调用start()方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start()会执行线程的相应准备工作，然后自动执行run()方法的内容，这是真正的多线程工作。 而直接执行run()方法，会把run方法当成一个mian线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。 总结： 调用start方法方可启动线程并使线程进入就绪状态，而run方法只是thread的一个普通方法调用，还是在主线程里执行。","categories":[{"name":"Java","slug":"Java","permalink":"https://yuechuanx.top/categories/Java/"}],"tags":[{"name":"multithread","slug":"multithread","permalink":"https://yuechuanx.top/tags/multithread/"},{"name":"interview","slug":"interview","permalink":"https://yuechuanx.top/tags/interview/"}]},{"title":"Java常见问题汇总-2","slug":"Java/string","date":"2019-01-03T12:10:39.000Z","updated":"2020-04-23T03:36:06.718Z","comments":true,"path":"Java/string/","link":"","permalink":"https://yuechuanx.top/Java/string/","excerpt":"","text":"String和StringBuffer、StringBuilder的区别是什么？String为什么是不可变的？ String和StringBuffer、StringBuilder的区别 可变性 简单的来说：String 类中使用 final 关键字字符数组保存字符串，private final char value[]，所以 String 对象是不可变的。而StringBuilder 与 StringBuffer 都继承自 AbstractStringBuilder 类，在 AbstractStringBuilder 中也是使用字符数组保存字符串char[]value 但是没有用 final 关键字修饰，所以这两种对象都是可变的。 StringBuilder 与 StringBuffer 的构造方法都是调用父类构造方法也就是 AbstractStringBuilder 实现的，大家可以自行查阅源码。 AbstractStringBuilder.java 12345678abstract class AbstractStringBuilder implements Appendable, CharSequence &#123; char[] value; int count; AbstractStringBuilder() &#123; &#125; AbstractStringBuilder(int capacity) &#123; value = new char[capacity]; &#125; 线程安全性 String 中的对象是不可变的，也就可以理解为常量，线程安全。AbstractStringBuilder 是 StringBuilder 与 StringBuffer 的公共父类，定义了一些字符串的基本操作，如 expandCapacity、append、insert、indexOf 等公共方法。StringBuffer 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。StringBuilder 并没有对方法进行加同步锁，所以是非线程安全的。 性能 每次对 String 类型进行改变的时候，都会生成一个新的 String 对象，然后将指针指向新的 String 对象。StringBuffer 每次都会对 StringBuffer 对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用 StirngBuilder 相比使用 StringBuffer 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。 对于三者使用的总结： 操作少量的数据 = String 单线程操作字符串缓冲区下操作大量数据 = StringBuilder 多线程操作字符串缓冲区下操作大量数据 = StringBuffer String为什么是不可变的吗？ 简单来说就是String类利用了final修饰的char类型数组存储字符，源码如下图所以： 12/** The value is used for character storage. */private final char value[]; String真的是不可变的吗？ 我觉得如果别人问这个问题的话，回答不可变就可以了。 下面只是给大家看两个有代表性的例子： 1) String不可变但不代表引用不可以变 123String str = \"Hello\";str = str + \" World\";System.out.println(\"str=\" + str); 结果： 1str=Hello World 解析： 实际上，原来String的内容是不变的，只是str由原来指向&quot;Hello&quot;的内存地址转为指向&quot;Hello World&quot;的内存地址而已，也就是说多开辟了一块内存区域给&quot;Hello World&quot;字符串。 2) 通过反射是可以修改所谓的“不可变”对象 123456789101112131415161718// 创建字符串\"Hello World\"， 并赋给引用sString s = \"Hello World\";System.out.println(\"s = \" + s); // Hello World// 获取String类中的value字段Field valueFieldOfString = String.class.getDeclaredField(\"value\");// 改变value属性的访问权限valueFieldOfString.setAccessible(true);// 获取s对象上的value属性的值char[] value = (char[]) valueFieldOfString.get(s);// 改变value所引用的数组中的第5个字符value[5] = '_';System.out.println(\"s = \" + s); // Hello_World 结果： 12s = Hello Worlds = Hello_World 解析： 用反射可以访问私有成员， 然后反射出String对象中的value属性， 进而改变通过获得的value引用改变数组的结构。但是一般我们不会这么做，这里只是简单提一下有这个东西。 什么是反射机制？反射机制的应用场景有哪些？ 反射机制介绍 JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。 静态编译和动态编译 **静态编译：**在编译时确定类型，绑定对象 **动态编译：**运行时确定类型，绑定对象 反射机制优缺点 优点： 运行期类型的判断，动态加载类，提高代码灵活度。 缺点： 性能瓶颈：反射相当于一系列解释操作，通知 JVM 要做的事情，性能比直接的java代码要慢很多。 反射的应用场景 反射是框架设计的灵魂。 在我们平时的项目开发过程中，基本上很少会直接使用到反射机制，但这不能说明反射机制没有用，实际上有很多设计、开发都与反射机制有关，例如模块化的开发，通过反射去调用对应的字节码；动态代理设计模式也采用了反射机制，还有我们日常使用的 Spring／Hibernate 等框架也大量使用到了反射机制。 举例：①我们在使用JDBC连接数据库时使用Class.forName()通过反射加载数据库的驱动程序；②Spring框架也用到很多反射机制，最经典的就是xml的配置模式。Spring 通过 XML 配置模式装载 Bean 的过程：1) 将程序内所有 XML 或 Properties 配置文件加载入内存中; 2)Java类里面解析xml或properties里面的内容，得到对应实体类的字节码字符串以及相关的属性信息; 3)使用反射机制，根据这个字符串获得某个类的Class实例; 4)动态配置实例的属性 推荐阅读： Reflection：Java反射机制的应用场景 Java基础之—反射（非常重要） 什么是JDK?什么是JRE？什么是JVM？三者之间的联系与区别 这几个是Java中很基本很基本的东西，但是我相信一定还有很多人搞不清楚！为什么呢？因为我们大多数时候在使用现成的编译工具以及环境的时候，并没有去考虑这些东西。 JDK: 顾名思义它是给开发者提供的开发工具箱,是给程序开发者用的。它除了包括完整的JRE（Java Runtime Environment），Java运行环境，还包含了其他供开发者使用的工具包。 JRE: 普通用户而只需要安装JRE（Java Runtime Environment）来运行Java程序。而程序开发者必须安装JDK来编译、调试程序。 JVM： 当我们运行一个程序时，JVM负责将字节码转换为特定机器代码，JVM提供了内存管理/垃圾回收和安全机制等。这种独立于硬件和操作系统，正是java程序可以一次编写多处执行的原因。 区别与联系： JDK用于开发，JRE用于运行java程序 ； JDK和JRE中都包含JVM ； JVM是java编程语言的核心并且具有平台独立性。 什么是字节码？采用字节码的最大好处是什么？ 先看下java中的编译器和解释器： Java中引入了虚拟机的概念，即在机器和编译程序之间加入了一层抽象的虚拟的机器。这台虚拟的机器在任何平台上都提供给编译程序一个的共同的接口。编译程序只需要面向虚拟机，生成虚拟机能够理解的代码，然后由解释器来将虚拟机代码转换为特定系统的机器码执行。在Java中，这种供虚拟机理解的代码叫做字节码（即扩展名为.class的文件），它不面向任何特定的处理器，只面向虚拟机。每一种平台的解释器是不同的，但是实现的虚拟机是相同的。Java源程序经过编译器编译后变成字节码，字节码由虚拟机解释执行，虚拟机将每一条要执行的字节码送给解释器，解释器将其翻译成特定机器上的机器码，然后在特定的机器上运行。这也就是解释了Java的编译与解释并存的特点。 Java源代码----&gt;编译器----&gt;jvm可执行的Java字节码(即虚拟指令)----&gt;jvm----&gt;jvm中解释器-----&gt;机器可执行的二进制机器码----&gt;程序运行。 采用字节码的好处： Java语言通过字节码的方式，在一定程度上解决了传统解释型语言执行效率低的问题，同时又保留了解释型语言可移植的特点。所以Java程序运行时比较高效，而且，由于字节码并不专对一种特定的机器，因此，Java程序无须重新编译便可在多种不同的计算机上运行。 Java和C++的区别 我知道很多人没学过C++，但是面试官就是没事喜欢拿咱们Java和C比呀！没办法！！！就算没学过C，也要记下来！ 都是面向对象的语言，都支持封装、继承和多态 Java不提供指针来直接访问内存，程序内存更加安全 Java的类是单继承的，C++支持多重继承；虽然Java的类不可以多继承，但是接口可以多继承。 Java有自动内存管理机制，不需要程序员手动释放无用内存 接口和抽象类的区别是什么？ 接口的方法默认是public，所有方法在接口中不能有实现，抽象类可以有非抽象的方法 接口中的实例变量默认是final类型的，而抽象类中则不一定 一个类可以实现多个接口，但最多只能实现一个抽象类 一个类实现接口的话要实现接口的所有方法，而抽象类不一定 接口不能用new实例化，但可以声明，但是必须引用一个实现该接口的对象 从设计层面来说，抽象是对类的抽象，是一种模板设计，接口是行为的抽象，是一种行为的规范。 注意：Java8 后接口可以有默认实现( default )。 成员变量与局部变量的区别有那些？ 从语法形式上，看成员变量是属于类的，而局部变量是在方法中定义的变量或是方法的参数；成员变量可以被public,private,static等修饰符所修饰，而局部变量不能被访问控制修饰符及static所修饰；但是，成员变量和局部变量都能被final所修饰； 从变量在内存中的存储方式来看，成员变量是对象的一部分，而对象存在于堆内存，局部变量存在于栈内存 从变量在内存中的生存时间上看，成员变量是对象的一部分，它随着对象的创建而存在，而局部变量随着方法的调用而自动消失。 成员变量如果没有被赋初值，则会自动以类型的默认值而赋值（一种情况例外被final修饰但没有被static修饰的成员变量必须显示地赋值）；而局部变量则不会自动赋值。 重载和重写的区别 重载： 发生在同一个类中，方法名必须相同，参数类型不同、个数不同、顺序不同，方法返回值和访问修饰符可以不同，发生在编译时。 重写： 发生在父子类中，方法名、参数列表必须相同，返回值范围小于等于父类，抛出的异常范围小于等于父类，访问修饰符范围大于等于父类；如果父类方法访问修饰符为private则子类就不能重写该方法。 字符型常量和字符串常量的区别 形式上: 字符常量是单引号引起的一个字符 字符串常量是双引号引起的若干个字符 含义上: 字符常量相当于一个整形值(ASCII值),可以参加表达式运算 字符串常量代表一个地址值(该字符串在内存中存放位置) 占内存大小 字符常量只占一个字节 字符串常量占若干个字节(至少一个字符结束标志)","categories":[{"name":"Java","slug":"Java","permalink":"https://yuechuanx.top/categories/Java/"}],"tags":[{"name":"interview-questions","slug":"interview-questions","permalink":"https://yuechuanx.top/tags/interview-questions/"}]},{"title":"Java常见问题汇总-1","slug":"Java/common-questions","date":"2019-01-03T12:10:39.000Z","updated":"2020-04-23T03:36:06.717Z","comments":true,"path":"Java/common-questions/","link":"","permalink":"https://yuechuanx.top/Java/common-questions/","excerpt":"","text":"一 为什么 Java 中只有值传递？ 首先回顾一下在程序设计语言中有关将参数传递给方法（或函数）的一些专业术语。按值调用(call by value)表示方法接收的是调用者提供的值，而按引用调用（call by reference)表示方法接收的是调用者提供的变量地址。一个方法可以修改传递引用所对应的变量值，而不能修改传递值调用所对应的变量值。 它用来描述各种程序设计语言（不只是Java)中方法参数传递方式。 Java程序设计语言总是采用按值调用。也就是说，方法得到的是所有参数值的一个拷贝，也就是说，方法不能修改传递给它的任何参数变量的内容。 下面通过 3 个例子来给大家说明 example 1 123456789101112131415161718public static void main(String[] args) &#123; int num1 = 10; int num2 = 20; swap(num1, num2); System.out.println(\"num1 = \" + num1); System.out.println(\"num2 = \" + num2);&#125;public static void swap(int a, int b) &#123; int temp = a; a = b; b = temp; System.out.println(\"a = \" + a); System.out.println(\"b = \" + b);&#125; 结果： 1234a = 20b = 10num1 = 10num2 = 20 解析： 在swap方法中，a、b的值进行交换，并不会影响到 num1、num2。因为，a、b中的值，只是从 num1、num2 的复制过来的。也就是说，a、b相当于num1、num2 的副本，副本的内容无论怎么修改，都不会影响到原件本身。 通过上面例子，我们已经知道了一个方法不能修改一个基本数据类型的参数，而对象引用作为参数就不一样，请看 example2. example 2 1234567891011public static void main(String[] args) &#123; int[] arr = &#123; 1, 2, 3, 4, 5 &#125;; System.out.println(arr[0]); change(arr); System.out.println(arr[0]);&#125;public static void change(int[] array) &#123; // 将数组的第一个元素变为0 array[0] = 0;&#125; 结果： 1210 解析： array 被初始化 arr 的拷贝也就是一个对象的引用，也就是说 array 和 arr 指向的时同一个数组对象。 因此，外部对引用对象的改变会反映到所对应的对象上。 通过 example2 我们已经看到，实现一个改变对象参数状态的方法并不是一件难事。理由很简单，方法得到的是对象引用的拷贝，对象引用及其他的拷贝同时引用同一个对象。 很多程序设计语言（特别是，C++和Pascal)提供了两种参数传递的方式：值调用和引用调用。有些程序员（甚至本书的作者）认为Java程序设计语言对对象采用的是引用调用，实际上，这种理解是不对的。由于这种误解具有一定的普遍性，所以下面给出一个反例来详细地阐述一下这个问题。 example 3 12345678910111213141516171819public class Test &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub Student s1 = new Student(\"小张\"); Student s2 = new Student(\"小李\"); Test.swap(s1, s2); System.out.println(\"s1:\" + s1.getName()); System.out.println(\"s2:\" + s2.getName()); &#125; public static void swap(Student x, Student y) &#123; Student temp = x; x = y; y = temp; System.out.println(\"x:\" + x.getName()); System.out.println(\"y:\" + y.getName()); &#125;&#125; 结果： 1234x:小李y:小张s1:小张s2:小李 解析： 交换之前： 交换之后： 通过上面两张图可以很清晰的看出： 方法并没有改变存储在变量 s1 和 s2 中的对象引用。swap方法的参数x和y被初始化为两个对象引用的拷贝，这个方法交换的是这两个拷贝 总结 Java程序设计语言对对象采用的不是引用调用，实际上，对象引用是按 值传递的。 下面再总结一下Java中方法参数的使用情况： 一个方法不能修改一个基本数据类型的参数（即数值型或布尔型》 一个方法可以改变一个对象参数的状态。 一个方法不能让对象参数引用一个新的对象。 参考： 《Java核心技术卷Ⅰ》基础知识第十版第四章4.5小节 二 ==与equals(重要) == : 它的作用是判断两个对象的地址是不是相等。即，判断两个对象是不是同一个对象。(基本数据类型比较的是值，引用数据类型比较的是内存地址) equals() : 它的作用也是判断两个对象是否相等。但它一般有两种使用情况： 情况1：类没有覆盖equals()方法。则通过equals()比较该类的两个对象时，等价于通过“==”比较这两个对象。 情况2：类覆盖了equals()方法。一般，我们都覆盖equals()方法来两个对象的内容相等；若它们的内容相等，则返回true(即，认为这两个对象相等)。 举个例子： 1234567891011121314151617public class test1 &#123; public static void main(String[] args) &#123; String a = new String(\"ab\"); // a 为一个引用 String b = new String(\"ab\"); // b为另一个引用,对象的内容一样 String aa = \"ab\"; // 放在常量池中 String bb = \"ab\"; // 从常量池中查找 if (aa == bb) // true System.out.println(\"aa==bb\"); if (a == b) // false，非同一对象 System.out.println(\"a==b\"); if (a.equals(b)) // true System.out.println(\"aEQb\"); if (42 == 42.0) &#123; // true System.out.println(\"true\"); &#125; &#125;&#125; 说明： String中的equals方法是被重写过的，因为object的equals方法是比较的对象的内存地址，而String的equals方法比较的是对象的值。 当创建String类型的对象时，虚拟机会在常量池中查找有没有已经存在的值和要创建的值相同的对象，如果有就把它赋给当前引用。如果没有就在常量池中重新创建一个String对象。 三 hashCode与equals（重要） 面试官可能会问你：“你重写过 hashcode 和 equals 么，为什么重写equals时必须重写hashCode方法？” hashCode（）介绍 hashCode() 的作用是获取哈希码，也称为散列码；它实际上是返回一个int整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。hashCode() 定义在JDK的Object.java中，这就意味着Java中的任何类都包含有hashCode() 函数。另外需要注意的是： Object 的 hashcode 方法是本地方法，也就是用 c 语言或 c++ 实现的，该方法通常用来将对象的 内存地址 转换为整数之后返回。 1234567891011121314151617/** * Returns a hash code value for the object. This method is * supported for the benefit of hash tables such as those provided by * &#123;@link java.util.HashMap&#125;. * &lt;p&gt; * As much as is reasonably practical, the hashCode method defined by * class &#123;@code Object&#125; does return distinct integers for distinct * objects. (This is typically implemented by converting the internal * address of the object into an integer, but this implementation * technique is not required by the * Java&amp;trade; programming language.) * * @return a hash code value for this object. * @see java.lang.Object#equals(java.lang.Object) * @see java.lang.System#identityHashCode */public native int hashCode(); 散列表存储的是键值对(key-value)，它的特点是：能根据“键”快速的检索出对应的“值”。这其中就利用到了散列码！（可以快速找到所需要的对象） 为什么要有hashCode 我们以“HashSet如何检查重复”为例子来说明为什么要有hashCode： 当你把对象加入HashSet时，HashSet会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他已经加入的对象的hashcode值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。但是如果发现有相同hashcode值的对象，这时会调用equals（）方法来检查hashcode相等的对象是否真的相同。如果两者相同，HashSet就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。（摘自我的Java启蒙书《Head fist java》第二版）。这样我们就大大减少了equals的次数，相应就大大提高了执行速度。 hashCode（）与equals（）的相关规定 如果两个对象相等，则hashcode一定也是相同的 两个对象相等,对两个对象分别调用equals方法都返回true 两个对象有相同的hashcode值，它们也不一定是相等的 因此，equals方法被覆盖过，则hashCode方法也必须被覆盖 hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写hashCode()，则该class的两个对象无论如何都不会相等（即使这两个对象指向相同的数据） 为什么两个对象有相同的hashcode值，它们也不一定是相等的？ 在这里解释一位小伙伴的问题。以下内容摘自《Head Fisrt Java》。 因为hashCode() 所使用的杂凑算法也许刚好会让多个对象传回相同的杂凑值。越糟糕的杂凑算法越容易碰撞，但这也与数据值域分布的特性有关（所谓碰撞也就是指的是不同的对象得到相同的 hashCode）。 我们刚刚也提到了 HashSet,如果 HashSet 在对比的时候，同样的 hashcode 有多个对象，它会使用 equals() 来判断是否真的相同。也就是说 hashcode 只是用来缩小查找成本。 参考： https://blog.csdn.net/zhzhao999/article/details/53449504 https://www.cnblogs.com/skywang12345/p/3324958.html https://www.cnblogs.com/skywang12345/p/3324958.html https://www.cnblogs.com/Eason-S/p/5524837.html","categories":[{"name":"Java","slug":"Java","permalink":"https://yuechuanx.top/categories/Java/"}],"tags":[{"name":"interview-questions","slug":"interview-questions","permalink":"https://yuechuanx.top/tags/interview-questions/"}]},{"title":"【剑指Offer】栈实现队列","slug":"Algorithm/implement-queue-with-stack","date":"2018-12-03T12:03:11.000Z","updated":"2020-04-23T03:36:06.708Z","comments":true,"path":"Algorithm/implement-queue-with-stack/","link":"","permalink":"https://yuechuanx.top/Algorithm/implement-queue-with-stack/","excerpt":"","text":"题目描述 用两个栈来实现一个队列，完成队列的Push和Pop操作。 队列中的元素为int类型。 算法分析 队列具有先进先出的性质，栈具有后进先出的性质，根据他们性质的联系，使用两个栈实现队列的思路如下： push操作用一个栈进行存储，pop操作用存储数据的栈向另一栈进行存放，这样数据两次倒转不变， 第二个栈的栈顶元素作为返回值，然后在倒转回第一个栈。 代码实现 1234567891011121314151617181920212223242526272829class Solution&#123;public: void push(int node) &#123; stack1.push(node); &#125; int pop() &#123; int res; while (!stack1.empty()) &#123; stack2.push(stack1.top()); stack1.pop(); &#125; res = stack2.top(); stack2.pop(); while (!stack2.empty()) &#123; stack1.push(stack2.top()); stack2.pop(); &#125; return res; &#125;private: stack&lt;int&gt; stack1; stack&lt;int&gt; stack2;&#125;;","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://yuechuanx.top/categories/Algorithm/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://yuechuanx.top/tags/algorithm/"},{"name":"queue","slug":"queue","permalink":"https://yuechuanx.top/tags/queue/"},{"name":"stack","slug":"stack","permalink":"https://yuechuanx.top/tags/stack/"}]},{"title":"【剑指Offer】旋转数组的最小数字","slug":"Algorithm/min-number-in-rotate-array","date":"2018-12-03T12:03:11.000Z","updated":"2020-04-23T03:36:06.709Z","comments":true,"path":"Algorithm/min-number-in-rotate-array/","link":"","permalink":"https://yuechuanx.top/Algorithm/min-number-in-rotate-array/","excerpt":"","text":"题目描述 把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。 输入一个非递减排序的数组的一个旋转，输出旋转数组的最小元素。 例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。 NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。 算法分析 我觉得这道题目挺没有意思，最直接的一个做法是遍历整个数组，它举了一个递减排序的数组，这里只需要找到旋转点是可以用二分的，不确定旋转数组是否是有序的话，就只能用第一个方法了。 代码实现 1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: int minNumberInRotateArray(vector&lt;int&gt; rotateArray) &#123; if(rotateArray.size() == 0)&#123; return 0; &#125; else&#123; int first = rotateArray[0]; int i = 1; while(rotateArray[i] != '\\0')&#123; if(rotateArray[i] &lt; first)&#123; break; //return rotateArray[i]; &#125; i++; &#125; return rotateArray[i]; &#125; &#125;&#125;;class Solution &#123;public: int minNumberInRotateArray(vector&lt;int&gt; rotateArray) &#123; int n = rotateArray.size(); if (n == 0) return 0; else &#123; int min = rotateArray[0]; for (auto i : rotateArray) &#123; if (i &lt; min) min = i; &#125; return min; &#125; &#125;&#125;;","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://yuechuanx.top/categories/Algorithm/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://yuechuanx.top/tags/algorithm/"},{"name":"search","slug":"search","permalink":"https://yuechuanx.top/tags/search/"}]},{"title":"【剑指Offer】从尾到头打印链表","slug":"Algorithm/print-list-from-tail-to-head","date":"2018-12-03T12:03:11.000Z","updated":"2020-04-23T03:36:06.709Z","comments":true,"path":"Algorithm/print-list-from-tail-to-head/","link":"","permalink":"https://yuechuanx.top/Algorithm/print-list-from-tail-to-head/","excerpt":"","text":"题目描述 输入一个链表，按链表值从尾到头的顺序返回一个ArrayList。 算法分析 使用递归的方法： 我们可以使用递归函数，head和head-&gt;next存在的时候进入下一层，当进入最后一层的时候开始从尾部返回。 使用栈的方法： 首先遍历一遍链表，将顺序的值压栈，然后利用栈的性质（后进先出）进行打印。 代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/*** struct ListNode &#123;* int val;* struct ListNode *next;* ListNode(int x) :* val(x), next(NULL) &#123;* &#125;* &#125;;*/// 递归class Solution &#123;public: vector&lt;int&gt; printListFromTailToHead(ListNode* head) &#123; vector&lt;int&gt; result; helper(head, result); return result; &#125; private: void helper(ListNode* head, vector&lt;int&gt; &amp;result)&#123; if(head)&#123; if(head -&gt; next)&#123; helper(head -&gt; next, result); &#125; result.push_back(head -&gt; val); &#125; &#125;&#125;;// 栈class Solution &#123;public: vector&lt;int&gt; printListFromTailToHead(ListNode* head) &#123; vector&lt;int&gt; res; stack&lt;int&gt; st; while (head) &#123; st.push(head-&gt;val); head = head-&gt;next; &#125; while (!st.empty()) &#123; res.push_back(st.top()); st.pop(); &#125; return res; &#125;&#125;;","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://yuechuanx.top/categories/Algorithm/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://yuechuanx.top/tags/algorithm/"},{"name":"linked-list","slug":"linked-list","permalink":"https://yuechuanx.top/tags/linked-list/"}]},{"title":"【剑指Offer】二维数组中的查找","slug":"Algorithm/find-in-two-dimensional-array","date":"2018-12-03T12:03:11.000Z","updated":"2020-04-23T03:36:06.708Z","comments":true,"path":"Algorithm/find-in-two-dimensional-array/","link":"","permalink":"https://yuechuanx.top/Algorithm/find-in-two-dimensional-array/","excerpt":"","text":"题目描述 在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 算法分析 我们可以观察二维数组（m，n）中的4个顶点。 左上角（0，0），向右和向下都是递增。右下角（m，n），向左和向上都是递增，所以我们无法确认哪一个方向能更快找到目标值。 考虑左下角（m，0），向右是递增的，向上的递减的，所以通过比较 target 和 current value 大小，我们可以判断其所在的相对方向。同理右上角。 代码实现 12345678910111213141516171819202122232425262728293031323334353637383940class Solution &#123;public: bool Find(int target, vector&lt;vector&lt;int&gt; &gt; array) &#123; int row = array.size(); int col = array[0].size(); int i, j; // 起始点在左下角 for(i = row - 1, j = 0; i &gt;= 0 &amp;&amp; j &lt; col;) &#123; if(target == array[i][j]) return true; if(target &lt; array[i][j])&#123; i--; continue; &#125; if(target &gt; array[i][j])&#123; j++; continue; &#125; &#125; // 或者起始点在右上角// for(i = 0, j = col - 1; i &lt; row &amp;&amp; j &gt;= 0;) &#123;// if(target == array[i][j])// return true;// if(target &lt; array[i][j])&#123;// j--;// continue;// &#125;// if(target &gt; array[i][j])&#123;//// i++;// continue;// &#125;// &#125; return false; &#125;&#125;;","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://yuechuanx.top/categories/Algorithm/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://yuechuanx.top/tags/algorithm/"},{"name":"array","slug":"array","permalink":"https://yuechuanx.top/tags/array/"}]},{"title":"【剑指Offer】重建二叉树","slug":"Algorithm/reconstruct-binary-tree","date":"2018-12-03T12:03:11.000Z","updated":"2020-04-23T03:36:06.709Z","comments":true,"path":"Algorithm/reconstruct-binary-tree/","link":"","permalink":"https://yuechuanx.top/Algorithm/reconstruct-binary-tree/","excerpt":"","text":"问题描述 输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列{1,2,4,7,3,5,6,8}和中序遍历序列{4,7,2,1,5,3,8,6}，则重建二叉树并返回。 算法分析 算法的基本思路是分治法，divide and conquer，可以拆解这个为相似的小问题，pre的第一个元素是根节点，树或者子树，然后可以拆解为左右子树的pre和vin，进行同样的过程 代码实现 1234567891011121314151617181920212223242526272829303132333435/** * Definition for binary tree * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* reConstructBinaryTree(vector&lt;int&gt; pre,vector&lt;int&gt; vin) &#123; if (pre.size() == 0) return NULL; else if (pre.size() == 1)&#123; TreeNode* root = new TreeNode(pre.back()); root -&gt; left = NULL; root -&gt; right = NULL; return root; &#125; else &#123; TreeNode* root = new TreeNode(pre.at(0)); vector&lt;int&gt;::iterator it = vin.begin(); while(it != vin.end() &amp;&amp; *it != pre.at(0)) ++it; int dis = it - vin.begin(); vector&lt;int&gt; subPreLeft(pre.begin() + 1, pre.begin() + dis + 1); vector&lt;int&gt; subPreRight(pre.begin() + dis + 1, pre.end()); vector&lt;int&gt; subVinLeft(vin.begin(), it); vector&lt;int&gt; subVinRight(it + 1, vin.end() ); root -&gt; left = reConstructBinaryTree(subPreLeft, subVinLeft); root -&gt; right = reConstructBinaryTree(subPreRight, subVinRight); return root; &#125; &#125; &#125;;","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://yuechuanx.top/categories/Algorithm/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://yuechuanx.top/tags/algorithm/"},{"name":"binary-tree","slug":"binary-tree","permalink":"https://yuechuanx.top/tags/binary-tree/"}]},{"title":"【剑指Offer】替换空格","slug":"Algorithm/replace-sapce","date":"2018-12-03T12:03:11.000Z","updated":"2020-04-23T03:36:06.710Z","comments":true,"path":"Algorithm/replace-sapce/","link":"","permalink":"https://yuechuanx.top/Algorithm/replace-sapce/","excerpt":"","text":"题目描述 请实现一个函数，将一个字符串中的空格替换成“%20”。例如，当字符串为We Are Happy.则经过替换之后的字符串为We%20Are%20Happy。 算法分析 首先复制一份字符串的备份，我们需要知道字符串原始长度，空格数来计算替换后字符串的长度，之后就只需要根据字符串原始长度和新长度对字符串进行拷贝。 代码实现 1234567891011121314151617181920212223242526272829class Solution &#123;public: void replaceSpace(char *str,int length) &#123; char *t = str; int strLen = 0, newStrLen = 0, spaceCount = 0; int p,q; if(str == NULL || length &lt;0) return; // 首先判定进入算法的有效条件 while(*t != '\\0')&#123; strLen++; if(*t == ' ') spaceCount++; t++; &#125; // 取字符串长度， 空格的个数 newStrLen = strLen + 2 * spaceCount; // 新的字符串的长度 if(newStrLen &gt; length) return ; for(p = strLen, q = newStrLen; p &gt;= 0; p-- )&#123; if(str[p] == ' ')&#123; str[q--] = '0'; str[q--] = '2'; str[q--] = '%'; &#125; else &#123; str[q--] = str[p]; &#125; &#125; &#125;&#125;;","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://yuechuanx.top/categories/Algorithm/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://yuechuanx.top/tags/algorithm/"},{"name":"string","slug":"string","permalink":"https://yuechuanx.top/tags/string/"}]},{"title":"<深入理解JVM> 函数调用机制","slug":"Java/implement-function-call-in-c","date":"2018-11-27T11:48:56.000Z","updated":"2020-04-23T03:36:06.717Z","comments":true,"path":"Java/implement-function-call-in-c/","link":"","permalink":"https://yuechuanx.top/Java/implement-function-call-in-c/","excerpt":"","text":"C语言函数调用实现 通过一个简单的C语言程序分析 123456789101112131415#include &lt;stdio.h&gt;int add();int main(int argc, char const *argv[])&#123; int c = add(); printf(\"%d\", c); return 0;&#125;int add() &#123; int z = 1 + 2; return z;&#125; 将这段C程序编译成汇编程序： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253 .file &quot;.\\\\sampleAdd.c&quot; .section .rodata.LC0: .string &quot;%d&quot; .text .globl main .type main, @functionmain:.LFB13: .cfi_startproc pushq %rbp .cfi_def_cfa_offset 16 .cfi_offset 6, -16 movq %rsp, %rbp .cfi_def_cfa_register 6 subq $32, %rsp movl %edi, -20(%rbp) movq %rsi, -32(%rbp) movl $0, %eax call add movl %eax, -4(%rbp) movl -4(%rbp), %eax movl %eax, %esi movl $.LC0, %edi movl $0, %eax call printf movl $0, %eax leave .cfi_def_cfa 7, 8 ret .cfi_endproc.LFE13: .size main, .-main .globl add .type add, @functionadd:.LFB14: .cfi_startproc pushq %rbp .cfi_def_cfa_offset 16 .cfi_offset 6, -16 movq %rsp, %rbp .cfi_def_cfa_register 6 movl $3, -4(%rbp) movl -4(%rbp), %eax popq %rbp .cfi_def_cfa 7, 8 ret .cfi_endproc.LFE14: .size add, .-add .ident &quot;GCC: (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609&quot; .section .note.GNU-stack,&quot;&quot;,@progbits 去除宏定义，保留主要指令如下： 123456789101112131415161718192021222324main: pushq %rbp movq %rsp, %rbp subq $32, %rsp movl %edi, -20(%rbp) movq %rsi, -32(%rbp) movl $0, %eax call add movl %eax, -4(%rbp) movl -4(%rbp), %eax movl %eax, %esi movl $.LC0, %edi movl $0, %eax call printf movl $0, %eax leave retadd: pushq %rbp movq %rsp, %rbp movl $3, -4(%rbp) movl -4(%rbp), %eax popq %rbp ret 汇编程序有两个标号main, add。这不是巧合，而是编译器处理的结果，编译器会把函数名处理成汇编程序中的标号。 有了标号，汇编程序就能执行函数调用，即call指令，有一条call and指令，就是汇编中执行函数调用的指令。 接下来逐段分析： 1234# 保存调用者栈基地址，并为main()函数分配新栈空间pushq %rbp movq %rsp, %rbpsubq $32, %rsp # 分配新栈，一共32字节 在mian，add代码段的开始都包含这3条指令，add代码段第3行是movl $3, -4(%rbp)该指令与mian代码段的subq $32, %rsp作用是相同的——分配栈空间。 这3条指令的作用为：保存段调用者基址，为新方法分配方法栈。这几乎是汇编程序执行方法调用的标准定式。 main() 函数的方法栈内存布局如下图所示： // 这里需要插入一张图片 带入参的C程序 123456789101112131415#include &lt;stdio.h&gt;int add(int a, int b);int main(int argc, char const *argv[])&#123; int a = 5, b = 3; int c = add(a, b); return 0;&#125;int add(int a, int b) &#123; int z = 1 + 2; return z;&#125; 将这段C程序编译成汇编程序(去除宏定义，保留主要指令)： 1234567891011121314151617181920212223242526main: pushq %rbp movq %rsp, %rbp subq $32, %rsp movl %edi, -20(%rbp) movq %rsi, -32(%rbp) movl $5, -12(%rbp) movl $3, -8(%rbp) movl -8(%rbp), %edx movl -12(%rbp), %eax movl %edx, %esi movl %eax, %edi call add movl %eax, -4(%rbp) movl $0, %eax leave retadd: pushq %rbp movq %rsp, %rbp movl %edi, -20(%rbp) movl %esi, -24(%rbp) movl $3, -4(%rbp) movl -4(%rbp), %eax popq %rbp ret C语言函数的调用机制 压栈 main函数调用add()函数之前，会将两个入参压栈（压入调用者的栈），压栈之后add()就可以获取这两个入参。 参数传递顺序 Linux平台，调用者函数向被调用者函数传递参数，采用逆向顺序压栈，即最后一个参数第一个压栈，第一个参数最后压栈 读取入参 读取入参的方式是：通过add()函数的栈基地址rbp的相对地址，从main()函数中读取，最后一位入参在8(%rbp)，依次12(%rbp)… 真实物理机器上执行函数调用的步骤： 保存调用者栈基地址，当前IP寄存器入栈 调用函数时，在x86平台参数从右到左依次入栈 一个方法所分配的栈空间大小，取决于方法内部局部变量空间、为被调用者所传递的入参大小 被调用者在接收入参时，从8(%rbp)处开始，往上逐个获取参数 被调用者将返回结果保存在eax寄存器中，调用者从该寄存器取值 补充（关于寄存器） %rax 作为函数返回值使用。 %rsp 栈指针寄存器，指向栈顶 %rdi，%rsi，%rdx，%rcx，%r8，%r9 用作函数参数，依次对应第1参数，第2参数。。。 %rbx，%rbp，%r12，%r13，%14，%15 用作数据存储，遵循被调用者使用规则，简单说就是随便用，调用子函数之前要备份它，以防他被修改 %r10，%r11 用作数据存储，遵循调用者使用规则，简单说就是使用之前要先保存原值 Reference X86-64寄存器和栈帧 揭秘Java虚拟机","categories":[{"name":"Java","slug":"Java","permalink":"https://yuechuanx.top/categories/Java/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://yuechuanx.top/tags/jvm/"}]},{"title":"平衡二叉树（AVLTree）封装+模板实现","slug":"Algorithm/avlree-template-implement","date":"2018-05-27T03:36:49.000Z","updated":"2020-04-23T03:36:06.708Z","comments":true,"path":"Algorithm/avlree-template-implement/","link":"","permalink":"https://yuechuanx.top/Algorithm/avlree-template-implement/","excerpt":"","text":"简介 平衡树（AVLTree） 在计算机科学中，AVL树是最先发明的自平衡二叉查找树。在AVL树中任何节点的两个子树的高度最大差别为1，所以它也被称为高度平衡树。查找、插入和删除在平均和最坏情况下的时间复杂度都是。增加和删除可能需要通过一次或多次树旋转来重新平衡这个树。AVL树得名于它的发明者G. M. Adelson-Velsky和E. M. Landis，他们在1962年的论文《An algorithm for the organization of information》中发表了它。 节点的平衡因子是它的左子树的高度减去它的右子树的高度（有时相反）。带有平衡因子1、0或 -1的节点被认为是平衡的。带有平衡因子 -2或2的节点被认为是不平衡的，并需要重新平衡这个树。平衡因子可以直接存储在每个节点中，或从可能存储在节点中的子树高度计算出来。 二叉查找树给我们带来了很多方便，但是由于其在有序序列插入时就会退化成单链表（时间复杂度退化成 O(n)，AVL-tree就克服了上述困难。AVL-tree是一个“加上了平衡条件的”二叉搜索树，平衡条件确保整棵树的深度为O(log n)。 AVL树是最先发明的自平衡二叉查找树。在AVL树中任何节点的两个子树的高度最大差别为一，所以它也被称为高度平衡树。查找、插入和删除在平均和最坏情况下都是 O(log n)。增加和删除可能需要通过一次或多次树旋转来重新平衡这个树。 AVL树的所有操作都与二叉查找树相同，不同的是，这里AVL树需要做“AVL旋转”。 AVL旋转 AVL树最重要的核心部分就是AVL旋转了，这部分我的感触是，单做旋转还是挺好理解的，只不过写起代码来有点复杂，书中以插入节点为例，删除节点的部分折腾了好久。 在理解AVL旋转之前，首先得知道以下几个概念： AVL 树节点的插入总是在叶子节点。 AVL 树在插入节点之前总是满足平衡条件的。 插入新节点后有可能满足平衡条件也有可能不满足。 当不满足平衡条件后，我们就需要对新的树进行旋转。 旋转之前，我们首先要找到一个X节点，这个X节点做如下定义： 假如我们在某一个叶子节点处插入一个新的节点后，此时这棵树的某些节点的平衡性会发生变化，那么我们从叶子节点向上到根节点的路径上第一个平衡性发生变化的节点。 基于这个X节点，考虑一件事情： 这个X节点分为左右子树，左右子树又有左右子树，1分2，2分4，所以以这个X节点为根节点的话，新插入的节点可能出现的位置有： X的左孩子节点的左子树上**(left-left)** X的右孩子节点的右子树上**(right-right)** X的左孩子节点的右子树上**(left-right)** X的右孩子节点的左子树上**(right-left)** 根据上述情况就延生出了4种旋转： 1.left-left Rotation 2.right-right Rotation 3.left-right Rotation 4.right-left Rotation 前两种属于单旋转，后两种属于双旋转，双旋转的操作可以由两次单旋转组成。 PS:AVL树的旋转还是得画图来理解，这里直接贴出书中的图了。 图片来自 C小加的博客 6节点的左子树3节点高度比右子树7节点大2，左子树3节点的左子树1节点高度大于右子树4节点，这种情况成为左左（LL）。 6节点的左子树2节点高度比右子树7节点大2，左子树2节点的左子树1节点高度小于右子树4节点，这种情况成为左右（LR）。 2节点的左子树1节点高度比右子树5节点小2，右子树5节点的左子树3节点高度大于右子树6节点，这种情况成为右左（RL）。 2节点的左子树1节点高度比右子树4节点小2，右子树4节点的左子树3节点高度小于右子树6节点，这种情况成为右右（RR）。 从图2中可以可以看出，1和4两种情况是对称的，这两种情况的旋转算法是一致的，只需要经过一次旋转就可以达到目标，我们称之为单旋转。2和3两种情况也是对称的，这两种情况的旋转算法也是一致的，需要进行两次旋转，我们称之为双旋转。 那么为什么需要双旋转呢？ 这里我做出我个人的解释，在 LL 情况中，要达到平衡，是需要将失衡节点划分到右边，失衡节点的左孩子补上失衡节点的位置。这样左子树的高度 -1， 右边的高度 +1，这样左右两边的个数就平衡了。当然根据BST的性质，如果失衡节点存在右孩子的话应该划也要分到右边。RR 情况与 LL 情况对称。 而在 LR 情况中，我们是需要把失衡节点划到右边，失衡节点的左孩子的右孩子替补失衡节点原来的位置。但我们的节点存储结构有不能获得前驱节点的限制，我们只有后继关系，即我们只能通过失衡节点访问其他节点，所以不能直接把LR孩子放上来，而是分成两步调整。 // 这里的描述太那啥了，得搞点图说明下 AVL-Tree实现 AVL-Tree是一个二叉排序树，其基本操作也跟它类似，唯一需要注意的就是在插入，删除节点后，需要对树进行调整，让树的每个节点保持平衡。 节点的平衡因子是通过计算其左子树和右子树的差得来的，这里有两种考虑方式： 每次都计算一次（递归求深度）。 将平衡因子作为一个成员变量保存在节点中，平衡性发生变化的时候更新。 本文采取的是第一种方式，关于两种方式利弊的比较： // 不想写？自己百度吧，反正就是第一种方法从上到下递归存在重复调用增加时间开销，第二种平衡性变化时候需要update 失衡位置 balanceFactor 另外，这里我用了C++类封装，为了学习还顺便使用了模板，所以类的声明和实现都放在了一个文件中，感觉内容太多，还是分开来比较好。 12345678910111213141516171819// AVLNode.h#ifndef __AVLNODE_H__#define __AVLNODE_H__#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;template &lt;typename KeyType&gt;class AVLNode&#123;public: KeyType key; AVLNode * left; AVLNode * right; AVLNode() : key(0), left(NULL), right(NULL) &#123;&#125; AVLNode(KeyType k) :key(k), left(NULL), right(NULL) &#123;&#125;&#125;;#endif 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576// AVLTree.h#ifndef AVLTREE_AVLTREE_H#define AVLTREE_AVLTREE_H#include \"AVLNode.h\"//AVL树的模板实现template &lt;typename KeyType&gt;class AVLTree&#123; //类型定义 typedef AVLNode&lt;KeyType&gt; AVLNode; typedef AVLTree&lt;KeyType&gt; AVLTree;private: AVLNode * avlroot; //求树的高度 int __height(const AVLNode *root); //高度差（平衡因子） int __diff(const AVLNode*root); //AVL4种旋转：左左，左右，右右，右左 //X定义为插入位置节点到根节点的路径上平衡条件被改变的节点中最深的那个节点 //X通过递归返回的方式找到 //左左：插入点位于X的左孩子节点的左子树 //左右：插入点位于X的左孩子节点的右子树 //右右：插入点位于X的右孩子节点的右子树 //右左：插入点位于X的右孩子节点的左子树 //单旋转 AVLNode * __ll_Rotation(AVLNode *root);//left-left rotation AVLNode * __rr_Rotation(AVLNode *root);//right-right rotation //双旋转 AVLNode * __lr_Rotation(AVLNode *root);//left-right rotation AVLNode * __rl_Rotation(AVLNode *root);//right-left rotation //平衡操作 AVLNode * __Balance(AVLNode *root); //插入的内部实现 AVLNode * __Insert(AVLNode *root, const KeyType &amp;k); //中序遍历的两种重载 // 1. 直接输出中序遍历节点 void __InorderTraversal(const AVLNode* root); // 2. 结果保存到vector中 void __InorderTraversal(const AVLNode*root, std::vector&lt;KeyType&gt;&amp;vec); //判断是否是叶子节点 bool __isLeaf(AVLNode* const &amp;node) &#123;return (node-&gt;left == nullptr &amp;&amp; node-&gt;right == nullptr) ? true : false&#125;; //判断是否有两个孩子 bool __isNodeWithTwoChild(AVLNode * const &amp;node); //查找的内部实现 AVLNode* __search(AVLNode *const root, const KeyType &amp;k); //删除树的所有节点 void __deleteTree(AVLNode * root); //删除节点 AVLNode* __Delete(AVLNode * root, const KeyType&amp; k); //求当前根节点最小（一路向左） AVLNode* __treeMin(AVLNode *root); //求当前根节点的最大（一路向右） AVLNode* __treeMax(AVLNode *root);public: AVLTree()&#123; avlroot = nullptr; &#125;//默认构造函数 ~AVLTree();//析构函数删除树中所有节点 AVLTree(const std::vector&lt;KeyType&gt;&amp;);//构造函数，容器构造 AVLTree(const KeyType * arr, size_t len);//构造函数，数组构造 void InorderTraversal();//中序遍历外部接口 void InorderTraversal(std::vector&lt;KeyType&gt;&amp;);//中序遍历外部接口重载2 bool Delete(const KeyType &amp;k);//删除节点的外部接口 void Insert(const KeyType &amp; k);//插入节点的外部接口 bool IsEmpty()&#123; return avlroot == nullptr; &#125; //树空？ bool search(const KeyType &amp;k);//查询外部接口&#125;;#endif //AVLTREE_AVLTREE_H 旋转操作 12345678910111213141516171819202122232425262728293031323334353637template &lt;typename KeyType&gt;AVLNode * AVLTree::__ll_Rotation(AVLNode *root)&#123; AVLNode * tmp; tmp = root-&gt;left; root-&gt;left = tmp-&gt;right; tmp-&gt;right = root; return tmp;&#125;template &lt;typename KeyType&gt;AVLNode * AVLTree::__rr_Rotation(AVLNode *root)&#123; AVLNode* tmp; tmp = root-&gt;right; root-&gt;right = tmp-&gt;left; tmp-&gt;left = root; return tmp;&#125;template &lt;typename KeyType&gt;AVLNode * AVLTree::__lr_Rotation(AVLNode *root)&#123; AVLNode * tmp; tmp = root-&gt;left; root-&gt;left = __rr_Rotation(tmp); return __ll_Rotation(root);&#125;template &lt;typename KeyType&gt;AVLNode * AVLTree::__rl_Rotation(AVLNode *root)&#123; AVLNode * tmp; tmp = root-&gt;right; root-&gt;right = __ll_Rotation(tmp); return __rr_Rotation(root);&#125; AVLTree 插入 12345678910111213141516171819202122template &lt;typename KeyType&gt;AVLNode * AVLTree::__Insert(AVLNode * root, const KeyType&amp; k)&#123; if (nullptr == root) &#123; root = new AVLNode(k); return root; &#125;//递归返回条件 else if (k &lt; root-&gt;key) &#123; root-&gt;left = __Insert(root-&gt;left, k);//递归左子树 //balance operation root = __Balance(root);//平衡操作包含了四种旋转 &#125; else if (k&gt;root-&gt;key) &#123; root-&gt;right = __Insert(root-&gt;right, k);//递归右子树 //balance operation root = __Balance(root);//平衡操作包含了四种旋转 &#125; return root;&#125; AVLTree 删除 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869//删除节点的私有成员实现template &lt;typename KeyType&gt;AVLNode * AVLTree::__Delete(AVLNode *root, const KeyType&amp; k)&#123; if (nullptr == root) return root; if (!search(k))//查找删除元素是否存在 &#123; std::cerr &lt;&lt; \"Delete error , key not find\" &lt;&lt; std::endl; return root; &#125; if (k == root-&gt;key)//根节点 &#123; if (__isNodeWithTwoChild(root))//左右子树都非空 &#123; if (__diff(root) &gt; 0)//左子树更高，在左边删除 &#123; root-&gt;key = __treeMax(root-&gt;left)-&gt;key;//以左子树的最大值替换当前值 root-&gt;left = __Delete(root-&gt;left, root-&gt;key);//删除左子树中已经替换上去的节点 &#125; else//右子树更高，在右边删除 &#123; root-&gt;key = __treeMin(root-&gt;right)-&gt;key; root-&gt;right = __Delete(root-&gt;right, root-&gt;key); &#125; &#125; else//有一个孩子、叶子节点的情况合并 &#123; //if (!__isLeaf(root)) AVLNode * tmp = root; root = (root-&gt;left) ? (root-&gt;left) :( root-&gt;right); delete tmp; tmp = nullptr; &#125; &#125;//end-if else if (k &lt; root-&gt;key)//往左边删除 &#123; root-&gt;left = __Delete(root-&gt;left, k);//左子树中递归删除 //判断平衡的条件与在插入时情况类似 if (__diff(root) &lt; -1)//不满足平衡条件，删除左边的后，右子树变高 &#123; if (__diff(root-&gt;right) &gt; 0) &#123; root = __rl_Rotation(root); &#125; else &#123; root = __rr_Rotation(root); &#125; &#125; &#125;//end else if else &#123; root-&gt;right = __Delete(root-&gt;right, k); if (__diff(root) &gt; 1)//不满足平衡条件 &#123; if (__diff(root-&gt;left) &lt; 0) &#123; root = __lr_Rotation(root); &#125; else &#123; root = __ll_Rotation(root); &#125; &#125; &#125; return root;&#125; 附：完整代码 参考 STL源码笔记（18）—平衡二叉树AVL（C++封装+模板） 平衡二叉树,AVL树之图解篇 一步一步写平衡二叉树（AVL树） 平衡二叉树(avl)分析与实现","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://yuechuanx.top/categories/Algorithm/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://yuechuanx.top/tags/algorithm/"},{"name":"tree","slug":"tree","permalink":"https://yuechuanx.top/tags/tree/"}]},{"title":"求有向图全部拓扑序列","slug":"Algorithm/topological-sort-all","date":"2018-05-05T10:38:54.000Z","updated":"2020-04-23T03:36:06.710Z","comments":true,"path":"Algorithm/topological-sort-all/","link":"","permalink":"https://yuechuanx.top/Algorithm/topological-sort-all/","excerpt":"","text":"All Topological Sorts，在前一章中Topological Sorting，已经讨论了拓扑排序的原理及其实现算法，但只是实现了从单一一个入度为0的节点进行的拓扑排序。本章主要来讨论一下，如何求一个有向无环图的所有拓扑排序序列。 问题描述 因为在一个有向无环图中，并非所有顶点间都有路径可达，而且可能有些点是孤立点，这导致了同一个有向图可能会有多个拓扑排序，因为显然孤立点在拓扑序列中的位置是任意的，各子连通子图间的先后次序也可以互换。 那么如何来求一个有向无环图的所有拓扑排序序列呢？我们可以通过修改前一篇文章中的算法达到这个目标，即在原有拓扑排序过程的基础上，加上回溯法，并对所有入度为0的顶点应用这个带回溯的拓扑排序算法， 算法思路 初始化所有顶点为未访问状态； 依次对所有入度为0的顶点，先把其入度降1，然后把该顶点放到排序序列中，然后递归访问它的所有邻接点，最后回溯； 在函数最终返回后，就得到了一个拓扑序列，然后重置访问状态和入度，继续寻找其它拓扑序列。 代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123#include &lt;bits/stdc++.h&gt;using namespace std;class Graph&#123; int V; // No. of vertices // Pointer to an array containing adjacency list list&lt;int&gt; *adj; // Vector to store indegree of vertices vector&lt;int&gt; indegree; // A function used by alltopologicalSort void alltopologicalSortUtil(vector&lt;int&gt;&amp; res, bool visited[]);public: Graph(int V); // Constructor // function to add an edge to graph void addEdge(int v, int w); // Prints all Topological Sorts void alltopologicalSort();&#125;;// Constructor of graphGraph::Graph(int V)&#123; this-&gt;V = V; adj = new list&lt;int&gt;[V]; // Initialising all indegree with 0 for (int i = 0; i &lt; V; i++) indegree.push_back(0);&#125;// Utility function to add edgevoid Graph::addEdge(int v, int w)&#123; adj[v].push_back(w); // Add w to v's list. // increasing inner degree of w by 1 indegree[w]++;&#125;// Main recursive function to print all possible// topological sortsvoid Graph::alltopologicalSortUtil(vector&lt;int&gt;&amp; res, bool visited[])&#123; // To indicate whether all topological are found // or not bool flag = false; for (int i = 0; i &lt; V; i++) &#123; // If indegree is 0 and not yet visited then // only choose that vertex if (indegree[i] == 0 &amp;&amp; !visited[i]) &#123; // reducing indegree of adjacent vertices list&lt;int&gt;:: iterator j; for (j = adj[i].begin(); j != adj[i].end(); j++) indegree[*j]--; // including in result res.push_back(i); visited[i] = true; alltopologicalSortUtil(res, visited); // resetting visited, res and indegree for // backtracking visited[i] = false; res.erase(res.end() - 1); for (j = adj[i].begin(); j != adj[i].end(); j++) indegree[*j]++; flag = true; &#125; &#125; // We reach here if all vertices are visited. // So we print the solution here if (!flag) &#123; for (int i = 0; i &lt; res.size(); i++) cout &lt;&lt; res[i] &lt;&lt; \" \"; cout &lt;&lt; endl; &#125;&#125;// The function does all Topological Sort.// It uses recursive alltopologicalSortUtil()void Graph::alltopologicalSort()&#123; // Mark all the vertices as not visited bool *visited = new bool[V]; for (int i = 0; i &lt; V; i++) visited[i] = false; vector&lt;int&gt; res; alltopologicalSortUtil(res, visited);&#125;int main()&#123; // Create a graph given in the above diagram Graph g(6); g.addEdge(5, 2); g.addEdge(5, 0); g.addEdge(4, 0); g.addEdge(4, 1); g.addEdge(2, 3); g.addEdge(3, 1); cout &lt;&lt; \"All Topological sorts\\\\n\"; g.alltopologicalSort(); return 0;&#125;","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://yuechuanx.top/categories/Algorithm/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://yuechuanx.top/tags/algorithm/"},{"name":"graph","slug":"graph","permalink":"https://yuechuanx.top/tags/graph/"},{"name":"topological-sort","slug":"topological-sort","permalink":"https://yuechuanx.top/tags/topological-sort/"}]},{"title":"求图的拓扑排序","slug":"Algorithm/topological-sort","date":"2018-05-01T10:38:54.000Z","updated":"2020-04-23T03:36:06.710Z","comments":true,"path":"Algorithm/topological-sort/","link":"","permalink":"https://yuechuanx.top/Algorithm/topological-sort/","excerpt":"","text":"简介 拓扑排序 （Topological Sorting） 在计算机科学领域，有向图的拓扑排序或拓扑排序是其顶点的线性排序，使得对于从顶点u到顶点v的每个有向边uv，u在排序中都在v之前。例如，图形的顶点可以表示要执行的任务，并且边缘可以表示一个任务必须在另一个任务之前执行的约束；在这个应用中，拓扑排序只是一个有效的任务顺序。如果当图形没有定向循环，即如果它是有向无环图（Directed Acyclic Graph，即DAG），则拓扑排序是可能的。任何DAG具有至少一个拓扑排序，并且已知有些算法用于在线性时间内构建任何DAG的拓扑排序。 在图论中，由一个有向无环图的顶点组成的序列，当且仅当满足下列条件时，称为该图的一个拓扑排序（Topological sorting）。 每个顶点出现且只出现一次； 若A在序列中排在B的前面，则在图中不存在从B到A的边。 也可以定义为：拓扑排序是对有向无环图的顶点的一种排序，它使得如果存在一条从顶点A到顶点B的路径，那么在排序中B出现在A的后面。 问题描述 一般可以用有向图表示一个工程。在这种有向图中，用顶点表示活动，用弧 &lt;i, j&gt; 表示活动 i 必须在活动 j 开始之前完成。这种有向图叫做用顶点表示活动的网络（Activity on Vertex），记作 AOV网络。 在AOV网络中不能存在有向回路，即有向环。因为如果出现了有向环，意味着某项活动要以自己的完成作为先决条件。显然这是不可能的。所以对给定的AOV网络，必须先判断它是否存在有向环。 一种方法是对AOV网络构造它的拓扑有序序列。即将所有的顶点能够成一个线性有序的序列，使得AOV网络所有的前驱和后继关系得到满足，这种构造AOV网络全部顶点的拓扑有序序列的运算就叫拓扑排序。 例如，下面有一个有向无环图，“5 4 2 3 1 0”是它的一个拓扑排序。一个有向无环图可以有多个拓扑排序，如下图的另一个拓扑排序为“4 5 2 3 1 0”，拓扑排序中的第一个顶点总是入度为0的顶点（即没有任何一条有向边以它为终点）。 算法思路 在AOV网络中选一个没有直接前驱的顶点v，并输出 从图中删除该顶点，同时删去所有从顶点v发出的弧 重复步骤1,2. 直到没有直接前驱的顶点全部输出 算法步骤 用二维list链表存储图的领接表 建立入度为0的顶点栈 当入度为0的顶点栈为空时，转到步骤6，否则步骤3 从入度为0的顶点栈顶元素v出栈，并输出顶点v 从AOV网络删去顶点v和所有顶点v发出的弧 &lt;v, j&gt;， 并将顶点 j 的入度 -1 如果顶点 j 的入度 = 0，则将该顶点置入入度为0的顶点栈，转到步骤2 如果输出顶点个数 &lt; AOV网络顶点数，则图中存在有向环 复杂度分析 Topological Sorting via Depth First Search(DFS) 在DFS中，我们先打印一个顶点，然后递归的对它的邻接点调用DFS。但是在拓扑排序中，任何一个顶点总要先于它的所有邻接顶点打印，如上面的图，顶点5和4必须先于顶点0打印。所以拓扑排序和DFS是不同的，例如“5 2 3 1 0 4”是上图的一个DFS序列，但是这个序列并不是拓扑排序。 在DFS中，我们从任意一个顶点出发，打印它然后对它的所有邻接顶点递归调用DFS。而在拓扑排序中，我们同样调用DFS过程，但是在递归调用DFS的过程中，我们不直接打印顶点，而是把顶点 push 到栈里，等到递归完成后，所有顶点就全都在栈里了。注意，在这个过程中当且仅当一个顶点的所有邻接顶点入栈后，才到当前顶点入栈，这就保证它们能满足拓扑排序的次序要求。所以最后栈里的内容，从栈顶到栈底，就是一个拓扑排序序列，我们不断出栈并打印它们即可。 因为这个算法只是简单的调用了下DFS，并借助栈做为辅助，所以其复杂度和DFS一样是O(V+E)。 代码实现 C++ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#include&lt;iostream&gt;#include &lt;list&gt;#include &lt;stack&gt;using namespace std;// Class to represent a graphclass Graph&#123; int V; // No. of vertices' // Pointer to an array containing adjacency listsList list&lt;int&gt; *adj; // A function used by topologicalSort void topologicalSortUtil(int v, bool visited[], stack&lt;int&gt; &amp;Stack);public: Graph(int V); // Constructor // function to add an edge to graph void addEdge(int v, int w); // prints a Topological Sort of the complete graph void topologicalSort();&#125;;Graph::Graph(int V)&#123; this-&gt;V = V; adj = new list&lt;int&gt;[V];&#125;void Graph::addEdge(int v, int w)&#123; adj[v].push_back(w); // Add w to v’s list.&#125;// A recursive function used by topologicalSortvoid Graph::topologicalSortUtil(int v, bool visited[], stack&lt;int&gt; &amp;Stack)&#123; // Mark the current node as visited. visited[v] = true; // Recur for all the vertices adjacent to this vertex list&lt;int&gt;::iterator i; for (i = adj[v].begin(); i != adj[v].end(); ++i) if (!visited[*i]) topologicalSortUtil(*i, visited, Stack); // Push current vertex to stack which stores result Stack.push(v);&#125;// The function to do Topological Sort. It uses recursive // topologicalSortUtil()void Graph::topologicalSort()&#123; stack&lt;int&gt; Stack; // Mark all the vertices as not visited bool *visited = new bool[V]; for (int i = 0; i &lt; V; i++) visited[i] = false; // Call the recursive helper function to store Topological // Sort starting from all vertices one by one for (int i = 0; i &lt; V; i++) if (visited[i] == false) topologicalSortUtil(i, visited, Stack); // Print contents of stack while (Stack.empty() == false) &#123; cout &lt;&lt; Stack.top() &lt;&lt; \" \"; Stack.pop(); &#125;&#125;int main()&#123; // Create a graph given in the above diagram Graph g(6); g.addEdge(5, 2); g.addEdge(5, 0); g.addEdge(4, 0); g.addEdge(4, 1); g.addEdge(2, 3); g.addEdge(3, 1); cout &lt;&lt; \"Following is a Topological Sort of the given graph n\"; g.topologicalSort(); return 0;&#125; Java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import java.io.*;import java.util.*;// This class represents a directed graph using adjacency// list representationclass Graph&#123; private int V; // No. of vertices private LinkedList&lt;Integer&gt; adj[]; // Adjacency List //Constructor Graph(int v) &#123; V = v; adj = new LinkedList[v]; for (int i=0; i&lt;v; ++i) adj[i] = new LinkedList(); &#125; // Function to add an edge into the graph void addEdge(int v,int w) &#123; adj[v].add(w); &#125; // A recursive function used by topologicalSort void topologicalSortUtil(int v, boolean visited[], Stack stack) &#123; // Mark the current node as visited. visited[v] = true; Integer i; // Recur for all the vertices adjacent to this // vertex Iterator&lt;Integer&gt; it = adj[v].iterator(); while (it.hasNext()) &#123; i = it.next(); if (!visited[i]) topologicalSortUtil(i, visited, stack); &#125; // Push current vertex to stack which stores result stack.push(new Integer(v)); &#125; // The function to do Topological Sort. It uses // recursive topologicalSortUtil() void topologicalSort() &#123; Stack stack = new Stack(); // Mark all the vertices as not visited boolean visited[] = new boolean[V]; for (int i = 0; i &lt; V; i++) visited[i] = false; // Call the recursive helper function to store // Topological Sort starting from all vertices // one by one for (int i = 0; i &lt; V; i++) if (visited[i] == false) topologicalSortUtil(i, visited, stack); // Print contents of stack while (stack.empty()==false) System.out.print(stack.pop() + \" \"); &#125; public static void main(String args[]) &#123; // Create a graph given in the above diagram Graph g = new Graph(6); g.addEdge(5, 2); g.addEdge(5, 0); g.addEdge(4, 0); g.addEdge(4, 1); g.addEdge(2, 3); g.addEdge(3, 1); System.out.println(\"Following is a Topological \" + \"sort of the given graph\"); g.topologicalSort(); &#125;&#125;","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://yuechuanx.top/categories/Algorithm/"}],"tags":[{"name":"graph","slug":"graph","permalink":"https://yuechuanx.top/tags/graph/"},{"name":"topological-sort","slug":"topological-sort","permalink":"https://yuechuanx.top/tags/topological-sort/"}]},{"title":"判断是否为二叉搜索树（BST）","slug":"Algorithm/isBST","date":"2018-04-03T12:03:11.000Z","updated":"2020-04-23T03:36:06.709Z","comments":true,"path":"Algorithm/isBST/","link":"","permalink":"https://yuechuanx.top/Algorithm/isBST/","excerpt":"","text":"问题描述 实现一个函数，判断一棵二叉树是否为二叉搜索树。 算法思路 二叉搜索树的中序遍历序列是有序的，所以只需求出中序遍历结果，再依次判断该序列是否有序即可。 上述方法需要额外线程空间保存遍历结果，在此可以省去该空间开销，只需一个变量保存访问当前节点时上一节点的值即可。 基于left &lt; current &lt; right的特性，可以递归用大小值比较进行判断 代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149/* 题目描述 请实现一个函数，检查一棵二叉树是否为二叉搜索树。 给定树的根结点指针TreeNode* root，请返回一个bool，代表该树是否为二叉搜索树。 */ #include &lt;iostream&gt; #include &lt;cstdlib&gt; #include &lt;vector&gt; #include &lt;queue&gt; using namespace std; /*二叉树节点数据结构*/ struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125; &#125;; const int flag = INT_MAX; TreeNode *generateTree(vector&lt;int&gt; &amp;nums) &#123; if (nums.empty()) return NULL; TreeNode *root = new TreeNode(nums[0]); queue&lt;TreeNode *&gt; que; que.push(root); //求出所给元素个数，对应二叉查找树节点个数 int size = nums.size(); for (int i = 1; i &lt; size; i += 2) &#123; //处理队首节点的左右子树 TreeNode *tmp = que.front(); TreeNode *left = NULL, *right = NULL; //定义非空左子树 if (nums[i] != flag) &#123; left = new TreeNode(nums[i]); que.push(left); &#125; //定义非空右子树 if (i + 1 &lt; size &amp;&amp; nums[i + 1] != flag) &#123; right = new TreeNode(nums[i + 1]); que.push(right); &#125; tmp-&gt;left = left; tmp-&gt;right = right; //弹出当前处理的节点 que.pop(); &#125; return root; &#125; class Checker &#123; public: /*方法一，将中序遍历结果保存到数组 T(n)=O(n) S(n)=O(n)*/ void inOrder(TreeNode *root,vector&lt;int&gt; &amp;v) &#123; if (root == NULL) return; inOrder(root-&gt;left, v); v.push_back(root-&gt;val); inOrder(root-&gt;right, v); &#125; bool checkBST1(TreeNode* root) &#123; vector&lt;int&gt; ret; inOrder(root, ret); for (auto i = ret.begin()+1; i != ret.end(); ++i) &#123; if (*i &lt; *(i - 1)) return false; &#125; return true; &#125; /*方法二、省掉线性空间，保存遍历的最后一个节点*/ int lastVal = INT_MIN; bool checkBST2(TreeNode* root) &#123; // write code here if (!root) return true; /*递归检查左子树*/ if (!checkBST2(root-&gt;left)) return false; /*比较当前节点，并更新已遍历节点最后的值*/ if (root-&gt;val &lt;= lastVal) return false; lastVal = root-&gt;val; /*递归检查右子树*/ if (!checkBST2(root-&gt;right)) return false; return true; &#125; /*方法三，最大最小值法*/ bool checkBST3(TreeNode* root) &#123; // write code here if (!root) return true; return checkBST3(root, INT_MAX, INT_MIN); &#125; bool checkBST3(TreeNode *root, int maxVal, int minVal) &#123; if (!root) return true; if (root-&gt;val &lt; minVal || root-&gt;val &gt;= maxVal) return false; if (!checkBST3(root-&gt;left, root-&gt;val, minVal) || !checkBST3(root-&gt;right, maxVal, root-&gt;val)) return false; return true; &#125; &#125;; int main() &#123; vector&lt;int&gt; v = &#123; 7, 6, flag, 4, flag, 2, 5, 8, 3, flag, flag, flag, flag, flag, flag &#125;; TreeNode *root = generateTree(v); Checker c; bool ret = c.checkBST1(root); cout &lt;&lt; ret &lt;&lt; endl; ret = c.checkBST2(root); cout &lt;&lt; ret &lt;&lt; endl; ret = c.checkBST3(root); cout &lt;&lt; ret &lt;&lt; endl; system(\"pause\"); return 0; &#125;","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://yuechuanx.top/categories/Algorithm/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://yuechuanx.top/tags/algorithm/"},{"name":"tree","slug":"tree","permalink":"https://yuechuanx.top/tags/tree/"}]},{"title":"Git 基础","slug":"DevOps/git-tutorial","date":"2018-01-01T10:38:54.000Z","updated":"2020-04-23T03:36:06.712Z","comments":true,"path":"DevOps/git-tutorial/","link":"","permalink":"https://yuechuanx.top/DevOps/git-tutorial/","excerpt":"","text":"获取 Git 仓库 有两种取得 Git 项目仓库的方法。 从当前项目初始化: 1git init 从现有仓库克隆: 12git clone [URL]git clone [URL] DIR_NAME 记录每次更新到仓库 检测当前文件状态 : 1git status 提出更改（把它们添加到暂存区）： 123git add filename # 针对特定文件git add * # 所有文件git add *.txt # 支持通配符，所有 .txt 文件 忽略文件： .gitignore 提交更新: 1git commit -m COMMIT_MSG #提交暂存区的代码 跳过使用暂存区域更新的方式 : 1git commit -a -m COMMIT_MSG #可跳过 git add 移除文件 ： 1git rm filename # 从暂存区域移除，然后提交。 对文件重命名 ： 12345git mv README.md README #这个命令相当于 mv README.md READMEgit rm README.mdgit add README 这三条命令的集合 推送改动到远程仓库 将你的仓库连接到某个远程仓库 git remote add origin &lt;server&gt; 将这些改动提交到远端仓库 1git push origin master # master可以替换为其他分支 远程仓库的移除与重命名 将 test 重命名位 test1： 1git remote rename test test1 移除远程仓库 test1: 1git remote rm test1 查看提交历史 在提交了若干更新，又或者克隆了某个项目之后，你也许想回顾下提交历史。 完成这个任务最简单而又有效的工具是 git log 命令。 git log 会按提交时间列出所有的更新，最近的更新排在最上面。 可以添加一些参数来查看自己希望看到的内容： 只看某个人的提交记录： 1git log --author=bob 撤销操作 有时候我们提交完了才发现漏掉了几个文件没有添加，或者提交信息写错了。 此时，可以运行带有 --amend 选项的提交命令尝试重新提交： 1git commit --amend 取消暂存的文件 1git reset filename 撤消对文件的修改: 1git checkout -- filename 假如你想丢弃你在本地的所有改动与提交，可以到服务器上获取最新的版本历史，并将你本地主分支指向它： 12git fetch origingit reset --hard origin/master 分支 分支是用来将特性开发绝缘开来的。在你创建仓库的时候，master 是“默认的”分支。在其他分支上进行开发，完成后再将它们合并到主分支上。 我们通常在开发新功能、修复一个紧急 bug 等等时候会选择创建分支。单分支开发好还是多分支开发好，还是要看具体场景来说。 创建一个名字叫做 test 的分支 1git branch test 切换当前分支到 test（当你切换分支的时候，Git 会重置你的工作目录，使其看起来像回到了你在那个分支上最后一次提交的样子。 Git 会自动添加、删除、修改文件以确保此时你的工作目录和这个分支最后一次提交时的样子一模一样） 1git checkout test 你也可以直接这样创建分支并切换过去(上面两条命令的合写) 1git checkout -b feature_x 切换到主分支 1git checkout master 合并分支(可能会有冲突) 1git merge test 把新建的分支删掉 1git branch -d feature_x 将分支推送到远端仓库（推送成功后其他人可见）： 1git push origin 推荐阅读 Git - 简明指南 图解Git 猴子都能懂得Git入门 Pro Git","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://yuechuanx.top/categories/DevOps/"}],"tags":[{"name":"git","slug":"git","permalink":"https://yuechuanx.top/tags/git/"}]}]}